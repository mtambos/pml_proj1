{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.io import savemat, loadmat\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (log_loss, mean_squared_error, roc_curve, auc,\n",
    "                             precision_recall_fscore_support, confusion_matrix)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from tqdm import tqdm, trange, tqdm_notebook as tqdmn\n",
    "\n",
    "from BEKML import BEMKL, plot_distplot\n",
    "from utils import poly_kernel, gauss_kernel, scoring, plot_kernel_importances, plot_compare_models\n",
    "\n",
    "sns.set(style='ticks', context='talk')\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.00000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.732323</td>\n",
       "      <td>17.412323</td>\n",
       "      <td>22.27601</td>\n",
       "      <td>114.856566</td>\n",
       "      <td>970.040909</td>\n",
       "      <td>0.102681</td>\n",
       "      <td>0.142648</td>\n",
       "      <td>0.156243</td>\n",
       "      <td>0.086776</td>\n",
       "      <td>0.192754</td>\n",
       "      <td>...</td>\n",
       "      <td>140.347778</td>\n",
       "      <td>1404.958586</td>\n",
       "      <td>0.143921</td>\n",
       "      <td>0.365102</td>\n",
       "      <td>0.436685</td>\n",
       "      <td>0.178778</td>\n",
       "      <td>0.323404</td>\n",
       "      <td>0.090828</td>\n",
       "      <td>2.847475</td>\n",
       "      <td>3.211340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.462870</td>\n",
       "      <td>3.161676</td>\n",
       "      <td>4.29829</td>\n",
       "      <td>21.383402</td>\n",
       "      <td>352.149215</td>\n",
       "      <td>0.012522</td>\n",
       "      <td>0.049898</td>\n",
       "      <td>0.070572</td>\n",
       "      <td>0.033877</td>\n",
       "      <td>0.027437</td>\n",
       "      <td>...</td>\n",
       "      <td>28.892279</td>\n",
       "      <td>586.006972</td>\n",
       "      <td>0.022004</td>\n",
       "      <td>0.163965</td>\n",
       "      <td>0.173625</td>\n",
       "      <td>0.045181</td>\n",
       "      <td>0.075161</td>\n",
       "      <td>0.021172</td>\n",
       "      <td>1.937964</td>\n",
       "      <td>5.479276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>10.38000</td>\n",
       "      <td>71.900000</td>\n",
       "      <td>361.600000</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>0.046050</td>\n",
       "      <td>0.023980</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>...</td>\n",
       "      <td>85.100000</td>\n",
       "      <td>508.100000</td>\n",
       "      <td>0.081910</td>\n",
       "      <td>0.051310</td>\n",
       "      <td>0.023980</td>\n",
       "      <td>0.028990</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.052500</td>\n",
       "      <td>19.41250</td>\n",
       "      <td>98.160000</td>\n",
       "      <td>702.525000</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.106850</td>\n",
       "      <td>0.063670</td>\n",
       "      <td>0.174075</td>\n",
       "      <td>...</td>\n",
       "      <td>118.075000</td>\n",
       "      <td>947.275000</td>\n",
       "      <td>0.129325</td>\n",
       "      <td>0.248700</td>\n",
       "      <td>0.322150</td>\n",
       "      <td>0.152650</td>\n",
       "      <td>0.275950</td>\n",
       "      <td>0.076578</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.500000</td>\n",
       "      <td>17.290000</td>\n",
       "      <td>21.75000</td>\n",
       "      <td>113.700000</td>\n",
       "      <td>929.100000</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.151350</td>\n",
       "      <td>0.086075</td>\n",
       "      <td>0.189350</td>\n",
       "      <td>...</td>\n",
       "      <td>136.500000</td>\n",
       "      <td>1295.000000</td>\n",
       "      <td>0.141850</td>\n",
       "      <td>0.351300</td>\n",
       "      <td>0.402350</td>\n",
       "      <td>0.179250</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.086890</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72.750000</td>\n",
       "      <td>19.580000</td>\n",
       "      <td>24.65500</td>\n",
       "      <td>129.650000</td>\n",
       "      <td>1193.500000</td>\n",
       "      <td>0.110975</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.103925</td>\n",
       "      <td>0.209325</td>\n",
       "      <td>...</td>\n",
       "      <td>159.875000</td>\n",
       "      <td>1694.250000</td>\n",
       "      <td>0.154875</td>\n",
       "      <td>0.423675</td>\n",
       "      <td>0.541050</td>\n",
       "      <td>0.207125</td>\n",
       "      <td>0.358800</td>\n",
       "      <td>0.101375</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>27.220000</td>\n",
       "      <td>39.28000</td>\n",
       "      <td>182.100000</td>\n",
       "      <td>2250.000000</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>232.200000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               2           3          4           5            6           7   \\\n",
       "count  198.000000  198.000000  198.00000  198.000000   198.000000  198.000000   \n",
       "mean    46.732323   17.412323   22.27601  114.856566   970.040909    0.102681   \n",
       "std     34.462870    3.161676    4.29829   21.383402   352.149215    0.012522   \n",
       "min      1.000000   10.950000   10.38000   71.900000   361.600000    0.074970   \n",
       "25%     14.000000   15.052500   19.41250   98.160000   702.525000    0.093900   \n",
       "50%     39.500000   17.290000   21.75000  113.700000   929.100000    0.101900   \n",
       "75%     72.750000   19.580000   24.65500  129.650000  1193.500000    0.110975   \n",
       "max    125.000000   27.220000   39.28000  182.100000  2250.000000    0.144700   \n",
       "\n",
       "               8           9           10          11     ...              25  \\\n",
       "count  198.000000  198.000000  198.000000  198.000000     ...      198.000000   \n",
       "mean     0.142648    0.156243    0.086776    0.192754     ...      140.347778   \n",
       "std      0.049898    0.070572    0.033877    0.027437     ...       28.892279   \n",
       "min      0.046050    0.023980    0.020310    0.130800     ...       85.100000   \n",
       "25%      0.110200    0.106850    0.063670    0.174075     ...      118.075000   \n",
       "50%      0.131750    0.151350    0.086075    0.189350     ...      136.500000   \n",
       "75%      0.172200    0.200500    0.103925    0.209325     ...      159.875000   \n",
       "max      0.311400    0.426800    0.201200    0.304000     ...      232.200000   \n",
       "\n",
       "                26          27          28          29          30  \\\n",
       "count   198.000000  198.000000  198.000000  198.000000  198.000000   \n",
       "mean   1404.958586    0.143921    0.365102    0.436685    0.178778   \n",
       "std     586.006972    0.022004    0.163965    0.173625    0.045181   \n",
       "min     508.100000    0.081910    0.051310    0.023980    0.028990   \n",
       "25%     947.275000    0.129325    0.248700    0.322150    0.152650   \n",
       "50%    1295.000000    0.141850    0.351300    0.402350    0.179250   \n",
       "75%    1694.250000    0.154875    0.423675    0.541050    0.207125   \n",
       "max    3903.000000    0.222600    1.058000    1.170000    0.290300   \n",
       "\n",
       "               31          32          33          34  \n",
       "count  198.000000  198.000000  198.000000  194.000000  \n",
       "mean     0.323404    0.090828    2.847475    3.211340  \n",
       "std      0.075161    0.021172    1.937964    5.479276  \n",
       "min      0.156500    0.055040    0.400000    0.000000  \n",
       "25%      0.275950    0.076578    1.500000    0.000000  \n",
       "50%      0.310300    0.086890    2.500000    1.000000  \n",
       "75%      0.358800    0.101375    3.500000    4.000000  \n",
       "max      0.663800    0.207500   10.000000   27.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119513</th>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>117.50</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>0.07055</td>\n",
       "      <td>...</td>\n",
       "      <td>139.70</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8423</th>\n",
       "      <td>N</td>\n",
       "      <td>61</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>N</td>\n",
       "      <td>116</td>\n",
       "      <td>21.37</td>\n",
       "      <td>17.44</td>\n",
       "      <td>137.50</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.08180</td>\n",
       "      <td>...</td>\n",
       "      <td>159.10</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>0.1188</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.09067</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843483</th>\n",
       "      <td>N</td>\n",
       "      <td>123</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.2839</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843584</th>\n",
       "      <td>R</td>\n",
       "      <td>27</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2      3      4       5       6        7       8       9   \\\n",
       "0                                                                       \n",
       "119513  N   31  18.02  27.60  117.50  1013.0  0.09489  0.1036  0.1086   \n",
       "8423    N   61  17.99  10.38  122.80  1001.0  0.11840  0.2776  0.3001   \n",
       "842517  N  116  21.37  17.44  137.50  1373.0  0.08836  0.1189  0.1255   \n",
       "843483  N  123  11.42  20.38   77.58   386.1  0.14250  0.2839  0.2414   \n",
       "843584  R   27  20.29  14.34  135.10  1297.0  0.10030  0.1328  0.1980   \n",
       "\n",
       "             10 ...       25      26      27      28      29      30      31  \\\n",
       "0               ...                                                            \n",
       "119513  0.07055 ...   139.70  1436.0  0.1195  0.1926  0.3140  0.1170  0.2677   \n",
       "8423    0.14710 ...   184.60  2019.0  0.1622  0.6656  0.7119  0.2654  0.4601   \n",
       "842517  0.08180 ...   159.10  1949.0  0.1188  0.3449  0.3414  0.2032  0.4334   \n",
       "843483  0.10520 ...    98.87   567.7  0.2098  0.8663  0.6869  0.2575  0.6638   \n",
       "843584  0.10430 ...   152.20  1575.0  0.1374  0.2050  0.4000  0.1625  0.2364   \n",
       "\n",
       "             32   33   34  \n",
       "0                          \n",
       "119513  0.08113  5.0  5.0  \n",
       "8423    0.11890  3.0  2.0  \n",
       "842517  0.09067  2.5  0.0  \n",
       "843483  0.17300  2.0  0.0  \n",
       "843584  0.07678  3.5  0.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.938144</td>\n",
       "      <td>17.402320</td>\n",
       "      <td>22.300979</td>\n",
       "      <td>114.781495</td>\n",
       "      <td>969.092268</td>\n",
       "      <td>0.102774</td>\n",
       "      <td>0.142642</td>\n",
       "      <td>0.156309</td>\n",
       "      <td>0.086808</td>\n",
       "      <td>0.192885</td>\n",
       "      <td>...</td>\n",
       "      <td>140.136907</td>\n",
       "      <td>1401.756701</td>\n",
       "      <td>0.143921</td>\n",
       "      <td>0.364567</td>\n",
       "      <td>0.436010</td>\n",
       "      <td>0.178449</td>\n",
       "      <td>0.322251</td>\n",
       "      <td>0.090777</td>\n",
       "      <td>2.867526</td>\n",
       "      <td>3.211340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.523646</td>\n",
       "      <td>3.171672</td>\n",
       "      <td>4.335292</td>\n",
       "      <td>21.430694</td>\n",
       "      <td>353.159959</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.050229</td>\n",
       "      <td>0.070942</td>\n",
       "      <td>0.033962</td>\n",
       "      <td>0.027679</td>\n",
       "      <td>...</td>\n",
       "      <td>28.826843</td>\n",
       "      <td>587.040705</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>0.165528</td>\n",
       "      <td>0.174757</td>\n",
       "      <td>0.045529</td>\n",
       "      <td>0.074068</td>\n",
       "      <td>0.021371</td>\n",
       "      <td>1.950588</td>\n",
       "      <td>5.479276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>10.380000</td>\n",
       "      <td>71.900000</td>\n",
       "      <td>361.600000</td>\n",
       "      <td>0.074970</td>\n",
       "      <td>0.046050</td>\n",
       "      <td>0.023980</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>...</td>\n",
       "      <td>85.100000</td>\n",
       "      <td>508.100000</td>\n",
       "      <td>0.081910</td>\n",
       "      <td>0.051310</td>\n",
       "      <td>0.023980</td>\n",
       "      <td>0.028990</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.250000</td>\n",
       "      <td>15.052500</td>\n",
       "      <td>19.342500</td>\n",
       "      <td>98.160000</td>\n",
       "      <td>702.525000</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.109850</td>\n",
       "      <td>0.106075</td>\n",
       "      <td>0.063760</td>\n",
       "      <td>0.174075</td>\n",
       "      <td>...</td>\n",
       "      <td>117.925000</td>\n",
       "      <td>940.575000</td>\n",
       "      <td>0.129325</td>\n",
       "      <td>0.247550</td>\n",
       "      <td>0.322150</td>\n",
       "      <td>0.152225</td>\n",
       "      <td>0.275950</td>\n",
       "      <td>0.076368</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.500000</td>\n",
       "      <td>17.290000</td>\n",
       "      <td>21.795000</td>\n",
       "      <td>113.700000</td>\n",
       "      <td>929.100000</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>0.131750</td>\n",
       "      <td>0.152050</td>\n",
       "      <td>0.086075</td>\n",
       "      <td>0.189350</td>\n",
       "      <td>...</td>\n",
       "      <td>136.500000</td>\n",
       "      <td>1295.000000</td>\n",
       "      <td>0.141750</td>\n",
       "      <td>0.350450</td>\n",
       "      <td>0.401150</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.086540</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>19.580000</td>\n",
       "      <td>24.782500</td>\n",
       "      <td>129.650000</td>\n",
       "      <td>1193.500000</td>\n",
       "      <td>0.111375</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.103925</td>\n",
       "      <td>0.209550</td>\n",
       "      <td>...</td>\n",
       "      <td>159.875000</td>\n",
       "      <td>1694.250000</td>\n",
       "      <td>0.154450</td>\n",
       "      <td>0.423675</td>\n",
       "      <td>0.550175</td>\n",
       "      <td>0.207125</td>\n",
       "      <td>0.358475</td>\n",
       "      <td>0.101775</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>27.220000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>182.100000</td>\n",
       "      <td>2250.000000</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>232.200000</td>\n",
       "      <td>3903.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               2           3           4           5            6   \\\n",
       "count  194.000000  194.000000  194.000000  194.000000   194.000000   \n",
       "mean    46.938144   17.402320   22.300979  114.781495   969.092268   \n",
       "std     34.523646    3.171672    4.335292   21.430694   353.159959   \n",
       "min      1.000000   10.950000   10.380000   71.900000   361.600000   \n",
       "25%     14.250000   15.052500   19.342500   98.160000   702.525000   \n",
       "50%     39.500000   17.290000   21.795000  113.700000   929.100000   \n",
       "75%     73.000000   19.580000   24.782500  129.650000  1193.500000   \n",
       "max    125.000000   27.220000   39.280000  182.100000  2250.000000   \n",
       "\n",
       "               7           8           9           10          11     ...      \\\n",
       "count  194.000000  194.000000  194.000000  194.000000  194.000000     ...       \n",
       "mean     0.102774    0.142642    0.156309    0.086808    0.192885     ...       \n",
       "std      0.012607    0.050229    0.070942    0.033962    0.027679     ...       \n",
       "min      0.074970    0.046050    0.023980    0.020310    0.130800     ...       \n",
       "25%      0.093900    0.109850    0.106075    0.063760    0.174075     ...       \n",
       "50%      0.102200    0.131750    0.152050    0.086075    0.189350     ...       \n",
       "75%      0.111375    0.172200    0.200500    0.103925    0.209550     ...       \n",
       "max      0.144700    0.311400    0.426800    0.201200    0.304000     ...       \n",
       "\n",
       "               25           26          27          28          29  \\\n",
       "count  194.000000   194.000000  194.000000  194.000000  194.000000   \n",
       "mean   140.136907  1401.756701    0.143921    0.364567    0.436010   \n",
       "std     28.826843   587.040705    0.022092    0.165528    0.174757   \n",
       "min     85.100000   508.100000    0.081910    0.051310    0.023980   \n",
       "25%    117.925000   940.575000    0.129325    0.247550    0.322150   \n",
       "50%    136.500000  1295.000000    0.141750    0.350450    0.401150   \n",
       "75%    159.875000  1694.250000    0.154450    0.423675    0.550175   \n",
       "max    232.200000  3903.000000    0.222600    1.058000    1.170000   \n",
       "\n",
       "               30          31          32          33          34  \n",
       "count  194.000000  194.000000  194.000000  194.000000  194.000000  \n",
       "mean     0.178449    0.322251    0.090777    2.867526    3.211340  \n",
       "std      0.045529    0.074068    0.021371    1.950588    5.479276  \n",
       "min      0.028990    0.156500    0.055040    0.400000    0.000000  \n",
       "25%      0.152225    0.275950    0.076368    1.500000    0.000000  \n",
       "50%      0.178500    0.310300    0.086540    2.500000    1.000000  \n",
       "75%      0.207125    0.358475    0.101775    3.500000    4.000000  \n",
       "max      0.290300    0.663800    0.207500   10.000000   27.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/wpbc.csv', names=list(range(35)), index_col=0, na_values='?')\n",
    "display(data.describe())\n",
    "data = data.dropna()\n",
    "display(data.head())\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 33)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(194,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.5257731958762887"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data.iloc[:, 1:].copy()\n",
    "y = data.iloc[:, 0].copy()\n",
    "N, D = X.shape\n",
    "y.loc[y == 'N'] = -1\n",
    "y.loc[y == 'R'] = 1\n",
    "y = y.astype(int)\n",
    "display(X.shape, y.shape, y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119513</th>\n",
       "      <td>31</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>117.50</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>0.07055</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>...</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8423</th>\n",
       "      <td>61</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>116</td>\n",
       "      <td>21.37</td>\n",
       "      <td>17.44</td>\n",
       "      <td>137.50</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.08180</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>...</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>0.1188</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.09067</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843483</th>\n",
       "      <td>123</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.2839</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843584</th>\n",
       "      <td>27</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2      3      4       5       6        7       8       9        10  \\\n",
       "0                                                                             \n",
       "119513   31  18.02  27.60  117.50  1013.0  0.09489  0.1036  0.1086  0.07055   \n",
       "8423     61  17.99  10.38  122.80  1001.0  0.11840  0.2776  0.3001  0.14710   \n",
       "842517  116  21.37  17.44  137.50  1373.0  0.08836  0.1189  0.1255  0.08180   \n",
       "843483  123  11.42  20.38   77.58   386.1  0.14250  0.2839  0.2414  0.10520   \n",
       "843584   27  20.29  14.34  135.10  1297.0  0.10030  0.1328  0.1980  0.10430   \n",
       "\n",
       "            11 ...      26      27      28      29      30      31       32  \\\n",
       "0              ...                                                            \n",
       "119513  0.1865 ...  1436.0  0.1195  0.1926  0.3140  0.1170  0.2677  0.08113   \n",
       "8423    0.2419 ...  2019.0  0.1622  0.6656  0.7119  0.2654  0.4601  0.11890   \n",
       "842517  0.2333 ...  1949.0  0.1188  0.3449  0.3414  0.2032  0.4334  0.09067   \n",
       "843483  0.2597 ...   567.7  0.2098  0.8663  0.6869  0.2575  0.6638  0.17300   \n",
       "843584  0.1809 ...  1575.0  0.1374  0.2050  0.4000  0.1625  0.2364  0.07678   \n",
       "\n",
       "         33   34  1   \n",
       "0                     \n",
       "119513  5.0  5.0  -1  \n",
       "8423    3.0  2.0  -1  \n",
       "842517  2.5  0.0  -1  \n",
       "843483  2.0  0.0  -1  \n",
       "843584  3.5  0.0   1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_data = data.copy()\n",
    "proc_data.iloc[:, 0] = y\n",
    "proc_data = proc_data.loc[:, list(proc_data.columns[1:]) + [proc_data.columns[0]]]\n",
    "proc_data.to_csv('data/proc_wpbc.csv')\n",
    "proc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 442)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_init, rbf_end = -3, 7\n",
    "ply_init, ply_end = 1, 4\n",
    "\n",
    "kernel_attrs = [('rbf', 'all', i) for i in range(rbf_init, rbf_end)]\n",
    "kernels = [lambda A, B: gauss_kernel(A, B, 2**i)\n",
    "           for i in range(rbf_init, rbf_end)]\n",
    "\n",
    "kernel_attrs += [('poly', 'all', i) for i in range(ply_init, ply_end)]\n",
    "kernels += [lambda A, B: poly_kernel(A, B, 1, i)\n",
    "            for i in range(ply_init, ply_end)]\n",
    "\n",
    "kernel_attrs += [('rbf', j, i) for i in range(rbf_init, rbf_end)\n",
    "                 for j in range(D)]\n",
    "kernels += [lambda A, B: gauss_kernel(A[:, j:j+1], B[:, j:j+1], 2**i)\n",
    "            for i in range(rbf_init, rbf_end) for j in range(D)]\n",
    "\n",
    "kernel_attrs += [('poly', j, i) for i in range(ply_init, ply_end)\n",
    "                 for j in range(D)]\n",
    "kernels += [lambda A, B: poly_kernel(A[:, j:j+1], B[:, j:j+1], 1, i)\n",
    "            for i in range(ply_init, ply_end) for j in range(D)]\n",
    "len(kernels), len(kernel_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =\\\n",
    "        train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 442/442 (1.0). SV: 142/145 (0.9793103448275862). Mean e: 0.0181. Median e: -0.0196. Std e: 0.0853. \n",
      "1 - Kernels: 442/442 (1.0). SV: 136/145 (0.9379310344827586). Mean e: 0.0148. Median e: -0.0342. Std e: 0.0982. \n",
      "2 - Kernels: 442/442 (1.0). SV: 128/146 (0.8767123287671232). Mean e: 0.0135. Median e: -0.0206. Std e: 0.0798. \n",
      "3 - Kernels: 112/442 (0.25339366515837103). SV: 127/146 (0.8698630136986302). Mean e: 0.0166. Median e: 0.0077. Std e: 0.0561. \n",
      "4 - Kernels: 432/442 (0.9773755656108597). SV: 133/145 (0.9172413793103448). Mean e: 0.0152. Median e: -0.0179. Std e: 0.0763. \n",
      "5 - Kernels: 442/442 (1.0). SV: 139/145 (0.9586206896551724). Mean e: 0.0127. Median e: -0.0223. Std e: 0.0779. \n",
      "6 - Kernels: 442/442 (1.0). SV: 128/146 (0.8767123287671232). Mean e: 0.0143. Median e: -0.0312. Std e: 0.1078. \n",
      "7 - Kernels: 432/442 (0.9773755656108597). SV: 103/146 (0.7054794520547946). Mean e: 0.0180. Median e: -0.0133. Std e: 0.0694. \n",
      "8 - Kernels: 102/442 (0.23076923076923078). SV: 144/145 (0.993103448275862). Mean e: 0.0159. Median e: -0.0098. Std e: 0.0583. \n",
      "9 - Kernels: 442/442 (1.0). SV: 115/145 (0.7931034482758621). Mean e: 0.0155. Median e: -0.0323. Std e: 0.1045. \n",
      "10 - Kernels: 442/442 (1.0). SV: 140/146 (0.958904109589041). Mean e: 0.0131. Median e: -0.0321. Std e: 0.0979. \n",
      "11 - Kernels: 432/442 (0.9773755656108597). SV: 111/146 (0.7602739726027398). Mean e: 0.0146. Median e: -0.0179. Std e: 0.0741. \n",
      "12 - Kernels: 432/442 (0.9773755656108597). SV: 115/145 (0.7931034482758621). Mean e: 0.0110. Median e: -0.0140. Std e: 0.0601. \n",
      "13 - Kernels: 442/442 (1.0). SV: 142/145 (0.9793103448275862). Mean e: 0.0180. Median e: -0.0238. Std e: 0.0948. \n",
      "14 - Kernels: 102/442 (0.23076923076923078). SV: 122/146 (0.8356164383561644). Mean e: 0.0193. Median e: -0.0036. Std e: 0.0743. \n",
      "15 - Kernels: 442/442 (1.0). SV: 139/146 (0.952054794520548). Mean e: 0.0148. Median e: -0.0229. Std e: 0.0774. \n",
      "16 - Kernels: 432/442 (0.9773755656108597). SV: 128/145 (0.8827586206896552). Mean e: 0.0152. Median e: -0.0157. Std e: 0.0768. \n",
      "17 - Kernels: 442/442 (1.0). SV: 137/145 (0.9448275862068966). Mean e: 0.0179. Median e: -0.0271. Std e: 0.1050. \n",
      "18 - Kernels: 432/442 (0.9773755656108597). SV: 112/146 (0.7671232876712328). Mean e: 0.0169. Median e: -0.0118. Std e: 0.0710. \n",
      "19 - Kernels: 442/442 (1.0). SV: 124/146 (0.8493150684931506). Mean e: 0.0135. Median e: -0.0190. Std e: 0.0782. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([ 9.203 ,  7.9835,  7.6467,  7.9533,  7.5436,  8.9835,  7.7023,  7.2376,  8.0288,  9.2573,\n",
       "         10.8527,  9.9686,  8.1865,  7.3853,  7.5086,  7.5116,  6.3709,  6.2813,  6.3742,  6.6055]),\n",
       "  'score_time': array([0.5165, 0.487 , 0.4665, 0.4674, 0.5666, 0.5098, 0.4927, 0.5379, 0.495 , 0.4831, 0.5042,\n",
       "         0.5124, 0.5048, 0.5485, 0.4848, 0.4762, 0.4737, 0.4661, 0.4623, 0.4703]),\n",
       "  'test_score': array([0.7551, 0.7551, 0.8125, 0.7917, 0.8163, 0.7959, 0.7708, 0.7292, 0.7347, 0.7551, 0.7917,\n",
       "         0.7917, 0.7143, 0.8163, 0.8333, 0.7708, 0.7551, 0.7551, 0.7708, 0.7292]),\n",
       "  'train_score': array([0.8069, 0.7931, 0.774 , 0.7603, 0.7793, 0.7655, 0.7808, 0.8014, 0.7862, 0.7862, 0.7671,\n",
       "         0.7877, 0.7793, 0.7724, 0.7671, 0.7671, 0.7724, 0.8276, 0.7945, 0.7808])},\n",
       " [{'elapsed_time': 8.923488855361938,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 142,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 7.687211990356445,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 136,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 7.323132514953613,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 128,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 7.62950873374939,\n",
       "   'nr_kernels_used': 112,\n",
       "   'nr_sv_used': 127,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 7.2235283851623535,\n",
       "   'nr_kernels_used': 432,\n",
       "   'nr_sv_used': 133,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 8.682949542999268,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 139,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 7.398940086364746,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 128,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.879850387573242,\n",
       "   'nr_kernels_used': 432,\n",
       "   'nr_sv_used': 103,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 7.697787761688232,\n",
       "   'nr_kernels_used': 102,\n",
       "   'nr_sv_used': 144,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 8.896764755249023,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 115,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 10.541829347610474,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 140,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 9.643259286880493,\n",
       "   'nr_kernels_used': 432,\n",
       "   'nr_sv_used': 111,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 7.897265434265137,\n",
       "   'nr_kernels_used': 432,\n",
       "   'nr_sv_used': 115,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 7.087337255477905,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 142,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 7.205117702484131,\n",
       "   'nr_kernels_used': 102,\n",
       "   'nr_sv_used': 122,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 7.203341007232666,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 139,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.082517147064209,\n",
       "   'nr_kernels_used': 432,\n",
       "   'nr_sv_used': 128,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 5.989139556884766,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 137,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.069711923599243,\n",
       "   'nr_kernels_used': 432,\n",
       "   'nr_sv_used': 112,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.310844659805298,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 124,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146}])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "base_model = BEMKL(kernels=kernels, hyp_lambda_alpha=1, hyp_lambda_beta=1,\n",
    "                   hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                   hyp_omega_alpha=1, hyp_omega_beta=1,\n",
    "                   e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                   filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                   max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "base_model = make_pipeline(Normalizer(), base_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "base_cv_results = cross_validate(base_model, X, y, cv=folds, scoring=scoring)\n",
    "base_stats = deepcopy(scoring.stats)\n",
    "base_cv_results, base_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7722363945578232 +- 0.03231630957034512\n",
      "Time: 7.618676316738129 +- 1.1787609739862706\n",
      "Kernels: 388.5 +- 119.04935951108683\n",
      "SVs: 128.25 +- 11.755317945508747\n"
     ]
    }
   ],
   "source": [
    "base_times = np.array([s['elapsed_time'] for s in base_stats])\n",
    "base_kernels = np.array([s['nr_kernels_used'] for s in base_stats])\n",
    "base_sv = np.array([s['nr_sv_used'] for s in base_stats])\n",
    "print(\n",
    "    f\"Score: {base_cv_results['test_score'].mean()} +- {base_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {base_times.mean()} +- {base_times.std()}\\n\"\n",
    "    f\"Kernels: {base_kernels.mean()} +- {base_kernels.std()}\\n\"\n",
    "    f\"SVs: {base_sv.mean()} +- {base_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel-sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 1/442 (0.0022624434389140274). SV: 141/145 (0.9724137931034482). Mean e: 0.0067. Median e: 0.0006. Std e: 0.1259. \n",
      "1 - Kernels: 1/442 (0.0022624434389140274). SV: 140/145 (0.9655172413793104). Mean e: 0.0044. Median e: 0.0006. Std e: 0.0802. \n",
      "2 - Kernels: 2/442 (0.004524886877828055). SV: 131/146 (0.8972602739726028). Mean e: 0.0062. Median e: 0.0005. Std e: 0.1169. \n",
      "3 - Kernels: 1/442 (0.0022624434389140274). SV: 118/146 (0.8082191780821918). Mean e: 0.0060. Median e: 0.0005. Std e: 0.1087. \n",
      "4 - Kernels: 3/442 (0.006787330316742082). SV: 139/145 (0.9586206896551724). Mean e: 0.0071. Median e: 0.0006. Std e: 0.1355. \n",
      "5 - Kernels: 1/442 (0.0022624434389140274). SV: 128/145 (0.8827586206896552). Mean e: 0.0077. Median e: 0.0006. Std e: 0.1405. \n",
      "6 - Kernels: 2/442 (0.004524886877828055). SV: 127/146 (0.8698630136986302). Mean e: 0.0092. Median e: 0.0005. Std e: 0.4941. \n",
      "7 - Kernels: 1/442 (0.0022624434389140274). SV: 139/146 (0.952054794520548). Mean e: 0.0045. Median e: 0.0006. Std e: 0.0822. \n",
      "8 - Kernels: 3/442 (0.006787330316742082). SV: 127/145 (0.8758620689655172). Mean e: 0.0065. Median e: 0.0004. Std e: 0.1229. \n",
      "9 - Kernels: 1/442 (0.0022624434389140274). SV: 134/145 (0.9241379310344827). Mean e: 0.0065. Median e: 0.0005. Std e: 0.1219. \n",
      "10 - Kernels: 1/442 (0.0022624434389140274). SV: 145/146 (0.9931506849315068). Mean e: 0.0052. Median e: 0.0005. Std e: 0.0991. \n",
      "11 - Kernels: 2/442 (0.004524886877828055). SV: 141/146 (0.9657534246575342). Mean e: 0.0101. Median e: 0.0005. Std e: 0.4781. \n",
      "12 - Kernels: 1/442 (0.0022624434389140274). SV: 134/145 (0.9241379310344827). Mean e: 0.0052. Median e: 0.0005. Std e: 0.0900. \n",
      "13 - Kernels: 3/442 (0.006787330316742082). SV: 137/145 (0.9448275862068966). Mean e: 0.0071. Median e: 0.0005. Std e: 0.1343. \n",
      "14 - Kernels: 3/442 (0.006787330316742082). SV: 141/146 (0.9657534246575342). Mean e: 0.0082. Median e: 0.0005. Std e: 0.1596. \n",
      "15 - Kernels: 1/442 (0.0022624434389140274). SV: 128/146 (0.8767123287671232). Mean e: 0.0054. Median e: 0.0005. Std e: 0.0989. \n",
      "16 - Kernels: 2/442 (0.004524886877828055). SV: 128/145 (0.8827586206896552). Mean e: 0.0077. Median e: 0.0006. Std e: 0.5192. \n",
      "17 - Kernels: 2/442 (0.004524886877828055). SV: 116/145 (0.8). Mean e: 0.0084. Median e: 0.0005. Std e: 0.4751. \n",
      "18 - Kernels: 1/442 (0.0022624434389140274). SV: 145/146 (0.9931506849315068). Mean e: 0.0046. Median e: 0.0006. Std e: 0.0844. \n",
      "19 - Kernels: 1/442 (0.0022624434389140274). SV: 143/146 (0.9794520547945206). Mean e: 0.0073. Median e: 0.0005. Std e: 0.1284. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([6.4306, 6.3294, 6.283 , 6.2944, 6.1326, 6.2388, 6.5526, 6.3465, 6.2336, 6.3462, 6.2089,\n",
       "         6.4385, 6.3119, 6.2683, 6.2977, 6.6148, 6.5269, 6.3812, 6.4009, 6.383 ]),\n",
       "  'score_time': array([0.4836, 0.4679, 0.4689, 0.4751, 0.4771, 0.5567, 0.464 , 0.4628, 0.4651, 0.4671, 0.4697,\n",
       "         0.4632, 0.4711, 0.4812, 0.4674, 0.4696, 0.4868, 0.4645, 0.4765, 0.4809]),\n",
       "  'test_score': array([0.7551, 0.7551, 0.8333, 0.75  , 0.7959, 0.7959, 0.75  , 0.7292, 0.7755, 0.7551, 0.75  ,\n",
       "         0.7917, 0.7347, 0.7755, 0.7917, 0.7292, 0.8163, 0.7959, 0.75  , 0.7083]),\n",
       "  'train_score': array([0.8069, 0.7655, 0.7671, 0.7945, 0.7724, 0.8138, 0.7808, 0.7877, 0.7724, 0.7931, 0.7808,\n",
       "         0.774 , 0.7931, 0.7655, 0.7945, 0.7945, 0.7517, 0.7793, 0.7808, 0.8082])},\n",
       " [{'elapsed_time': 6.150483131408691,\n",
       "   'nr_kernels_used': 1,\n",
       "   'nr_sv_used': 141,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.040616989135742,\n",
       "   'nr_kernels_used': 1,\n",
       "   'nr_sv_used': 140,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 5.98814582824707,\n",
       "   'nr_kernels_used': 2,\n",
       "   'nr_sv_used': 131,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 5.998875856399536,\n",
       "   'nr_kernels_used': 1,\n",
       "   'nr_sv_used': 118,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 5.842489242553711,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 139,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 5.9241783618927,\n",
       "   'nr_kernels_used': 1,\n",
       "   'nr_sv_used': 128,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.245795249938965,\n",
       "   'nr_kernels_used': 2,\n",
       "   'nr_sv_used': 127,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.045584440231323,\n",
       "   'nr_kernels_used': 1,\n",
       "   'nr_sv_used': 139,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 5.942713260650635,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 127,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.0586466789245605,\n",
       "   'nr_kernels_used': 1,\n",
       "   'nr_sv_used': 134,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 5.9175636768341064,\n",
       "   'nr_kernels_used': 1,\n",
       "   'nr_sv_used': 145,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.1179585456848145,\n",
       "   'nr_kernels_used': 2,\n",
       "   'nr_sv_used': 141,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.021216869354248,\n",
       "   'nr_kernels_used': 1,\n",
       "   'nr_sv_used': 134,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 5.979412078857422,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 137,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 5.980578184127808,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 141,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.316793203353882,\n",
       "   'nr_kernels_used': 1,\n",
       "   'nr_sv_used': 128,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.234901666641235,\n",
       "   'nr_kernels_used': 2,\n",
       "   'nr_sv_used': 128,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.088092088699341,\n",
       "   'nr_kernels_used': 2,\n",
       "   'nr_sv_used': 116,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.102879524230957,\n",
       "   'nr_kernels_used': 1,\n",
       "   'nr_sv_used': 145,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.080373287200928,\n",
       "   'nr_kernels_used': 1,\n",
       "   'nr_sv_used': 143,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146}])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "ksparse_model = BEMKL(kernels=kernels, hyp_lambda_alpha=1, hyp_lambda_beta=1,\n",
    "                      hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                      hyp_omega_alpha=1e-11, hyp_omega_beta=1e9,\n",
    "                      e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                      filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                      max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "ksparse_pipeline = make_pipeline(Normalizer(), ksparse_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "ksparse_cv_results = cross_validate(ksparse_pipeline, X, y, cv=folds, scoring=scoring)\n",
    "ksparse_stats = deepcopy(scoring.stats)\n",
    "ksparse_cv_results, ksparse_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.766921768707483 +- 0.03133090895784486\n",
      "Time: 6.053864908218384 +- 0.11586270656791635\n",
      "Kernels: 1.65 +- 0.792148975887743\n",
      "SVs: 134.1 +- 8.245604889879214\n"
     ]
    }
   ],
   "source": [
    "ksparse_times = np.array([s['elapsed_time'] for s in ksparse_stats])\n",
    "ksparse_kernels = np.array([s['nr_kernels_used'] for s in ksparse_stats])\n",
    "ksparse_sv = np.array([s['nr_sv_used'] for s in ksparse_stats])\n",
    "print(\n",
    "    f\"Score: {ksparse_cv_results['test_score'].mean()} +- {ksparse_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {ksparse_times.mean()} +- {ksparse_times.std()}\\n\"\n",
    "    f\"Kernels: {ksparse_kernels.mean()} +- {ksparse_kernels.std()}\\n\"\n",
    "    f\"SVs: {ksparse_sv.mean()} +- {ksparse_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV-sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 442/442 (1.0). SV: 127/145 (0.8758620689655172). Mean e: 0.0104. Median e: -0.0280. Std e: 0.0845. \n",
      "1 - Kernels: 102/442 (0.23076923076923078). SV: 74/145 (0.5103448275862069). Mean e: 0.0198. Median e: -0.0021. Std e: 0.0683. \n",
      "2 - Kernels: 102/442 (0.23076923076923078). SV: 54/146 (0.3698630136986301). Mean e: 0.0147. Median e: -0.0078. Std e: 0.0616. \n",
      "3 - Kernels: 442/442 (1.0). SV: 130/146 (0.8904109589041096). Mean e: 0.0160. Median e: -0.0172. Std e: 0.0720. \n",
      "4 - Kernels: 432/442 (0.9773755656108597). SV: 54/145 (0.3724137931034483). Mean e: 0.0155. Median e: -0.0174. Std e: 0.0722. \n",
      "5 - Kernels: 442/442 (1.0). SV: 116/145 (0.8). Mean e: 0.0165. Median e: -0.0212. Std e: 0.0778. \n",
      "6 - Kernels: 442/442 (1.0). SV: 79/146 (0.541095890410959). Mean e: 0.0128. Median e: -0.0257. Std e: 0.0822. \n",
      "7 - Kernels: 102/442 (0.23076923076923078). SV: 102/146 (0.6986301369863014). Mean e: 0.0150. Median e: -0.0099. Std e: 0.0670. \n",
      "8 - Kernels: 102/442 (0.23076923076923078). SV: 52/145 (0.3586206896551724). Mean e: 0.0163. Median e: -0.0030. Std e: 0.0717. \n",
      "9 - Kernels: 102/442 (0.23076923076923078). SV: 46/145 (0.31724137931034485). Mean e: 0.0155. Median e: -0.0061. Std e: 0.0567. \n",
      "10 - Kernels: 102/442 (0.23076923076923078). SV: 42/146 (0.2876712328767123). Mean e: 0.0167. Median e: -0.0005. Std e: 0.0657. \n",
      "11 - Kernels: 442/442 (1.0). SV: 97/146 (0.6643835616438356). Mean e: 0.0125. Median e: -0.0213. Std e: 0.0742. \n",
      "12 - Kernels: 432/442 (0.9773755656108597). SV: 59/145 (0.4068965517241379). Mean e: 0.0165. Median e: -0.0166. Std e: 0.0711. \n",
      "13 - Kernels: 432/442 (0.9773755656108597). SV: 115/145 (0.7931034482758621). Mean e: 0.0154. Median e: -0.0145. Std e: 0.0657. \n",
      "14 - Kernels: 102/442 (0.23076923076923078). SV: 103/146 (0.7054794520547946). Mean e: 0.0141. Median e: -0.0099. Std e: 0.0624. \n",
      "15 - Kernels: 102/442 (0.23076923076923078). SV: 94/146 (0.6438356164383562). Mean e: 0.0151. Median e: -0.0068. Std e: 0.0629. \n",
      "16 - Kernels: 112/442 (0.25339366515837103). SV: 50/145 (0.3448275862068966). Mean e: 0.0204. Median e: 0.0031. Std e: 0.0688. \n",
      "17 - Kernels: 112/442 (0.25339366515837103). SV: 46/145 (0.31724137931034485). Mean e: 0.0155. Median e: 0.0025. Std e: 0.0550. \n",
      "18 - Kernels: 432/442 (0.9773755656108597). SV: 99/146 (0.678082191780822). Mean e: 0.0128. Median e: -0.0120. Std e: 0.0568. \n",
      "19 - Kernels: 102/442 (0.23076923076923078). SV: 122/146 (0.8356164383561644). Mean e: 0.0142. Median e: -0.0085. Std e: 0.0640. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([6.4598, 6.8024, 6.7456, 6.5401, 6.3233, 6.6127, 6.379 , 6.3001, 6.4754, 6.347 , 6.4128,\n",
       "         6.5809, 6.5175, 6.5831, 6.3101, 6.4769, 7.0766, 6.5673, 6.4769, 6.4364]),\n",
       "  'score_time': array([0.4622, 0.4639, 0.4713, 0.4614, 0.4641, 0.4652, 0.4625, 0.4659, 0.474 , 0.4719, 0.4838,\n",
       "         0.4766, 0.4683, 0.4797, 0.4826, 0.469 , 0.4756, 0.4674, 0.4841, 0.4602]),\n",
       "  'test_score': array([0.7551, 0.7755, 0.7917, 0.75  , 0.7959, 0.7143, 0.7917, 0.75  , 0.7551, 0.7755, 0.7708,\n",
       "         0.7083, 0.7551, 0.7755, 0.7917, 0.8125, 0.7755, 0.7551, 0.75  , 0.75  ]),\n",
       "  'train_score': array([0.8207, 0.7862, 0.7671, 0.7877, 0.7793, 0.7862, 0.7808, 0.8082, 0.7862, 0.7793, 0.8014,\n",
       "         0.7808, 0.7862, 0.7724, 0.7603, 0.7808, 0.8138, 0.7724, 0.7877, 0.774 ])},\n",
       " [{'elapsed_time': 6.168569326400757,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 127,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.51063084602356,\n",
       "   'nr_kernels_used': 102,\n",
       "   'nr_sv_used': 74,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.445582628250122,\n",
       "   'nr_kernels_used': 102,\n",
       "   'nr_sv_used': 54,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.246416091918945,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 130,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.026396989822388,\n",
       "   'nr_kernels_used': 432,\n",
       "   'nr_sv_used': 54,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.322415113449097,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 116,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.086711406707764,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 79,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.0048980712890625,\n",
       "   'nr_kernels_used': 102,\n",
       "   'nr_sv_used': 102,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.1773154735565186,\n",
       "   'nr_kernels_used': 102,\n",
       "   'nr_sv_used': 52,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.05074405670166,\n",
       "   'nr_kernels_used': 102,\n",
       "   'nr_sv_used': 46,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.111309766769409,\n",
       "   'nr_kernels_used': 102,\n",
       "   'nr_sv_used': 42,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.2871928215026855,\n",
       "   'nr_kernels_used': 442,\n",
       "   'nr_sv_used': 97,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.221140384674072,\n",
       "   'nr_kernels_used': 432,\n",
       "   'nr_sv_used': 59,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.291700124740601,\n",
       "   'nr_kernels_used': 432,\n",
       "   'nr_sv_used': 115,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.007657051086426,\n",
       "   'nr_kernels_used': 102,\n",
       "   'nr_sv_used': 103,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.18068265914917,\n",
       "   'nr_kernels_used': 102,\n",
       "   'nr_sv_used': 94,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.784640789031982,\n",
       "   'nr_kernels_used': 112,\n",
       "   'nr_sv_used': 50,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.275846242904663,\n",
       "   'nr_kernels_used': 112,\n",
       "   'nr_sv_used': 46,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 145},\n",
       "  {'elapsed_time': 6.176268100738525,\n",
       "   'nr_kernels_used': 432,\n",
       "   'nr_sv_used': 99,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146},\n",
       "  {'elapsed_time': 6.139043569564819,\n",
       "   'nr_kernels_used': 102,\n",
       "   'nr_sv_used': 122,\n",
       "   'total_kernels': 442,\n",
       "   'total_sv': 146}])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "ssparse_model = BEMKL(kernels=kernels,\n",
    "                      hyp_lambda_alpha=1e-11, hyp_lambda_beta=1e9,\n",
    "                      hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                      hyp_omega_alpha=1, hyp_omega_beta=1,\n",
    "                      e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                      filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                      max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "ssparse_pipeline = make_pipeline(Normalizer(), ssparse_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "ssparse_cv_results = cross_validate(ssparse_pipeline, X, y, cv=folds, scoring=scoring)\n",
    "ssparse_stats = deepcopy(scoring.stats)\n",
    "ssparse_cv_results, ssparse_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7649659863945578 +- 0.025393226697273525\n",
      "Time: 6.225758075714111 +- 0.1842578786641781\n",
      "Kernels: 254.0 +- 166.0903368652132\n",
      "SVs: 83.05 +- 29.9474122421287\n"
     ]
    }
   ],
   "source": [
    "ssparse_times = np.array([s['elapsed_time'] for s in ssparse_stats])\n",
    "ssparse_kernels = np.array([s['nr_kernels_used'] for s in ssparse_stats])\n",
    "ssparse_sv = np.array([s['nr_sv_used'] for s in ssparse_stats])\n",
    "print(\n",
    "    f\"Score: {ssparse_cv_results['test_score'].mean()} +- {ssparse_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {ssparse_times.mean()} +- {ssparse_times.std()}\\n\"\n",
    "    f\"Kernels: {ssparse_kernels.mean()} +- {ssparse_kernels.std()}\\n\"\n",
    "    f\"SVs: {ssparse_sv.mean()} +- {ssparse_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('wpbc_results.json', 'w') as fp:\n",
    "    json.dump(\n",
    "        {\n",
    "            'ksparse': {\n",
    "                'scores': list(ksparse_cv_results['test_score']),\n",
    "                'times': list(ksparse_times),\n",
    "                'kernels': [int(k) for k in ksparse_kernels],\n",
    "                'svs': [int(s) for s in ksparse_sv],\n",
    "            },\n",
    "            'ssparse': {\n",
    "                'scores': list(ssparse_cv_results['test_score']),\n",
    "                'times': list(ssparse_times),\n",
    "                'kernels': [int(k) for k in ksparse_kernels],\n",
    "                'svs': [int(s) for s in ssparse_sv],\n",
    "            },\n",
    "            'base': {\n",
    "                'scores': list(base_cv_results['test_score']),\n",
    "                'times': list(base_times),\n",
    "                'kernels': [int(k) for k in base_kernels],\n",
    "                'svs': [int(s) for s in base_sv],\n",
    "            },\n",
    "            'total_kernels': len(kernels),\n",
    "            'total_sv': len(X_train),\n",
    "        },\n",
    "        fp,\n",
    "        indent=4,\n",
    "        sort_keys=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml",
   "language": "python",
   "name": "pml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
