{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.io import savemat, loadmat\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (log_loss, mean_squared_error, roc_curve, auc,\n",
    "                             precision_recall_fscore_support, confusion_matrix)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from tqdm import tqdm, trange, tqdm_notebook as tqdmn\n",
    "\n",
    "from BEKML import BEMKL, plot_distplot\n",
    "from utils import poly_kernel, gauss_kernel, scoring, plot_kernel_importances, plot_compare_models\n",
    "\n",
    "sns.set(style='ticks', context='talk')\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2      3       4       5        6        7       8        9   \\\n",
       "0                                                                              \n",
       "842302    M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710   \n",
       "842517    M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017   \n",
       "84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790   \n",
       "84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520   \n",
       "84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430   \n",
       "\n",
       "              10   ...        22     23      24      25      26      27  \\\n",
       "0                  ...                                                    \n",
       "842302    0.2419   ...     25.38  17.33  184.60  2019.0  0.1622  0.6656   \n",
       "842517    0.1812   ...     24.99  23.41  158.80  1956.0  0.1238  0.1866   \n",
       "84300903  0.2069   ...     23.57  25.53  152.50  1709.0  0.1444  0.4245   \n",
       "84348301  0.2597   ...     14.91  26.50   98.87   567.7  0.2098  0.8663   \n",
       "84358402  0.1809   ...     22.54  16.67  152.20  1575.0  0.1374  0.2050   \n",
       "\n",
       "              28      29      30       31  \n",
       "0                                          \n",
       "842302    0.7119  0.2654  0.4601  0.11890  \n",
       "842517    0.2416  0.1860  0.2750  0.08902  \n",
       "84300903  0.4504  0.2430  0.3613  0.08758  \n",
       "84348301  0.6869  0.2575  0.6638  0.17300  \n",
       "84358402  0.4000  0.1625  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               2           3           4            5           6   \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    14.127292   19.289649   91.969033   654.889104    0.096360   \n",
       "std      3.524049    4.301036   24.298981   351.914129    0.014064   \n",
       "min      6.981000    9.710000   43.790000   143.500000    0.052630   \n",
       "25%     11.700000   16.170000   75.170000   420.300000    0.086370   \n",
       "50%     13.370000   18.840000   86.240000   551.100000    0.095870   \n",
       "75%     15.780000   21.800000  104.100000   782.700000    0.105300   \n",
       "max     28.110000   39.280000  188.500000  2501.000000    0.163400   \n",
       "\n",
       "               7           8           9           10          11     ...      \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000     ...       \n",
       "mean     0.104341    0.088799    0.048919    0.181162    0.062798     ...       \n",
       "std      0.052813    0.079720    0.038803    0.027414    0.007060     ...       \n",
       "min      0.019380    0.000000    0.000000    0.106000    0.049960     ...       \n",
       "25%      0.064920    0.029560    0.020310    0.161900    0.057700     ...       \n",
       "50%      0.092630    0.061540    0.033500    0.179200    0.061540     ...       \n",
       "75%      0.130400    0.130700    0.074000    0.195700    0.066120     ...       \n",
       "max      0.345400    0.426800    0.201200    0.304000    0.097440     ...       \n",
       "\n",
       "               22          23          24           25          26  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
       "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
       "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
       "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
       "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
       "\n",
       "               27          28          29          30          31  \n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
       "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
       "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
       "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
       "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/wdbc.csv', names=list(range(32)), index_col=0)\n",
    "display(data.head())\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.2548330404217926"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data.iloc[:, 1:].copy()\n",
    "y = data.iloc[:, 0].copy()\n",
    "N, D = X.shape\n",
    "y.loc[y == 'B'] = -1\n",
    "y.loc[y == 'M'] = 1\n",
    "y = y.astype(int)\n",
    "display(X.shape, y.shape, y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             2      3       4       5        6        7       8        9   \\\n",
       "0                                                                           \n",
       "842302    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710   \n",
       "842517    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017   \n",
       "84300903  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790   \n",
       "84348301  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520   \n",
       "84358402  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430   \n",
       "\n",
       "              10       11 ...     23      24      25      26      27      28  \\\n",
       "0                         ...                                                  \n",
       "842302    0.2419  0.07871 ...  17.33  184.60  2019.0  0.1622  0.6656  0.7119   \n",
       "842517    0.1812  0.05667 ...  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
       "84300903  0.2069  0.05999 ...  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
       "84348301  0.2597  0.09744 ...  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
       "84358402  0.1809  0.05883 ...  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
       "\n",
       "              29      30       31  1   \n",
       "0                                      \n",
       "842302    0.2654  0.4601  0.11890   1  \n",
       "842517    0.1860  0.2750  0.08902   1  \n",
       "84300903  0.2430  0.3613  0.08758   1  \n",
       "84348301  0.2575  0.6638  0.17300   1  \n",
       "84358402  0.1625  0.2364  0.07678   1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_data = data.copy()\n",
    "proc_data.iloc[:, 0] = y\n",
    "proc_data = proc_data.loc[:, list(proc_data.columns[1:]) + [proc_data.columns[0]]]\n",
    "proc_data.to_csv('data/proc_wdbc.csv')\n",
    "proc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 403)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_init, rbf_end = -3, 7\n",
    "ply_init, ply_end = 1, 4\n",
    "\n",
    "kernel_attrs = [('rbf', 'all', i) for i in range(rbf_init, rbf_end)]\n",
    "kernels = [lambda A, B: gauss_kernel(A, B, 2**i)\n",
    "           for i in range(rbf_init, rbf_end)]\n",
    "\n",
    "kernel_attrs += [('poly', 'all', i) for i in range(ply_init, ply_end)]\n",
    "kernels += [lambda A, B: poly_kernel(A, B, 1, i)\n",
    "            for i in range(ply_init, ply_end)]\n",
    "\n",
    "kernel_attrs += [('rbf', j, i) for i in range(rbf_init, rbf_end)\n",
    "                 for j in range(D)]\n",
    "kernels += [lambda A, B: gauss_kernel(A[:, j:j+1], B[:, j:j+1], 2**i)\n",
    "            for i in range(rbf_init, rbf_end) for j in range(D)]\n",
    "\n",
    "kernel_attrs += [('poly', j, i) for i in range(ply_init, ply_end)\n",
    "                 for j in range(D)]\n",
    "kernels += [lambda A, B: poly_kernel(A[:, j:j+1], B[:, j:j+1], 1, i)\n",
    "            for i in range(ply_init, ply_end) for j in range(D)]\n",
    "len(kernels), len(kernel_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =\\\n",
    "        train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 13/403 (0.03225806451612903). SV: 379/426 (0.8896713615023474). Mean e: 0.0163. Median e: 0.0088. Std e: 0.0819. \n",
      "1 - Kernels: 13/403 (0.03225806451612903). SV: 420/427 (0.9836065573770492). Mean e: 0.0150. Median e: 0.0077. Std e: 0.0790. \n",
      "2 - Kernels: 13/403 (0.03225806451612903). SV: 377/427 (0.882903981264637). Mean e: 0.0125. Median e: 0.0057. Std e: 0.0738. \n",
      "3 - Kernels: 13/403 (0.03225806451612903). SV: 389/427 (0.9110070257611241). Mean e: 0.0136. Median e: 0.0066. Std e: 0.0772. \n",
      "4 - Kernels: 13/403 (0.03225806451612903). SV: 406/426 (0.9530516431924883). Mean e: 0.0144. Median e: 0.0071. Std e: 0.0798. \n",
      "5 - Kernels: 13/403 (0.03225806451612903). SV: 361/427 (0.8454332552693209). Mean e: 0.0145. Median e: 0.0076. Std e: 0.0750. \n",
      "6 - Kernels: 13/403 (0.03225806451612903). SV: 416/427 (0.9742388758782201). Mean e: 0.0127. Median e: 0.0049. Std e: 0.0847. \n",
      "7 - Kernels: 13/403 (0.03225806451612903). SV: 374/427 (0.8758782201405152). Mean e: 0.0145. Median e: 0.0076. Std e: 0.0749. \n",
      "8 - Kernels: 13/403 (0.03225806451612903). SV: 369/426 (0.8661971830985915). Mean e: 0.0136. Median e: 0.0065. Std e: 0.0779. \n",
      "9 - Kernels: 13/403 (0.03225806451612903). SV: 419/427 (0.9812646370023419). Mean e: 0.0146. Median e: 0.0076. Std e: 0.0767. \n",
      "10 - Kernels: 13/403 (0.03225806451612903). SV: 383/427 (0.8969555035128806). Mean e: 0.0156. Median e: 0.0083. Std e: 0.0792. \n",
      "11 - Kernels: 13/403 (0.03225806451612903). SV: 393/427 (0.9203747072599532). Mean e: 0.0159. Median e: 0.0087. Std e: 0.0786. \n",
      "12 - Kernels: 13/403 (0.03225806451612903). SV: 393/426 (0.9225352112676056). Mean e: 0.0144. Median e: 0.0074. Std e: 0.0764. \n",
      "13 - Kernels: 13/403 (0.03225806451612903). SV: 386/427 (0.9039812646370023). Mean e: 0.0155. Median e: 0.0082. Std e: 0.0799. \n",
      "14 - Kernels: 13/403 (0.03225806451612903). SV: 383/427 (0.8969555035128806). Mean e: 0.0134. Median e: 0.0063. Std e: 0.0778. \n",
      "15 - Kernels: 13/403 (0.03225806451612903). SV: 320/427 (0.7494145199063232). Mean e: 0.0139. Median e: 0.0070. Std e: 0.0757. \n",
      "16 - Kernels: 13/403 (0.03225806451612903). SV: 359/426 (0.8427230046948356). Mean e: 0.0155. Median e: 0.0084. Std e: 0.0769. \n",
      "17 - Kernels: 13/403 (0.03225806451612903). SV: 371/427 (0.8688524590163934). Mean e: 0.0155. Median e: 0.0080. Std e: 0.0818. \n",
      "18 - Kernels: 13/403 (0.03225806451612903). SV: 337/427 (0.7892271662763466). Mean e: 0.0136. Median e: 0.0065. Std e: 0.0780. \n",
      "19 - Kernels: 13/403 (0.03225806451612903). SV: 373/427 (0.8735362997658079). Mean e: 0.0139. Median e: 0.0072. Std e: 0.0727. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([23.5434, 24.3743, 25.6749, 22.9158, 22.8114, 23.1622, 23.5647, 23.0302, 23.1108, 22.9726,\n",
       "         23.8407, 23.2623, 23.1117, 23.8848, 23.6176, 23.0503, 22.8715, 23.6353, 26.4198, 22.7334]),\n",
       "  'score_time': array([4.6688, 4.3916, 4.2891, 4.2866, 4.2724, 4.2657, 4.3258, 4.2519, 4.4902, 4.3054, 4.7011,\n",
       "         4.3482, 4.3192, 4.3132, 4.3267, 4.3079, 4.2729, 4.4355, 4.2855, 4.3507]),\n",
       "  'test_score': array([0.9091, 0.9014, 0.9225, 0.9296, 0.9371, 0.9155, 0.9155, 0.9155, 0.9161, 0.8944, 0.9014,\n",
       "         0.9437, 0.951 , 0.9085, 0.9014, 0.9085, 0.9021, 0.8944, 0.9366, 0.9437]),\n",
       "  'train_score': array([0.9272, 0.9274, 0.9157, 0.918 , 0.9178, 0.9227, 0.9274, 0.9227, 0.9225, 0.9251, 0.9274,\n",
       "         0.904 , 0.9085, 0.9251, 0.9274, 0.9204, 0.9296, 0.9274, 0.9157, 0.9133])},\n",
       " [{'elapsed_time': 21.027663230895996,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 379,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 21.921558380126953,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 420,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 23.245291233062744,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 377,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.45836877822876,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 389,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.353114366531372,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 406,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.713799476623535,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 361,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 21.113776922225952,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 416,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.554515838623047,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 374,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.659239292144775,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 369,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.478779315948486,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 419,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 21.341302394866943,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 383,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.767874002456665,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 393,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.64832878112793,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 393,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 21.418809175491333,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 386,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 21.14409351348877,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 383,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.55959701538086,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 320,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.41911816596985,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 359,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 21.2128164768219,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 371,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 23.917829990386963,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 337,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.295687675476074,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 373,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "base_model = BEMKL(kernels=kernels, hyp_lambda_alpha=1, hyp_lambda_beta=1,\n",
    "                   hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                   hyp_omega_alpha=1, hyp_omega_beta=1,\n",
    "                   e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                   filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                   max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "base_model = make_pipeline(Normalizer(), base_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "base_cv_results = cross_validate(base_model, X, y, cv=folds, scoring=scoring)\n",
    "base_stats = deepcopy(scoring.stats)\n",
    "base_cv_results, base_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9173889490790899 +- 0.016950870305825923\n",
      "Time: 21.112578201293946 +- 0.9248643330677546\n",
      "Kernels: 13.0 +- 0.0\n",
      "SVs: 380.4 +- 24.607722365143832\n"
     ]
    }
   ],
   "source": [
    "base_times = np.array([s['elapsed_time'] for s in base_stats])\n",
    "base_kernels = np.array([s['nr_kernels_used'] for s in base_stats])\n",
    "base_sv = np.array([s['nr_sv_used'] for s in base_stats])\n",
    "print(\n",
    "    f\"Score: {base_cv_results['test_score'].mean()} +- {base_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {base_times.mean()} +- {base_times.std()}\\n\"\n",
    "    f\"Kernels: {base_kernels.mean()} +- {base_kernels.std()}\\n\"\n",
    "    f\"SVs: {base_sv.mean()} +- {base_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel-sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 3/403 (0.007444168734491315). SV: 375/426 (0.8802816901408451). Mean e: 0.0068. Median e: 0.0001. Std e: 0.0774. \n",
      "1 - Kernels: 3/403 (0.007444168734491315). SV: 344/427 (0.8056206088992974). Mean e: 0.0064. Median e: 0.0001. Std e: 0.0730. \n",
      "2 - Kernels: 3/403 (0.007444168734491315). SV: 294/427 (0.6885245901639344). Mean e: 0.0069. Median e: 0.0001. Std e: 0.0793. \n",
      "3 - Kernels: 3/403 (0.007444168734491315). SV: 340/427 (0.7962529274004684). Mean e: 0.0073. Median e: 0.0001. Std e: 0.0837. \n",
      "4 - Kernels: 3/403 (0.007444168734491315). SV: 375/426 (0.8802816901408451). Mean e: 0.0071. Median e: 0.0001. Std e: 0.0811. \n",
      "5 - Kernels: 3/403 (0.007444168734491315). SV: 352/427 (0.8243559718969555). Mean e: 0.0069. Median e: 0.0001. Std e: 0.0792. \n",
      "6 - Kernels: 3/403 (0.007444168734491315). SV: 329/427 (0.7704918032786885). Mean e: 0.0065. Median e: 0.0001. Std e: 0.0742. \n",
      "7 - Kernels: 3/403 (0.007444168734491315). SV: 414/427 (0.9695550351288056). Mean e: 0.0069. Median e: 0.0001. Std e: 0.0788. \n",
      "8 - Kernels: 3/403 (0.007444168734491315). SV: 321/426 (0.7535211267605634). Mean e: 0.0075. Median e: 0.0001. Std e: 0.0857. \n",
      "9 - Kernels: 3/403 (0.007444168734491315). SV: 391/427 (0.9156908665105387). Mean e: 0.0069. Median e: 0.0001. Std e: 0.0787. \n",
      "10 - Kernels: 3/403 (0.007444168734491315). SV: 341/427 (0.7985948477751756). Mean e: 0.0067. Median e: 0.0001. Std e: 0.0764. \n",
      "11 - Kernels: 3/403 (0.007444168734491315). SV: 353/427 (0.8266978922716628). Mean e: 0.0069. Median e: 0.0001. Std e: 0.0787. \n",
      "12 - Kernels: 3/403 (0.007444168734491315). SV: 304/426 (0.7136150234741784). Mean e: 0.0068. Median e: 0.0001. Std e: 0.0776. \n",
      "13 - Kernels: 3/403 (0.007444168734491315). SV: 307/427 (0.7189695550351288). Mean e: 0.0065. Median e: 0.0001. Std e: 0.0740. \n",
      "14 - Kernels: 3/403 (0.007444168734491315). SV: 391/427 (0.9156908665105387). Mean e: 0.0068. Median e: 0.0001. Std e: 0.0773. \n",
      "15 - Kernels: 3/403 (0.007444168734491315). SV: 351/427 (0.8220140515222483). Mean e: 0.0075. Median e: 0.0001. Std e: 0.0860. \n",
      "16 - Kernels: 3/403 (0.007444168734491315). SV: 326/426 (0.7652582159624414). Mean e: 0.0070. Median e: 0.0001. Std e: 0.0799. \n",
      "17 - Kernels: 3/403 (0.007444168734491315). SV: 371/427 (0.8688524590163934). Mean e: 0.0065. Median e: 0.0001. Std e: 0.0738. \n",
      "18 - Kernels: 3/403 (0.007444168734491315). SV: 333/427 (0.7798594847775175). Mean e: 0.0071. Median e: 0.0001. Std e: 0.0808. \n",
      "19 - Kernels: 3/403 (0.007444168734491315). SV: 412/427 (0.9648711943793911). Mean e: 0.0068. Median e: 0.0001. Std e: 0.0777. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([31.8894, 27.2667, 23.2289, 22.9908, 22.9379, 23.9261, 23.3843, 23.48  , 22.7919, 22.8237,\n",
       "         23.0361, 22.7708, 24.0527, 23.2313, 22.8116, 22.8613, 23.1158, 22.9194, 22.7761, 23.2873]),\n",
       "  'score_time': array([4.7327, 4.248 , 4.4103, 4.4189, 4.3075, 4.3359, 4.3122, 4.3113, 4.2577, 4.3865, 4.2484,\n",
       "         4.3767, 4.4139, 4.2854, 4.3969, 4.2681, 4.2867, 4.2564, 4.2725, 4.2994]),\n",
       "  'test_score': array([0.9091, 0.9296, 0.9437, 0.9085, 0.9091, 0.9155, 0.9437, 0.9014, 0.9021, 0.9296, 0.9085,\n",
       "         0.9437, 0.9231, 0.9437, 0.9296, 0.9014, 0.8951, 0.9507, 0.9014, 0.9225]),\n",
       "  'train_score': array([0.9249, 0.918 , 0.9087, 0.9297, 0.9225, 0.9251, 0.911 , 0.9321, 0.9296, 0.9204, 0.9251,\n",
       "         0.9157, 0.9202, 0.9157, 0.918 , 0.9274, 0.9272, 0.911 , 0.9274, 0.9227])},\n",
       " [{'elapsed_time': 29.457967281341553,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 375,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 24.782368183135986,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 344,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.77387237548828,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 294,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.526841640472412,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 340,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.432697534561157,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 375,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 21.473310232162476,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 352,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.933004140853882,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 329,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 21.000191926956177,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 414,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.302558660507202,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 321,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.362311124801636,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 391,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.503437519073486,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 341,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.287493228912354,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 353,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 21.639296531677246,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 304,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.76130199432373,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 307,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.35774326324463,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 391,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.39124870300293,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 351,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.642087697982788,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 326,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.434491395950317,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 371,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.331098079681396,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 333,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.846060514450073,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 412,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "ksparse_model = BEMKL(kernels=kernels, hyp_lambda_alpha=1, hyp_lambda_beta=1,\n",
    "                      hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                      hyp_omega_alpha=1e-11, hyp_omega_beta=1e9,\n",
    "                      e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                      filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                      max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "ksparse_pipeline = make_pipeline(Normalizer(), ksparse_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "ksparse_cv_results = cross_validate(ksparse_pipeline, X, y, cv=folds, scoring=scoring)\n",
    "ksparse_stats = deepcopy(scoring.stats)\n",
    "ksparse_cv_results, ksparse_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9205850487540627 +- 0.01727545744937103\n",
      "Time: 21.311969101428986 +- 2.1040136595700645\n",
      "Kernels: 3.0 +- 0.0\n",
      "SVs: 351.2 +- 33.49865668948532\n"
     ]
    }
   ],
   "source": [
    "ksparse_times = np.array([s['elapsed_time'] for s in ksparse_stats])\n",
    "ksparse_kernels = np.array([s['nr_kernels_used'] for s in ksparse_stats])\n",
    "ksparse_sv = np.array([s['nr_sv_used'] for s in ksparse_stats])\n",
    "print(\n",
    "    f\"Score: {ksparse_cv_results['test_score'].mean()} +- {ksparse_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {ksparse_times.mean()} +- {ksparse_times.std()}\\n\"\n",
    "    f\"Kernels: {ksparse_kernels.mean()} +- {ksparse_kernels.std()}\\n\"\n",
    "    f\"SVs: {ksparse_sv.mean()} +- {ksparse_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV-sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 13/403 (0.03225806451612903). SV: 323/426 (0.7582159624413145). Mean e: 0.0133. Median e: 0.0064. Std e: 0.0750. \n",
      "1 - Kernels: 13/403 (0.03225806451612903). SV: 348/427 (0.8149882903981265). Mean e: 0.0151. Median e: 0.0080. Std e: 0.0773. \n",
      "2 - Kernels: 13/403 (0.03225806451612903). SV: 333/427 (0.7798594847775175). Mean e: 0.0139. Median e: 0.0063. Std e: 0.0833. \n",
      "3 - Kernels: 13/403 (0.03225806451612903). SV: 332/427 (0.7775175644028103). Mean e: 0.0173. Median e: 0.0098. Std e: 0.0815. \n",
      "4 - Kernels: 13/403 (0.03225806451612903). SV: 342/426 (0.8028169014084507). Mean e: 0.0142. Median e: 0.0067. Std e: 0.0813. \n",
      "5 - Kernels: 13/403 (0.03225806451612903). SV: 371/427 (0.8688524590163934). Mean e: 0.0147. Median e: 0.0076. Std e: 0.0780. \n",
      "6 - Kernels: 13/403 (0.03225806451612903). SV: 361/427 (0.8454332552693209). Mean e: 0.0147. Median e: 0.0072. Std e: 0.0813. \n",
      "7 - Kernels: 13/403 (0.03225806451612903). SV: 308/427 (0.7213114754098361). Mean e: 0.0152. Median e: 0.0080. Std e: 0.0785. \n",
      "8 - Kernels: 13/403 (0.03225806451612903). SV: 273/426 (0.6408450704225352). Mean e: 0.0141. Median e: 0.0066. Std e: 0.0821. \n",
      "9 - Kernels: 13/403 (0.03225806451612903). SV: 358/427 (0.8384074941451991). Mean e: 0.0126. Median e: 0.0055. Std e: 0.0770. \n",
      "10 - Kernels: 13/403 (0.03225806451612903). SV: 362/427 (0.8477751756440282). Mean e: 0.0164. Median e: 0.0089. Std e: 0.0820. \n",
      "11 - Kernels: 13/403 (0.03225806451612903). SV: 296/427 (0.6932084309133489). Mean e: 0.0161. Median e: 0.0091. Std e: 0.0774. \n",
      "12 - Kernels: 13/403 (0.03225806451612903). SV: 360/426 (0.8450704225352113). Mean e: 0.0156. Median e: 0.0084. Std e: 0.0796. \n",
      "13 - Kernels: 13/403 (0.03225806451612903). SV: 322/427 (0.7540983606557377). Mean e: 0.0146. Median e: 0.0069. Std e: 0.0836. \n",
      "14 - Kernels: 13/403 (0.03225806451612903). SV: 386/427 (0.9039812646370023). Mean e: 0.0145. Median e: 0.0074. Std e: 0.0771. \n",
      "15 - Kernels: 13/403 (0.03225806451612903). SV: 360/427 (0.8430913348946136). Mean e: 0.0143. Median e: 0.0070. Std e: 0.0795. \n",
      "16 - Kernels: 13/403 (0.03225806451612903). SV: 339/426 (0.795774647887324). Mean e: 0.0139. Median e: 0.0069. Std e: 0.0769. \n",
      "17 - Kernels: 13/403 (0.03225806451612903). SV: 353/427 (0.8266978922716628). Mean e: 0.0150. Median e: 0.0077. Std e: 0.0802. \n",
      "18 - Kernels: 13/403 (0.03225806451612903). SV: 317/427 (0.7423887587822015). Mean e: 0.0164. Median e: 0.0087. Std e: 0.0839. \n",
      "19 - Kernels: 13/403 (0.03225806451612903). SV: 322/427 (0.7540983606557377). Mean e: 0.0142. Median e: 0.0070. Std e: 0.0790. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([22.9817, 22.7917, 22.9075, 22.82  , 22.8179, 22.9772, 23.0265, 23.0023, 22.8389, 22.9372,\n",
       "         23.0317, 22.8454, 22.9831, 22.8465, 22.7964, 23.0949, 22.8364, 22.8416, 23.0125, 23.1468]),\n",
       "  'score_time': array([4.2466, 4.246 , 4.305 , 4.2507, 4.2806, 4.4149, 4.3151, 4.2562, 4.2807, 4.2554, 4.2546,\n",
       "         4.26  , 4.2593, 4.2781, 4.2377, 4.2882, 4.3017, 4.2489, 4.252 , 4.329 ]),\n",
       "  'test_score': array([0.9301, 0.9366, 0.9155, 0.9014, 0.9231, 0.8944, 0.9155, 0.9507, 0.9231, 0.8944, 0.9366,\n",
       "         0.9225, 0.9161, 0.9155, 0.9296, 0.9085, 0.9161, 0.9437, 0.8803, 0.9296]),\n",
       "  'train_score': array([0.9155, 0.9204, 0.9251, 0.9297, 0.9178, 0.9321, 0.9274, 0.9087, 0.9178, 0.9321, 0.9133,\n",
       "         0.9251, 0.9202, 0.9227, 0.9157, 0.9274, 0.9225, 0.911 , 0.9344, 0.9204])},\n",
       " [{'elapsed_time': 20.53350043296814,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 323,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.345441341400146,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 348,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.45554780960083,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 333,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.432036876678467,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 332,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.363523483276367,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 342,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.532771348953247,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 371,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.580174922943115,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 361,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.51172161102295,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 308,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.362165451049805,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 273,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.469218730926514,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 358,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.578993320465088,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 362,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.406340837478638,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 296,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.51042127609253,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 360,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.40516972541809,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 322,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.336357355117798,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 386,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.652771949768066,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 360,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.391929149627686,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 339,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.37826657295227,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 353,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.565712213516235,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 317,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.510149002075195,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 322,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "ssparse_model = BEMKL(kernels=kernels,\n",
    "                      hyp_lambda_alpha=1e-11, hyp_lambda_beta=1e9,\n",
    "                      hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                      hyp_omega_alpha=1, hyp_omega_beta=1,\n",
    "                      e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                      filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                      max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "ssparse_pipeline = make_pipeline(Normalizer(), ssparse_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "ssparse_cv_results = cross_validate(ssparse_pipeline, X, y, cv=folds, scoring=scoring)\n",
    "ssparse_stats = deepcopy(scoring.stats)\n",
    "ssparse_cv_results, ssparse_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9191519747857775 +- 0.017048868513916685\n",
      "Time: 20.466110670566557 +- 0.08944214821566429\n",
      "Kernels: 13.0 +- 0.0\n",
      "SVs: 338.3 +- 26.771440006096046\n"
     ]
    }
   ],
   "source": [
    "ssparse_times = np.array([s['elapsed_time'] for s in ssparse_stats])\n",
    "ssparse_kernels = np.array([s['nr_kernels_used'] for s in ssparse_stats])\n",
    "ssparse_sv = np.array([s['nr_sv_used'] for s in ssparse_stats])\n",
    "print(\n",
    "    f\"Score: {ssparse_cv_results['test_score'].mean()} +- {ssparse_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {ssparse_times.mean()} +- {ssparse_times.std()}\\n\"\n",
    "    f\"Kernels: {ssparse_kernels.mean()} +- {ssparse_kernels.std()}\\n\"\n",
    "    f\"SVs: {ssparse_sv.mean()} +- {ssparse_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('wdbc_results.json', 'w') as fp:\n",
    "    json.dump(\n",
    "        {\n",
    "            'ksparse': {\n",
    "                'scores': list(ksparse_cv_results['test_score']),\n",
    "                'times': list(ksparse_times),\n",
    "                'kernels': [int(k) for k in ksparse_kernels],\n",
    "                'svs': [int(s) for s in ksparse_sv],\n",
    "            },\n",
    "            'ssparse': {\n",
    "                'scores': list(ssparse_cv_results['test_score']),\n",
    "                'times': list(ssparse_times),\n",
    "                'kernels': [int(k) for k in ssparse_kernels],\n",
    "                'svs': [int(s) for s in ssparse_sv],\n",
    "            },\n",
    "            'base': {\n",
    "                'scores': list(base_cv_results['test_score']),\n",
    "                'times': list(base_times),\n",
    "                'kernels': [int(k) for k in base_kernels],\n",
    "                'svs': [int(s) for s in base_sv],\n",
    "            },\n",
    "            'total_kernels': len(kernels),\n",
    "            'total_sv': len(X_train),\n",
    "        },\n",
    "        fp,\n",
    "        indent=4,\n",
    "        sort_keys=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml",
   "language": "python",
   "name": "pml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
