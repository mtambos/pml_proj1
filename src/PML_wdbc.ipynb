{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.io import savemat, loadmat\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (log_loss, mean_squared_error, roc_curve, auc,\n",
    "                             precision_recall_fscore_support, confusion_matrix)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from tqdm import tqdm, trange, tqdm_notebook as tqdmn\n",
    "\n",
    "from BEKML import BEMKL, plot_distplot\n",
    "from utils import poly_kernel, gauss_kernel, scoring, plot_kernel_importances, plot_compare_models\n",
    "\n",
    "sns.set(style='ticks', context='talk')\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2      3       4       5        6        7       8        9   \\\n",
       "0                                                                              \n",
       "842302    M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710   \n",
       "842517    M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017   \n",
       "84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790   \n",
       "84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520   \n",
       "84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430   \n",
       "\n",
       "              10   ...        22     23      24      25      26      27  \\\n",
       "0                  ...                                                    \n",
       "842302    0.2419   ...     25.38  17.33  184.60  2019.0  0.1622  0.6656   \n",
       "842517    0.1812   ...     24.99  23.41  158.80  1956.0  0.1238  0.1866   \n",
       "84300903  0.2069   ...     23.57  25.53  152.50  1709.0  0.1444  0.4245   \n",
       "84348301  0.2597   ...     14.91  26.50   98.87   567.7  0.2098  0.8663   \n",
       "84358402  0.1809   ...     22.54  16.67  152.20  1575.0  0.1374  0.2050   \n",
       "\n",
       "              28      29      30       31  \n",
       "0                                          \n",
       "842302    0.7119  0.2654  0.4601  0.11890  \n",
       "842517    0.2416  0.1860  0.2750  0.08902  \n",
       "84300903  0.4504  0.2430  0.3613  0.08758  \n",
       "84348301  0.6869  0.2575  0.6638  0.17300  \n",
       "84358402  0.4000  0.1625  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               2           3           4            5           6   \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    14.127292   19.289649   91.969033   654.889104    0.096360   \n",
       "std      3.524049    4.301036   24.298981   351.914129    0.014064   \n",
       "min      6.981000    9.710000   43.790000   143.500000    0.052630   \n",
       "25%     11.700000   16.170000   75.170000   420.300000    0.086370   \n",
       "50%     13.370000   18.840000   86.240000   551.100000    0.095870   \n",
       "75%     15.780000   21.800000  104.100000   782.700000    0.105300   \n",
       "max     28.110000   39.280000  188.500000  2501.000000    0.163400   \n",
       "\n",
       "               7           8           9           10          11     ...      \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000     ...       \n",
       "mean     0.104341    0.088799    0.048919    0.181162    0.062798     ...       \n",
       "std      0.052813    0.079720    0.038803    0.027414    0.007060     ...       \n",
       "min      0.019380    0.000000    0.000000    0.106000    0.049960     ...       \n",
       "25%      0.064920    0.029560    0.020310    0.161900    0.057700     ...       \n",
       "50%      0.092630    0.061540    0.033500    0.179200    0.061540     ...       \n",
       "75%      0.130400    0.130700    0.074000    0.195700    0.066120     ...       \n",
       "max      0.345400    0.426800    0.201200    0.304000    0.097440     ...       \n",
       "\n",
       "               22          23          24           25          26  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
       "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
       "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
       "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
       "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
       "\n",
       "               27          28          29          30          31  \n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
       "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
       "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
       "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
       "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/wdbc.csv', names=list(range(32)), index_col=0)\n",
    "display(data.head())\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.2548330404217926"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data.iloc[:, 1:].copy()\n",
    "y = data.iloc[:, 0].copy()\n",
    "N, D = X.shape\n",
    "y.loc[y == 'B'] = -1\n",
    "y.loc[y == 'M'] = 1\n",
    "y = y.astype(int)\n",
    "display(X.shape, y.shape, y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             2      3       4       5        6        7       8        9   \\\n",
       "0                                                                           \n",
       "842302    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710   \n",
       "842517    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017   \n",
       "84300903  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790   \n",
       "84348301  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520   \n",
       "84358402  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430   \n",
       "\n",
       "              10       11 ...     23      24      25      26      27      28  \\\n",
       "0                         ...                                                  \n",
       "842302    0.2419  0.07871 ...  17.33  184.60  2019.0  0.1622  0.6656  0.7119   \n",
       "842517    0.1812  0.05667 ...  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
       "84300903  0.2069  0.05999 ...  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
       "84348301  0.2597  0.09744 ...  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
       "84358402  0.1809  0.05883 ...  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
       "\n",
       "              29      30       31  1   \n",
       "0                                      \n",
       "842302    0.2654  0.4601  0.11890   1  \n",
       "842517    0.1860  0.2750  0.08902   1  \n",
       "84300903  0.2430  0.3613  0.08758   1  \n",
       "84348301  0.2575  0.6638  0.17300   1  \n",
       "84358402  0.1625  0.2364  0.07678   1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_data = data.copy()\n",
    "proc_data.iloc[:, 0] = y\n",
    "proc_data = proc_data.loc[:, list(proc_data.columns[1:]) + [proc_data.columns[0]]]\n",
    "proc_data.to_csv('data/proc_wdbc.csv')\n",
    "proc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 403)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_init, rbf_end = -3, 7\n",
    "ply_init, ply_end = 1, 4\n",
    "\n",
    "kernel_attrs = [('rbf', 'all', i) for i in range(rbf_init, rbf_end)]\n",
    "kernels = [lambda A, B: gauss_kernel(A, B, 2**i)\n",
    "           for i in range(rbf_init, rbf_end)]\n",
    "\n",
    "kernel_attrs += [('poly', 'all', i) for i in range(ply_init, ply_end)]\n",
    "kernels += [lambda A, B: poly_kernel(A, B, 1, i)\n",
    "            for i in range(ply_init, ply_end)]\n",
    "\n",
    "kernel_attrs += [('rbf', j, i) for i in range(rbf_init, rbf_end)\n",
    "                 for j in range(D)]\n",
    "kernels += [lambda A, B: gauss_kernel(A[:, j:j+1], B[:, j:j+1], 2**i)\n",
    "            for i in range(rbf_init, rbf_end) for j in range(D)]\n",
    "\n",
    "kernel_attrs += [('poly', j, i) for i in range(ply_init, ply_end)\n",
    "                 for j in range(D)]\n",
    "kernels += [lambda A, B: poly_kernel(A[:, j:j+1], B[:, j:j+1], 1, i)\n",
    "            for i in range(ply_init, ply_end) for j in range(D)]\n",
    "len(kernels), len(kernel_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =\\\n",
    "        train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 13/403 (0.03225806451612903). SV: 374/426 (0.8779342723004695). Mean e: 0.0146. Median e: 0.0077. Std e: 0.0752. \n",
      "1 - Kernels: 13/403 (0.03225806451612903). SV: 327/427 (0.765807962529274). Mean e: 0.0151. Median e: 0.0082. Std e: 0.0755. \n",
      "2 - Kernels: 13/403 (0.03225806451612903). SV: 352/427 (0.8243559718969555). Mean e: 0.0150. Median e: 0.0076. Std e: 0.0809. \n",
      "3 - Kernels: 13/403 (0.03225806451612903). SV: 389/427 (0.9110070257611241). Mean e: 0.0163. Median e: 0.0095. Std e: 0.0743. \n",
      "4 - Kernels: 13/403 (0.03225806451612903). SV: 408/426 (0.9577464788732394). Mean e: 0.0139. Median e: 0.0066. Std e: 0.0793. \n",
      "5 - Kernels: 13/403 (0.03225806451612903). SV: 379/427 (0.8875878220140515). Mean e: 0.0147. Median e: 0.0075. Std e: 0.0790. \n",
      "6 - Kernels: 13/403 (0.03225806451612903). SV: 390/427 (0.9133489461358314). Mean e: 0.0151. Median e: 0.0083. Std e: 0.0743. \n",
      "7 - Kernels: 13/403 (0.03225806451612903). SV: 347/427 (0.8126463700234192). Mean e: 0.0138. Median e: 0.0066. Std e: 0.0785. \n",
      "8 - Kernels: 13/403 (0.03225806451612903). SV: 227/426 (0.5328638497652582). Mean e: 0.0136. Median e: 0.0060. Std e: 0.0825. \n",
      "9 - Kernels: 13/403 (0.03225806451612903). SV: 352/427 (0.8243559718969555). Mean e: 0.0138. Median e: 0.0070. Std e: 0.0738. \n",
      "10 - Kernels: 13/403 (0.03225806451612903). SV: 385/427 (0.9016393442622951). Mean e: 0.0157. Median e: 0.0083. Std e: 0.0805. \n",
      "11 - Kernels: 13/403 (0.03225806451612903). SV: 330/427 (0.7728337236533958). Mean e: 0.0169. Median e: 0.0093. Std e: 0.0836. \n",
      "12 - Kernels: 13/403 (0.03225806451612903). SV: 402/426 (0.9436619718309859). Mean e: 0.0128. Median e: 0.0060. Std e: 0.0739. \n",
      "13 - Kernels: 13/403 (0.03225806451612903). SV: 314/427 (0.7353629976580797). Mean e: 0.0151. Median e: 0.0077. Std e: 0.0811. \n",
      "14 - Kernels: 13/403 (0.03225806451612903). SV: 358/427 (0.8384074941451991). Mean e: 0.0146. Median e: 0.0071. Std e: 0.0813. \n",
      "15 - Kernels: 403/403 (1.0). SV: 357/427 (0.8360655737704918). Mean e: 0.0172. Median e: 0.0102. Std e: 0.0766. \n",
      "16 - Kernels: 13/403 (0.03225806451612903). SV: 285/426 (0.6690140845070423). Mean e: 0.0156. Median e: 0.0089. Std e: 0.0730. \n",
      "17 - Kernels: 13/403 (0.03225806451612903). SV: 342/427 (0.8009367681498829). Mean e: 0.0128. Median e: 0.0058. Std e: 0.0755. \n",
      "18 - Kernels: 13/403 (0.03225806451612903). SV: 394/427 (0.9227166276346604). Mean e: 0.0145. Median e: 0.0068. Std e: 0.0838. \n",
      "19 - Kernels: 13/403 (0.03225806451612903). SV: 352/427 (0.8243559718969555). Mean e: 0.0144. Median e: 0.0075. Std e: 0.0747. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([22.9045, 22.8748, 23.201 , 30.1612, 22.6314, 23.25  , 22.9797, 22.7122, 23.1859, 23.9337,\n",
       "         22.9778, 23.0889, 22.7188, 22.8844, 23.143 , 22.8097, 22.285 , 23.5469, 22.7584, 22.7748]),\n",
       "  'score_time': array([4.2227, 4.2024, 4.2244, 4.3227, 4.2968, 4.3587, 4.3644, 4.3143, 4.2249, 4.5245, 4.1892,\n",
       "         4.2392, 4.2924, 4.3045, 4.3487, 4.2104, 4.2622, 4.1989, 4.3   , 4.1865]),\n",
       "  'test_score': array([0.9301, 0.9225, 0.9085, 0.9366, 0.9021, 0.9014, 0.9789, 0.9014, 0.8741, 0.9507, 0.9577,\n",
       "         0.9014, 0.9441, 0.9225, 0.9155, 0.8944, 0.9371, 0.9014, 0.9296, 0.9366]),\n",
       "  'train_score': array([0.9202, 0.9227, 0.9251, 0.918 , 0.9249, 0.9274, 0.904 , 0.9344, 0.9272, 0.9133, 0.9087,\n",
       "         0.9321, 0.9155, 0.918 , 0.9251, 0.9321, 0.9155, 0.9274, 0.9251, 0.9133])},\n",
       " [{'elapsed_time': 20.37468719482422,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 374,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.502962350845337,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 327,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.748059511184692,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 352,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 27.725629091262817,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 389,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.246323108673096,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 408,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.746570587158203,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 379,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.52132821083069,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 390,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.29319739341736,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 347,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.764679670333862,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 227,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 21.48176670074463,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 352,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.53735589981079,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 385,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.635080099105835,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 330,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.255668878555298,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 402,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.349413633346558,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 314,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.665701866149902,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 358,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.346198558807373,\n",
       "   'nr_kernels_used': 403,\n",
       "   'nr_sv_used': 357,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 19.853422164916992,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 285,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 21.095770835876465,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 342,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.325316190719604,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 394,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.332447052001953,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 352,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "base_model = BEMKL(kernels=kernels, hyp_lambda_alpha=1, hyp_lambda_beta=1,\n",
    "                   hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                   hyp_omega_alpha=1, hyp_omega_beta=1,\n",
    "                   e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                   filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                   max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "base_model = make_pipeline(Normalizer(), base_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "base_cv_results = cross_validate(base_model, X, y, cv=folds, scoring=scoring)\n",
    "base_stats = deepcopy(scoring.stats)\n",
    "base_cv_results, base_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9223283758495026 +- 0.02446601814854977\n",
      "Time: 20.890078949928284 +- 1.6036013263561602\n",
      "Kernels: 32.5 +- 84.99852939904314\n",
      "SVs: 353.2 +- 42.03522332520669\n"
     ]
    }
   ],
   "source": [
    "base_times = np.array([s['elapsed_time'] for s in base_stats])\n",
    "base_kernels = np.array([s['nr_kernels_used'] for s in base_stats])\n",
    "base_sv = np.array([s['nr_sv_used'] for s in base_stats])\n",
    "print(\n",
    "    f\"Score: {base_cv_results['test_score'].mean()} +- {base_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {base_times.mean()} +- {base_times.std()}\\n\"\n",
    "    f\"Kernels: {base_kernels.mean()} +- {base_kernels.std()}\\n\"\n",
    "    f\"SVs: {base_sv.mean()} +- {base_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel-sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 3/403 (0.007444168734491315). SV: 389/426 (0.9131455399061033). Mean e: 0.0067. Median e: 0.0001. Std e: 0.0770. \n",
      "1 - Kernels: 3/403 (0.007444168734491315). SV: 384/427 (0.8992974238875878). Mean e: 0.0069. Median e: 0.0001. Std e: 0.0791. \n",
      "2 - Kernels: 3/403 (0.007444168734491315). SV: 354/427 (0.8290398126463701). Mean e: 0.0066. Median e: 0.0001. Std e: 0.0752. \n",
      "3 - Kernels: 3/403 (0.007444168734491315). SV: 374/427 (0.8758782201405152). Mean e: 0.0074. Median e: 0.0001. Std e: 0.0847. \n",
      "4 - Kernels: 3/403 (0.007444168734491315). SV: 346/426 (0.812206572769953). Mean e: 0.0071. Median e: 0.0001. Std e: 0.0808. \n",
      "5 - Kernels: 3/403 (0.007444168734491315). SV: 385/427 (0.9016393442622951). Mean e: 0.0066. Median e: 0.0001. Std e: 0.0750. \n",
      "6 - Kernels: 3/403 (0.007444168734491315). SV: 402/427 (0.9414519906323185). Mean e: 0.0074. Median e: 0.0001. Std e: 0.0847. \n",
      "7 - Kernels: 3/403 (0.007444168734491315). SV: 388/427 (0.9086651053864169). Mean e: 0.0066. Median e: 0.0001. Std e: 0.0754. \n",
      "8 - Kernels: 3/403 (0.007444168734491315). SV: 370/426 (0.8685446009389671). Mean e: 0.0063. Median e: 0.0001. Std e: 0.0726. \n",
      "9 - Kernels: 3/403 (0.007444168734491315). SV: 376/427 (0.8805620608899297). Mean e: 0.0070. Median e: 0.0001. Std e: 0.0805. \n",
      "10 - Kernels: 3/403 (0.007444168734491315). SV: 357/427 (0.8360655737704918). Mean e: 0.0069. Median e: 0.0001. Std e: 0.0784. \n",
      "11 - Kernels: 3/403 (0.007444168734491315). SV: 321/427 (0.7517564402810304). Mean e: 0.0071. Median e: 0.0001. Std e: 0.0816. \n",
      "12 - Kernels: 3/403 (0.007444168734491315). SV: 370/426 (0.8685446009389671). Mean e: 0.0070. Median e: 0.0000. Std e: 0.0807. \n",
      "13 - Kernels: 3/403 (0.007444168734491315). SV: 229/427 (0.5362997658079626). Mean e: 0.0068. Median e: 0.0001. Std e: 0.0773. \n",
      "14 - Kernels: 3/403 (0.007444168734491315). SV: 378/427 (0.8852459016393442). Mean e: 0.0070. Median e: 0.0001. Std e: 0.0803. \n",
      "15 - Kernels: 3/403 (0.007444168734491315). SV: 389/427 (0.9110070257611241). Mean e: 0.0067. Median e: 0.0001. Std e: 0.0770. \n",
      "16 - Kernels: 3/403 (0.007444168734491315). SV: 239/426 (0.5610328638497653). Mean e: 0.0075. Median e: 0.0001. Std e: 0.0856. \n",
      "17 - Kernels: 3/403 (0.007444168734491315). SV: 406/427 (0.9508196721311475). Mean e: 0.0063. Median e: 0.0001. Std e: 0.0714. \n",
      "18 - Kernels: 3/403 (0.007444168734491315). SV: 380/427 (0.8899297423887588). Mean e: 0.0068. Median e: 0.0001. Std e: 0.0774. \n",
      "19 - Kernels: 3/403 (0.007444168734491315). SV: 366/427 (0.8571428571428571). Mean e: 0.0073. Median e: 0.0001. Std e: 0.0839. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([22.3753, 22.9347, 22.8556, 25.6279, 23.7483, 22.9251, 22.793 , 23.2492, 22.7382, 23.0057,\n",
       "         23.1831, 22.8225, 22.8959, 25.0821, 23.1253, 23.1809, 22.8659, 22.9201, 22.9529, 22.7752]),\n",
       "  'score_time': array([4.2915, 4.1726, 4.5307, 4.2984, 4.2973, 4.2126, 4.2516, 4.2946, 4.2824, 4.1953, 4.2992,\n",
       "         4.2038, 4.234 , 4.3118, 4.1802, 4.2069, 4.2804, 4.222 , 4.2206, 4.2115]),\n",
       "  'test_score': array([0.9301, 0.8944, 0.9577, 0.9085, 0.9021, 0.9014, 0.9296, 0.9366, 0.9161, 0.9085, 0.9225,\n",
       "         0.9366, 0.9021, 0.9296, 0.9225, 0.9296, 0.9161, 0.9296, 0.9225, 0.9225]),\n",
       "  'train_score': array([0.9202, 0.9274, 0.9087, 0.9297, 0.9249, 0.9274, 0.918 , 0.918 , 0.9249, 0.9251, 0.918 ,\n",
       "         0.9133, 0.9225, 0.918 , 0.9227, 0.918 , 0.9155, 0.918 , 0.9227, 0.9251])},\n",
       " [{'elapsed_time': 19.98964834213257,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 389,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.44584560394287,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 384,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.419716119766235,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 354,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 23.11672616004944,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 374,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 21.23383116722107,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 346,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.46833086013794,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 385,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.409553289413452,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 402,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.800995111465454,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 388,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.30619192123413,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 370,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.563862562179565,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 376,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.75106716156006,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 357,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.383493900299072,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 321,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.363407373428345,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 370,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 22.63741159439087,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 229,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.688026666641235,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 378,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.737209796905518,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 389,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.42705464363098,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 239,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.478364944458008,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 406,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.484514713287354,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 380,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.326950550079346,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 366,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427}])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "ksparse_model = BEMKL(kernels=kernels, hyp_lambda_alpha=1, hyp_lambda_beta=1,\n",
    "                      hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                      hyp_omega_alpha=1e-11, hyp_omega_beta=1e9,\n",
    "                      e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                      filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                      max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "ksparse_pipeline = make_pipeline(Normalizer(), ksparse_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "ksparse_cv_results = cross_validate(ksparse_pipeline, X, y, cv=folds, scoring=scoring)\n",
    "ksparse_stats = deepcopy(scoring.stats)\n",
    "ksparse_cv_results, ksparse_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9209273121244952 +- 0.014824311538043911\n",
      "Time: 20.751610124111174 +- 0.7524048538477147\n",
      "Kernels: 3.0 +- 0.0\n",
      "SVs: 360.15 +- 46.109950119253\n"
     ]
    }
   ],
   "source": [
    "ksparse_times = np.array([s['elapsed_time'] for s in ksparse_stats])\n",
    "ksparse_kernels = np.array([s['nr_kernels_used'] for s in ksparse_stats])\n",
    "ksparse_sv = np.array([s['nr_sv_used'] for s in ksparse_stats])\n",
    "print(\n",
    "    f\"Score: {ksparse_cv_results['test_score'].mean()} +- {ksparse_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {ksparse_times.mean()} +- {ksparse_times.std()}\\n\"\n",
    "    f\"Kernels: {ksparse_kernels.mean()} +- {ksparse_kernels.std()}\\n\"\n",
    "    f\"SVs: {ksparse_sv.mean()} +- {ksparse_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV-sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 13/403 (0.03225806451612903). SV: 380/426 (0.892018779342723). Mean e: 0.0154. Median e: 0.0073. Std e: 0.0881. \n",
      "1 - Kernels: 13/403 (0.03225806451612903). SV: 321/427 (0.7517564402810304). Mean e: 0.0157. Median e: 0.0089. Std e: 0.0745. \n",
      "2 - Kernels: 13/403 (0.03225806451612903). SV: 373/427 (0.8735362997658079). Mean e: 0.0154. Median e: 0.0082. Std e: 0.0786. \n",
      "3 - Kernels: 13/403 (0.03225806451612903). SV: 379/427 (0.8875878220140515). Mean e: 0.0128. Median e: 0.0057. Std e: 0.0773. \n",
      "4 - Kernels: 13/403 (0.03225806451612903). SV: 319/426 (0.7488262910798122). Mean e: 0.0142. Median e: 0.0071. Std e: 0.0780. \n",
      "5 - Kernels: 13/403 (0.03225806451612903). SV: 343/427 (0.8032786885245902). Mean e: 0.0151. Median e: 0.0073. Std e: 0.0859. \n",
      "6 - Kernels: 13/403 (0.03225806451612903). SV: 355/427 (0.8313817330210773). Mean e: 0.0161. Median e: 0.0086. Std e: 0.0816. \n",
      "7 - Kernels: 13/403 (0.03225806451612903). SV: 387/427 (0.9063231850117096). Mean e: 0.0136. Median e: 0.0066. Std e: 0.0761. \n",
      "8 - Kernels: 13/403 (0.03225806451612903). SV: 377/426 (0.8849765258215962). Mean e: 0.0145. Median e: 0.0075. Std e: 0.0765. \n",
      "9 - Kernels: 13/403 (0.03225806451612903). SV: 317/427 (0.7423887587822015). Mean e: 0.0155. Median e: 0.0082. Std e: 0.0799. \n",
      "10 - Kernels: 13/403 (0.03225806451612903). SV: 407/427 (0.9531615925058547). Mean e: 0.0151. Median e: 0.0081. Std e: 0.0770. \n",
      "11 - Kernels: 13/403 (0.03225806451612903). SV: 315/427 (0.7377049180327869). Mean e: 0.0151. Median e: 0.0074. Std e: 0.0841. \n",
      "12 - Kernels: 13/403 (0.03225806451612903). SV: 381/426 (0.8943661971830986). Mean e: 0.0144. Median e: 0.0074. Std e: 0.0771. \n",
      "13 - Kernels: 13/403 (0.03225806451612903). SV: 362/427 (0.8477751756440282). Mean e: 0.0145. Median e: 0.0074. Std e: 0.0764. \n",
      "14 - Kernels: 13/403 (0.03225806451612903). SV: 285/427 (0.667447306791569). Mean e: 0.0132. Median e: 0.0060. Std e: 0.0784. \n",
      "15 - Kernels: 13/403 (0.03225806451612903). SV: 320/427 (0.7494145199063232). Mean e: 0.0164. Median e: 0.0087. Std e: 0.0842. \n",
      "16 - Kernels: 13/403 (0.03225806451612903). SV: 345/426 (0.8098591549295775). Mean e: 0.0151. Median e: 0.0082. Std e: 0.0758. \n",
      "17 - Kernels: 13/403 (0.03225806451612903). SV: 382/427 (0.8946135831381733). Mean e: 0.0154. Median e: 0.0086. Std e: 0.0742. \n",
      "18 - Kernels: 13/403 (0.03225806451612903). SV: 327/427 (0.765807962529274). Mean e: 0.0159. Median e: 0.0085. Std e: 0.0800. \n",
      "19 - Kernels: 13/403 (0.03225806451612903). SV: 339/427 (0.7939110070257611). Mean e: 0.0133. Median e: 0.0059. Std e: 0.0807. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([23.0085, 22.77  , 22.7981, 23.3034, 23.0207, 23.1319, 23.4263, 24.6487, 22.7371, 23.4058,\n",
       "         23.1804, 22.9609, 22.8678, 23.178 , 23.1473, 23.199 , 22.7531, 22.963 , 22.9891, 22.8221]),\n",
       "  'score_time': array([4.2822, 4.2535, 4.1944, 4.2481, 4.5068, 4.3159, 4.1761, 4.2258, 4.223 , 4.2619, 4.2195,\n",
       "         4.2694, 4.3636, 4.2457, 4.2267, 4.2077, 4.2104, 4.3259, 4.2809, 4.3436]),\n",
       "  'test_score': array([0.8881, 0.9507, 0.9296, 0.9225, 0.9301, 0.9225, 0.8873, 0.9437, 0.9161, 0.8944, 0.9507,\n",
       "         0.9085, 0.9301, 0.9085, 0.9366, 0.9085, 0.9301, 0.9155, 0.9296, 0.9014]),\n",
       "  'train_score': array([0.9319, 0.9157, 0.9157, 0.9204, 0.9178, 0.9157, 0.9321, 0.9157, 0.9249, 0.9274, 0.9157,\n",
       "         0.9227, 0.9202, 0.9251, 0.9204, 0.9274, 0.9202, 0.9227, 0.9274, 0.9274])},\n",
       " [{'elapsed_time': 20.559281587600708,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 380,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.31490659713745,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 321,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.372852563858032,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 373,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.891520977020264,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 379,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.543129920959473,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 319,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.57863211631775,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 343,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.991875648498535,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 355,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 22.229857444763184,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 387,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.279918670654297,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 377,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.93818759918213,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 317,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.72971272468567,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 407,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.470319747924805,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 315,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.427222728729248,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 381,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.716567516326904,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 362,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.655267477035522,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 285,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.7431583404541,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 320,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.304951906204224,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 345,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 426},\n",
       "  {'elapsed_time': 20.53248691558838,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 382,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.4915771484375,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 327,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427},\n",
       "  {'elapsed_time': 20.367598056793213,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 339,\n",
       "   'total_kernels': 403,\n",
       "   'total_sv': 427}])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "ssparse_model = BEMKL(kernels=kernels,\n",
    "                      hyp_lambda_alpha=1e-11, hyp_lambda_beta=1e9,\n",
    "                      hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                      hyp_omega_alpha=1, hyp_omega_beta=1,\n",
    "                      e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                      filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                      max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "ssparse_pipeline = make_pipeline(Normalizer(), ssparse_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "ssparse_cv_results = cross_validate(ssparse_pipeline, X, y, cv=folds, scoring=scoring)\n",
    "ssparse_stats = deepcopy(scoring.stats)\n",
    "ssparse_cv_results, ssparse_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9202132374667584 +- 0.018363463609058602\n",
      "Time: 20.65695128440857 +- 0.4149199875959604\n",
      "Kernels: 13.0 +- 0.0\n",
      "SVs: 350.7 +- 31.405572753891946\n"
     ]
    }
   ],
   "source": [
    "ssparse_times = np.array([s['elapsed_time'] for s in ssparse_stats])\n",
    "ssparse_kernels = np.array([s['nr_kernels_used'] for s in ssparse_stats])\n",
    "ssparse_sv = np.array([s['nr_sv_used'] for s in ssparse_stats])\n",
    "print(\n",
    "    f\"Score: {ssparse_cv_results['test_score'].mean()} +- {ssparse_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {ssparse_times.mean()} +- {ssparse_times.std()}\\n\"\n",
    "    f\"Kernels: {ssparse_kernels.mean()} +- {ssparse_kernels.std()}\\n\"\n",
    "    f\"SVs: {ssparse_sv.mean()} +- {ssparse_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('wdbc_results.json', 'w') as fp:\n",
    "    json.dump(\n",
    "        {\n",
    "            'ksparse': {\n",
    "                'scores': list(ksparse_cv_results['test_score']),\n",
    "                'times': list(ksparse_times),\n",
    "                'kernels': [int(k) for k in ksparse_kernels],\n",
    "                'svs': [int(s) for s in ksparse_sv],\n",
    "            },\n",
    "            'ssparse': {\n",
    "                'scores': list(ssparse_cv_results['test_score']),\n",
    "                'times': list(ssparse_times),\n",
    "                'kernels': [int(k) for k in ksparse_kernels],\n",
    "                'svs': [int(s) for s in ssparse_sv],\n",
    "            },\n",
    "            'base': {\n",
    "                'scores': list(base_cv_results['test_score']),\n",
    "                'times': list(base_times),\n",
    "                'kernels': [int(k) for k in base_kernels],\n",
    "                'svs': [int(s) for s in base_sv],\n",
    "            },\n",
    "            'total_kernels': len(kernels),\n",
    "            'total_sv': len(X_train),\n",
    "        },\n",
    "        fp,\n",
    "        indent=4,\n",
    "        sort_keys=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml",
   "language": "python",
   "name": "pml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
