{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.io import savemat, loadmat\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (log_loss, mean_squared_error, roc_curve, auc,\n",
    "                             precision_recall_fscore_support, confusion_matrix)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from tqdm import tqdm, trange, tqdm_notebook as tqdmn\n",
    "\n",
    "from BEKML import BEMKL, plot_distplot\n",
    "from utils import poly_kernel, gauss_kernel, scoring, plot_kernel_importances, plot_compare_models\n",
    "\n",
    "sns.set(style='ticks', context='talk')\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "        9  ...       25       26       27       28       29       30       31  \\\n",
       "0  0.03760 ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267 -0.54487   \n",
       "1 -0.04549 ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626 -0.06288   \n",
       "2  0.01198 ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436 -0.24180   \n",
       "3  0.00000 ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682  1.00000   \n",
       "4 -0.16399 ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707 -0.59573   \n",
       "\n",
       "        32       33  34  \n",
       "0  0.18641 -0.45300   1  \n",
       "1 -0.13738 -0.02447  -1  \n",
       "2  0.56045 -0.38238   1  \n",
       "3 -0.32382  1.00000  -1  \n",
       "4 -0.04608 -0.65697   1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.0</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.282051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "      <td>0.960769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1           2           3           4           5   \\\n",
       "count  351.000000  351.0  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738    0.0    0.641342    0.044372    0.601068    0.115889   \n",
       "std      0.311155    0.0    0.497708    0.441435    0.519862    0.460810   \n",
       "min      0.000000    0.0   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.0    0.472135   -0.064735    0.412660   -0.024795   \n",
       "50%      1.000000    0.0    0.871110    0.016310    0.809200    0.022800   \n",
       "75%      1.000000    0.0    1.000000    0.194185    1.000000    0.334655   \n",
       "max      1.000000    0.0    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9      ...              25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000     ...      351.000000   \n",
       "mean     0.550095    0.119360    0.511848    0.181345     ...       -0.071187   \n",
       "std      0.492654    0.520750    0.507066    0.483851     ...        0.508495   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000     ...       -1.000000   \n",
       "25%      0.211310   -0.054840    0.087110   -0.048075     ...       -0.332390   \n",
       "50%      0.728730    0.014710    0.684210    0.018290     ...       -0.015050   \n",
       "75%      0.969240    0.445675    0.953240    0.534195     ...        0.156765   \n",
       "max      1.000000    1.000000    1.000000    1.000000     ...        1.000000   \n",
       "\n",
       "               26          27          28          29          30          31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.541641   -0.069538    0.378445   -0.027907    0.352514   -0.003794   \n",
       "std      0.516205    0.550025    0.575886    0.507974    0.571483    0.513574   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      0.286435   -0.443165    0.000000   -0.236885    0.000000   -0.242595   \n",
       "50%      0.708240   -0.017690    0.496640    0.000000    0.442770    0.000000   \n",
       "75%      0.999945    0.153535    0.883465    0.154075    0.857620    0.200120   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               32          33          34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean     0.349364    0.014480    0.282051  \n",
       "std      0.522663    0.468337    0.960769  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%      0.000000   -0.165350   -1.000000  \n",
       "50%      0.409560    0.000000    1.000000  \n",
       "75%      0.813765    0.171660    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes = {i: float for i in range(35)}\n",
    "dtypes[35] = str\n",
    "data = pd.read_csv('data/ionosphere.csv', names=list(range(35)))#, dtype=dtypes)\n",
    "data.loc[data.loc[:, 34] == 'g', 34] = 1\n",
    "data.loc[data.loc[:, 34] == 'b', 34] = -1\n",
    "data.loc[:, 34] = data.loc[:, 34].astype(int)\n",
    "display(data.head())\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(351,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.28205128205128205"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data.iloc[:, :-1].copy()\n",
    "y = data.iloc[:, -1].copy()\n",
    "N, D = X.shape\n",
    "display(X.shape, y.shape, y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data = data.copy()\n",
    "proc_data.iloc[:, -1] = y\n",
    "proc_data.to_csv('data/proc_ionosphere.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 455)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_init, rbf_end = -3, 7\n",
    "ply_init, ply_end = 1, 4\n",
    "\n",
    "kernel_attrs = [('rbf', 'all', i) for i in range(rbf_init, rbf_end)]\n",
    "kernels = [lambda A, B: gauss_kernel(A, B, 2**i)\n",
    "           for i in range(rbf_init, rbf_end)]\n",
    "\n",
    "kernel_attrs += [('poly', 'all', i) for i in range(ply_init, ply_end)]\n",
    "kernels += [lambda A, B: poly_kernel(A, B, 1, i)\n",
    "            for i in range(ply_init, ply_end)]\n",
    "\n",
    "kernel_attrs += [('rbf', j, i) for i in range(rbf_init, rbf_end)\n",
    "                 for j in range(D)]\n",
    "kernels += [lambda A, B: gauss_kernel(A[:, j:j+1], B[:, j:j+1], 2**i)\n",
    "            for i in range(rbf_init, rbf_end) for j in range(D)]\n",
    "\n",
    "kernel_attrs += [('poly', j, i) for i in range(ply_init, ply_end)\n",
    "                 for j in range(D)]\n",
    "kernels += [lambda A, B: poly_kernel(A[:, j:j+1], B[:, j:j+1], 1, i)\n",
    "            for i in range(ply_init, ply_end) for j in range(D)]\n",
    "len(kernels), len(kernel_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =\\\n",
    "        train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 455/455 (1.0). SV: 257/262 (0.9809160305343512). Mean e: -0.0022. Median e: -0.0227. Std e: 0.1192. \n",
      "1 - Kernels: 455/455 (1.0). SV: 253/263 (0.9619771863117871). Mean e: -0.0021. Median e: -0.0184. Std e: 0.1042. \n",
      "2 - Kernels: 455/455 (1.0). SV: 259/264 (0.9810606060606061). Mean e: -0.0072. Median e: -0.0248. Std e: 0.1163. \n",
      "3 - Kernels: 455/455 (1.0). SV: 255/264 (0.9659090909090909). Mean e: -0.0031. Median e: -0.0240. Std e: 0.1167. \n",
      "4 - Kernels: 455/455 (1.0). SV: 254/262 (0.9694656488549618). Mean e: 0.0013. Median e: -0.0227. Std e: 0.1218. \n",
      "5 - Kernels: 455/455 (1.0). SV: 246/263 (0.935361216730038). Mean e: -0.0035. Median e: -0.0187. Std e: 0.1035. \n",
      "6 - Kernels: 455/455 (1.0). SV: 254/264 (0.9621212121212122). Mean e: -0.0060. Median e: -0.0229. Std e: 0.1108. \n",
      "7 - Kernels: 455/455 (1.0). SV: 258/264 (0.9772727272727273). Mean e: -0.0073. Median e: -0.0249. Std e: 0.1132. \n",
      "8 - Kernels: 455/455 (1.0). SV: 252/262 (0.9618320610687023). Mean e: -0.0058. Median e: -0.0247. Std e: 0.1175. \n",
      "9 - Kernels: 455/455 (1.0). SV: 246/263 (0.935361216730038). Mean e: 0.0016. Median e: -0.0127. Std e: 0.1013. \n",
      "10 - Kernels: 455/455 (1.0). SV: 253/264 (0.9583333333333334). Mean e: -0.0054. Median e: -0.0228. Std e: 0.1163. \n",
      "11 - Kernels: 455/455 (1.0). SV: 255/264 (0.9659090909090909). Mean e: -0.0115. Median e: -0.0205. Std e: 0.1107. \n",
      "12 - Kernels: 455/455 (1.0). SV: 251/262 (0.9580152671755725). Mean e: -0.0017. Median e: -0.0186. Std e: 0.1084. \n",
      "13 - Kernels: 455/455 (1.0). SV: 259/263 (0.9847908745247148). Mean e: 0.0008. Median e: -0.0239. Std e: 0.1102. \n",
      "14 - Kernels: 353/455 (0.7758241758241758). SV: 256/264 (0.9696969696969697). Mean e: -0.0112. Median e: -0.0243. Std e: 0.1140. \n",
      "15 - Kernels: 455/455 (1.0). SV: 259/264 (0.9810606060606061). Mean e: -0.0006. Median e: -0.0113. Std e: 0.0972. \n",
      "16 - Kernels: 455/455 (1.0). SV: 254/262 (0.9694656488549618). Mean e: -0.0065. Median e: -0.0233. Std e: 0.1094. \n",
      "17 - Kernels: 455/455 (1.0). SV: 255/263 (0.9695817490494296). Mean e: -0.0052. Median e: -0.0171. Std e: 0.1021. \n",
      "18 - Kernels: 455/455 (1.0). SV: 260/264 (0.9848484848484849). Mean e: 0.0002. Median e: -0.0237. Std e: 0.1232. \n",
      "19 - Kernels: 455/455 (1.0). SV: 257/264 (0.9734848484848485). Mean e: -0.0031. Median e: -0.0234. Std e: 0.1142. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([16.3186, 19.5719, 21.1818, 16.1789, 15.9457, 13.0516, 13.3368, 13.0482, 12.6117, 12.7089,\n",
       "         13.2758, 13.0589, 13.3763, 12.9491, 12.7268, 12.8185, 12.7006, 13.0645, 12.895 , 12.7197]),\n",
       "  'score_time': array([1.9763, 1.6714, 1.7425, 1.7386, 1.6494, 1.6661, 1.6496, 1.6596, 1.6697, 1.6744, 1.6673,\n",
       "         1.6657, 1.6418, 1.6697, 1.6595, 1.6654, 1.6819, 1.6723, 1.6643, 1.6365]),\n",
       "  'test_score': array([0.9101, 0.8636, 0.908 , 0.908 , 0.9213, 0.8068, 0.908 , 0.8621, 0.8764, 0.8523, 0.908 ,\n",
       "         0.8506, 0.8315, 0.8864, 0.908 , 0.8621, 0.8652, 0.8636, 0.8851, 0.8736]),\n",
       "  'train_score': array([0.9885, 0.9772, 0.9811, 0.9811, 0.9809, 0.981 , 0.9848, 0.9811, 0.9809, 0.981 , 0.9735,\n",
       "         0.9886, 0.9847, 0.9658, 0.9811, 0.9811, 0.9847, 0.9696, 0.9773, 0.9773])},\n",
       " [{'elapsed_time': 15.266514301300049,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 257,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 18.506811141967773,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 253,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 20.036790370941162,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 259,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 15.044431209564209,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 255,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 14.869178533554077,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 254,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 12.051223278045654,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 246,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 12.313329219818115,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 254,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.025899648666382,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 258,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.555477142333984,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 252,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.670689344406128,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 246,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 12.2489914894104,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 253,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.010467767715454,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 255,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.320993423461914,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 251,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.902504682540894,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 259,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.676377773284912,\n",
       "   'nr_kernels_used': 353,\n",
       "   'nr_sv_used': 256,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.763394832611084,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 259,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.6533362865448,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 254,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 12.02643871307373,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 255,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.83534836769104,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 260,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.678155422210693,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 257,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "base_model = BEMKL(kernels=kernels, hyp_lambda_alpha=1, hyp_lambda_beta=1,\n",
    "                   hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                   hyp_omega_alpha=1, hyp_omega_beta=1,\n",
    "                   e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                   filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                   max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "base_model = make_pipeline(Normalizer(), base_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "base_cv_results = cross_validate(base_model, X, y, cv=folds, scoring=scoring)\n",
    "base_stats = deepcopy(scoring.stats)\n",
    "base_cv_results, base_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8775392436570273 +- 0.029405353239401272\n",
      "Time: 13.122817647457122 +- 2.354564825686717\n",
      "Kernels: 449.9 +- 22.230384612057435\n",
      "SVs: 254.65 +- 3.785168424258028\n"
     ]
    }
   ],
   "source": [
    "base_times = np.array([s['elapsed_time'] for s in base_stats])\n",
    "base_kernels = np.array([s['nr_kernels_used'] for s in base_stats])\n",
    "base_sv = np.array([s['nr_sv_used'] for s in base_stats])\n",
    "print(\n",
    "    f\"Score: {base_cv_results['test_score'].mean()} +- {base_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {base_times.mean()} +- {base_times.std()}\\n\"\n",
    "    f\"Kernels: {base_kernels.mean()} +- {base_kernels.std()}\\n\"\n",
    "    f\"SVs: {base_sv.mean()} +- {base_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel-sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 3/455 (0.006593406593406593). SV: 258/262 (0.9847328244274809). Mean e: 0.0089. Median e: -0.0001. Std e: 0.1028. \n",
      "1 - Kernels: 3/455 (0.006593406593406593). SV: 249/263 (0.9467680608365019). Mean e: 0.0089. Median e: -0.0002. Std e: 0.1106. \n",
      "2 - Kernels: 3/455 (0.006593406593406593). SV: 258/264 (0.9772727272727273). Mean e: 0.0088. Median e: -0.0002. Std e: 0.1078. \n",
      "3 - Kernels: 3/455 (0.006593406593406593). SV: 245/264 (0.928030303030303). Mean e: 0.0089. Median e: -0.0002. Std e: 0.1108. \n",
      "4 - Kernels: 3/455 (0.006593406593406593). SV: 253/262 (0.9656488549618321). Mean e: 0.0089. Median e: -0.0001. Std e: 0.1004. \n",
      "5 - Kernels: 3/455 (0.006593406593406593). SV: 256/263 (0.973384030418251). Mean e: 0.0087. Median e: -0.0002. Std e: 0.1071. \n",
      "6 - Kernels: 3/455 (0.006593406593406593). SV: 251/264 (0.9507575757575758). Mean e: 0.0089. Median e: -0.0002. Std e: 0.1123. \n",
      "7 - Kernels: 3/455 (0.006593406593406593). SV: 257/264 (0.9734848484848485). Mean e: 0.0092. Median e: -0.0002. Std e: 0.1101. \n",
      "8 - Kernels: 3/455 (0.006593406593406593). SV: 257/262 (0.9809160305343512). Mean e: 0.0076. Median e: -0.0001. Std e: 0.0933. \n",
      "9 - Kernels: 3/455 (0.006593406593406593). SV: 254/263 (0.9657794676806084). Mean e: 0.0095. Median e: -0.0002. Std e: 0.1169. \n",
      "10 - Kernels: 3/455 (0.006593406593406593). SV: 252/264 (0.9545454545454546). Mean e: 0.0093. Median e: -0.0002. Std e: 0.1143. \n",
      "11 - Kernels: 3/455 (0.006593406593406593). SV: 256/264 (0.9696969696969697). Mean e: 0.0090. Median e: -0.0002. Std e: 0.1125. \n",
      "12 - Kernels: 3/455 (0.006593406593406593). SV: 260/262 (0.9923664122137404). Mean e: 0.0096. Median e: -0.0002. Std e: 0.1110. \n",
      "13 - Kernels: 3/455 (0.006593406593406593). SV: 259/263 (0.9847908745247148). Mean e: 0.0092. Median e: -0.0002. Std e: 0.1153. \n",
      "14 - Kernels: 3/455 (0.006593406593406593). SV: 261/264 (0.9886363636363636). Mean e: 0.0106. Median e: -0.0001. Std e: 0.1281. \n",
      "15 - Kernels: 3/455 (0.006593406593406593). SV: 258/264 (0.9772727272727273). Mean e: 0.0080. Median e: -0.0001. Std e: 0.0992. \n",
      "16 - Kernels: 3/455 (0.006593406593406593). SV: 253/262 (0.9656488549618321). Mean e: 0.0096. Median e: -0.0002. Std e: 0.1191. \n",
      "17 - Kernels: 3/455 (0.006593406593406593). SV: 258/263 (0.9809885931558935). Mean e: 0.0096. Median e: -0.0002. Std e: 0.1162. \n",
      "18 - Kernels: 3/455 (0.006593406593406593). SV: 261/264 (0.9886363636363636). Mean e: 0.0090. Median e: -0.0001. Std e: 0.1097. \n",
      "19 - Kernels: 3/455 (0.006593406593406593). SV: 254/264 (0.9621212121212122). Mean e: 0.0091. Median e: -0.0001. Std e: 0.1114. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([12.7769, 13.1763, 13.2464, 13.2482, 12.5824, 12.6649, 13.0838, 13.3394, 12.8283, 13.1353,\n",
       "         12.7233, 13.2776, 12.9565, 13.2046, 12.673 , 12.7503, 12.6731, 13.1342, 13.0239, 12.6545]),\n",
       "  'score_time': array([1.666 , 1.6676, 1.675 , 1.6555, 1.661 , 1.6608, 1.6783, 1.677 , 1.6782, 1.6541, 1.6541,\n",
       "         1.6765, 1.679 , 1.6827, 1.664 , 1.772 , 1.6981, 1.6735, 1.653 , 1.6889]),\n",
       "  'test_score': array([0.8652, 0.8409, 0.908 , 0.8621, 0.8539, 0.9205, 0.908 , 0.8506, 0.8202, 0.8523, 0.8966,\n",
       "         0.9425, 0.8989, 0.9091, 0.931 , 0.8276, 0.9438, 0.8295, 0.8621, 0.8276]),\n",
       "  'train_score': array([0.9733, 0.9886, 0.9735, 0.9848, 0.9847, 0.981 , 0.9886, 0.9735, 0.9847, 0.9924, 0.9735,\n",
       "         0.9735, 0.9771, 0.9924, 0.9924, 0.9773, 0.9771, 0.9886, 0.9848, 0.9848])},\n",
       " [{'elapsed_time': 11.674834251403809,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 258,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 12.122445344924927,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 249,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 12.222662925720215,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 258,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.186975002288818,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 245,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.561897993087769,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 253,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.623360633850098,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 256,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 12.063121318817139,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 251,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.19652247428894,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 257,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.79371190071106,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 257,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 12.09228253364563,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 254,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.703805923461914,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 252,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.265169620513916,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 256,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.905695915222168,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 260,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 12.162359476089478,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 259,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.621523380279541,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 261,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.676363468170166,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 258,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.619908332824707,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 253,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 12.071667432785034,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 258,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.94871473312378,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 261,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.617191076278687,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 254,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "ksparse_model = BEMKL(kernels=kernels, hyp_lambda_alpha=1, hyp_lambda_beta=1,\n",
    "                      hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                      hyp_omega_alpha=1e-11, hyp_omega_beta=1e9,\n",
    "                      e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                      filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                      max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "ksparse_pipeline = make_pipeline(Normalizer(), ksparse_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "ksparse_cv_results = cross_validate(ksparse_pipeline, X, y, cv=folds, scoring=scoring)\n",
    "ksparse_stats = deepcopy(scoring.stats)\n",
    "ksparse_cv_results, ksparse_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8775193576602914 +- 0.0396667525776768\n",
      "Time: 11.90651068687439 +- 0.24474368790924794\n",
      "Kernels: 3.0 +- 0.0\n",
      "SVs: 255.5 +- 4.031128874149275\n"
     ]
    }
   ],
   "source": [
    "ksparse_times = np.array([s['elapsed_time'] for s in ksparse_stats])\n",
    "ksparse_kernels = np.array([s['nr_kernels_used'] for s in ksparse_stats])\n",
    "ksparse_sv = np.array([s['nr_sv_used'] for s in ksparse_stats])\n",
    "print(\n",
    "    f\"Score: {ksparse_cv_results['test_score'].mean()} +- {ksparse_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {ksparse_times.mean()} +- {ksparse_times.std()}\\n\"\n",
    "    f\"Kernels: {ksparse_kernels.mean()} +- {ksparse_kernels.std()}\\n\"\n",
    "    f\"SVs: {ksparse_sv.mean()} +- {ksparse_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV-sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 455/455 (1.0). SV: 81/262 (0.30916030534351147). Mean e: 0.0034. Median e: -0.0106. Std e: 0.0898. \n",
      "1 - Kernels: 115/455 (0.25274725274725274). SV: 75/263 (0.28517110266159695). Mean e: 0.0098. Median e: -0.0023. Std e: 0.1011. \n",
      "2 - Kernels: 13/455 (0.02857142857142857). SV: 61/264 (0.23106060606060605). Mean e: 0.0010. Median e: -0.0067. Std e: 0.0964. \n",
      "3 - Kernels: 455/455 (1.0). SV: 84/264 (0.3181818181818182). Mean e: 0.0063. Median e: -0.0127. Std e: 0.1012. \n",
      "4 - Kernels: 115/455 (0.25274725274725274). SV: 85/262 (0.3244274809160305). Mean e: 0.0054. Median e: -0.0093. Std e: 0.1042. \n",
      "5 - Kernels: 13/455 (0.02857142857142857). SV: 65/263 (0.24714828897338403). Mean e: 0.0109. Median e: 0.0013. Std e: 0.1025. \n",
      "6 - Kernels: 455/455 (1.0). SV: 68/264 (0.25757575757575757). Mean e: 0.0046. Median e: -0.0119. Std e: 0.1027. \n",
      "7 - Kernels: 353/455 (0.7758241758241758). SV: 65/264 (0.24621212121212122). Mean e: -0.0014. Median e: -0.0132. Std e: 0.0959. \n",
      "8 - Kernels: 3/455 (0.006593406593406593). SV: 67/262 (0.25572519083969464). Mean e: 0.0064. Median e: -0.0024. Std e: 0.0937. \n",
      "9 - Kernels: 115/455 (0.25274725274725274). SV: 67/263 (0.25475285171102663). Mean e: 0.0112. Median e: -0.0089. Std e: 0.1071. \n",
      "10 - Kernels: 115/455 (0.25274725274725274). SV: 64/264 (0.24242424242424243). Mean e: 0.0039. Median e: -0.0091. Std e: 0.1025. \n",
      "11 - Kernels: 115/455 (0.25274725274725274). SV: 85/264 (0.32196969696969696). Mean e: 0.0079. Median e: -0.0093. Std e: 0.0863. \n",
      "12 - Kernels: 455/455 (1.0). SV: 75/262 (0.2862595419847328). Mean e: 0.0045. Median e: -0.0133. Std e: 0.1135. \n",
      "13 - Kernels: 115/455 (0.25274725274725274). SV: 79/263 (0.30038022813688214). Mean e: 0.0113. Median e: -0.0046. Std e: 0.0872. \n",
      "14 - Kernels: 3/455 (0.006593406593406593). SV: 56/264 (0.21212121212121213). Mean e: 0.0014. Median e: -0.0086. Std e: 0.0957. \n",
      "15 - Kernels: 115/455 (0.25274725274725274). SV: 62/264 (0.23484848484848486). Mean e: 0.0027. Median e: -0.0089. Std e: 0.1020. \n",
      "16 - Kernels: 115/455 (0.25274725274725274). SV: 67/262 (0.25572519083969464). Mean e: 0.0072. Median e: -0.0068. Std e: 0.0981. \n",
      "17 - Kernels: 115/455 (0.25274725274725274). SV: 59/263 (0.22433460076045628). Mean e: 0.0145. Median e: -0.0097. Std e: 0.1065. \n",
      "18 - Kernels: 115/455 (0.25274725274725274). SV: 71/264 (0.2689393939393939). Mean e: 0.0102. Median e: -0.0038. Std e: 0.1005. \n",
      "19 - Kernels: 455/455 (1.0). SV: 66/264 (0.25). Mean e: -0.0032. Median e: -0.0102. Std e: 0.1075. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([12.3501, 13.5023, 14.8478, 12.6714, 12.3837, 12.6628, 13.1383, 13.1392, 13.1558, 12.6334,\n",
       "         12.85  , 12.9905, 13.2905, 12.9656, 12.588 , 12.8194, 12.9544, 13.0225, 12.8811, 12.6993]),\n",
       "  'score_time': array([1.6879, 1.6964, 1.6409, 1.6426, 1.6407, 1.6976, 1.6506, 1.6805, 1.6671, 1.6706, 1.6679,\n",
       "         1.666 , 1.6697, 1.7762, 1.6706, 1.7252, 1.6722, 1.6559, 1.6711, 1.664 ]),\n",
       "  'test_score': array([0.8315, 0.8636, 0.9425, 0.7931, 0.8989, 0.9205, 0.8506, 0.7586, 0.8315, 0.8409, 0.8736,\n",
       "         0.8276, 0.8315, 0.8523, 0.8851, 0.8736, 0.8652, 0.8636, 0.7701, 0.8391]),\n",
       "  'train_score': array([0.9771, 1.    , 0.9773, 0.9962, 0.9924, 0.9924, 0.9962, 0.9848, 0.9885, 1.    , 0.9848,\n",
       "         0.9886, 0.9924, 0.9848, 0.9848, 0.9962, 0.9924, 0.9924, 1.    , 0.9924])},\n",
       " [{'elapsed_time': 11.33696985244751,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 81,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 12.456539392471313,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 75,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 13.782732963562012,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 61,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.661915302276611,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 84,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.37544584274292,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 85,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.61739206314087,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 65,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 12.062368154525757,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 68,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.113091707229614,\n",
       "   'nr_kernels_used': 353,\n",
       "   'nr_sv_used': 65,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.131168603897095,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 67,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.57236933708191,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 67,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.786712884902954,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 64,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.940311908721924,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 85,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.234537124633789,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 75,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.92102861404419,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 79,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.500153064727783,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 56,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.758036375045776,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 62,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.893230199813843,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 67,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.969337224960327,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 59,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.838810920715332,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 71,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.629866361618042,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 66,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "ssparse_model = BEMKL(kernels=kernels,\n",
    "                      hyp_lambda_alpha=1e-11, hyp_lambda_beta=1e9,\n",
    "                      hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                      hyp_omega_alpha=1, hyp_omega_beta=1,\n",
    "                      e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                      filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                      max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "ssparse_pipeline = make_pipeline(Normalizer(), ssparse_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "ssparse_cv_results = cross_validate(ssparse_pipeline, X, y, cv=folds, scoring=scoring)\n",
    "ssparse_stats = deepcopy(scoring.stats)\n",
    "ssparse_cv_results, ssparse_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8506564580324751 +- 0.04390731667720741\n",
      "Time: 11.929100894927979 +- 0.5092721980526712\n",
      "Kernels: 190.5 +- 168.30552575598938\n",
      "SVs: 70.1 +- 8.642337646724988\n"
     ]
    }
   ],
   "source": [
    "ssparse_times = np.array([s['elapsed_time'] for s in ssparse_stats])\n",
    "ssparse_kernels = np.array([s['nr_kernels_used'] for s in ssparse_stats])\n",
    "ssparse_sv = np.array([s['nr_sv_used'] for s in ssparse_stats])\n",
    "print(\n",
    "    f\"Score: {ssparse_cv_results['test_score'].mean()} +- {ssparse_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {ssparse_times.mean()} +- {ssparse_times.std()}\\n\"\n",
    "    f\"Kernels: {ssparse_kernels.mean()} +- {ssparse_kernels.std()}\\n\"\n",
    "    f\"SVs: {ssparse_sv.mean()} +- {ssparse_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('ionosphere_results.json', 'w') as fp:\n",
    "    json.dump(\n",
    "        {\n",
    "            'ksparse': {\n",
    "                'scores': list(ksparse_cv_results['test_score']),\n",
    "                'times': list(ksparse_times),\n",
    "                'kernels': [int(k) for k in ksparse_kernels],\n",
    "                'svs': [int(s) for s in ksparse_sv],\n",
    "            },\n",
    "            'ssparse': {\n",
    "                'scores': list(ssparse_cv_results['test_score']),\n",
    "                'times': list(ssparse_times),\n",
    "                'kernels': [int(k) for k in ssparse_kernels],\n",
    "                'svs': [int(s) for s in ssparse_sv],\n",
    "            },\n",
    "            'base': {\n",
    "                'scores': list(base_cv_results['test_score']),\n",
    "                'times': list(base_times),\n",
    "                'kernels': [int(k) for k in base_kernels],\n",
    "                'svs': [int(s) for s in base_sv],\n",
    "            },\n",
    "            'total_kernels': len(kernels),\n",
    "            'total_sv': len(X_train),\n",
    "        },\n",
    "        fp,\n",
    "        indent=4,\n",
    "        sort_keys=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml",
   "language": "python",
   "name": "pml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
