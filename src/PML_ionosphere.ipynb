{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.io import savemat, loadmat\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (log_loss, mean_squared_error, roc_curve, auc,\n",
    "                             precision_recall_fscore_support, confusion_matrix)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from tqdm import tqdm, trange, tqdm_notebook as tqdmn\n",
    "\n",
    "from BEKML import BEMKL, plot_distplot\n",
    "from utils import poly_kernel, gauss_kernel, scoring, plot_kernel_importances, plot_compare_models\n",
    "\n",
    "sns.set(style='ticks', context='talk')\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "        9  ...       25       26       27       28       29       30       31  \\\n",
       "0  0.03760 ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267 -0.54487   \n",
       "1 -0.04549 ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626 -0.06288   \n",
       "2  0.01198 ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436 -0.24180   \n",
       "3  0.00000 ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682  1.00000   \n",
       "4 -0.16399 ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707 -0.59573   \n",
       "\n",
       "        32       33  34  \n",
       "0  0.18641 -0.45300   1  \n",
       "1 -0.13738 -0.02447  -1  \n",
       "2  0.56045 -0.38238   1  \n",
       "3 -0.32382  1.00000  -1  \n",
       "4 -0.04608 -0.65697   1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.0</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.282051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "      <td>0.960769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1           2           3           4           5   \\\n",
       "count  351.000000  351.0  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738    0.0    0.641342    0.044372    0.601068    0.115889   \n",
       "std      0.311155    0.0    0.497708    0.441435    0.519862    0.460810   \n",
       "min      0.000000    0.0   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.0    0.472135   -0.064735    0.412660   -0.024795   \n",
       "50%      1.000000    0.0    0.871110    0.016310    0.809200    0.022800   \n",
       "75%      1.000000    0.0    1.000000    0.194185    1.000000    0.334655   \n",
       "max      1.000000    0.0    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9      ...              25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000     ...      351.000000   \n",
       "mean     0.550095    0.119360    0.511848    0.181345     ...       -0.071187   \n",
       "std      0.492654    0.520750    0.507066    0.483851     ...        0.508495   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000     ...       -1.000000   \n",
       "25%      0.211310   -0.054840    0.087110   -0.048075     ...       -0.332390   \n",
       "50%      0.728730    0.014710    0.684210    0.018290     ...       -0.015050   \n",
       "75%      0.969240    0.445675    0.953240    0.534195     ...        0.156765   \n",
       "max      1.000000    1.000000    1.000000    1.000000     ...        1.000000   \n",
       "\n",
       "               26          27          28          29          30          31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.541641   -0.069538    0.378445   -0.027907    0.352514   -0.003794   \n",
       "std      0.516205    0.550025    0.575886    0.507974    0.571483    0.513574   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      0.286435   -0.443165    0.000000   -0.236885    0.000000   -0.242595   \n",
       "50%      0.708240   -0.017690    0.496640    0.000000    0.442770    0.000000   \n",
       "75%      0.999945    0.153535    0.883465    0.154075    0.857620    0.200120   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               32          33          34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean     0.349364    0.014480    0.282051  \n",
       "std      0.522663    0.468337    0.960769  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%      0.000000   -0.165350   -1.000000  \n",
       "50%      0.409560    0.000000    1.000000  \n",
       "75%      0.813765    0.171660    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes = {i: float for i in range(35)}\n",
    "dtypes[35] = str\n",
    "data = pd.read_csv('data/ionosphere.csv', names=list(range(35)))#, dtype=dtypes)\n",
    "data.loc[data.loc[:, 34] == 'g', 34] = 1\n",
    "data.loc[data.loc[:, 34] == 'b', 34] = -1\n",
    "data.loc[:, 34] = data.loc[:, 34].astype(int)\n",
    "display(data.head())\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(351,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.28205128205128205"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data.iloc[:, :-1].copy()\n",
    "y = data.iloc[:, -1].copy()\n",
    "N, D = X.shape\n",
    "display(X.shape, y.shape, y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data = data.copy()\n",
    "proc_data.iloc[:, -1] = y\n",
    "proc_data.to_csv('data/proc_ionosphere.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 455)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_init, rbf_end = -3, 7\n",
    "ply_init, ply_end = 1, 4\n",
    "\n",
    "kernel_attrs = [('rbf', 'all', i) for i in range(rbf_init, rbf_end)]\n",
    "kernels = [lambda A, B: gauss_kernel(A, B, 2**i)\n",
    "           for i in range(rbf_init, rbf_end)]\n",
    "\n",
    "kernel_attrs += [('poly', 'all', i) for i in range(ply_init, ply_end)]\n",
    "kernels += [lambda A, B: poly_kernel(A, B, 1, i)\n",
    "            for i in range(ply_init, ply_end)]\n",
    "\n",
    "kernel_attrs += [('rbf', j, i) for i in range(rbf_init, rbf_end)\n",
    "                 for j in range(D)]\n",
    "kernels += [lambda A, B: gauss_kernel(A[:, j:j+1], B[:, j:j+1], 2**i)\n",
    "            for i in range(rbf_init, rbf_end) for j in range(D)]\n",
    "\n",
    "kernel_attrs += [('poly', j, i) for i in range(ply_init, ply_end)\n",
    "                 for j in range(D)]\n",
    "kernels += [lambda A, B: poly_kernel(A[:, j:j+1], B[:, j:j+1], 1, i)\n",
    "            for i in range(ply_init, ply_end) for j in range(D)]\n",
    "len(kernels), len(kernel_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =\\\n",
    "        train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 353/455 (0.7758241758241758). SV: 247/262 (0.9427480916030534). Mean e: -0.0099. Median e: -0.0190. Std e: 0.1232. \n",
      "1 - Kernels: 353/455 (0.7758241758241758). SV: 254/263 (0.9657794676806084). Mean e: -0.0037. Median e: -0.0155. Std e: 0.1129. \n",
      "2 - Kernels: 455/455 (1.0). SV: 260/264 (0.9848484848484849). Mean e: -0.0074. Median e: -0.0231. Std e: 0.1029. \n",
      "3 - Kernels: 455/455 (1.0). SV: 261/264 (0.9886363636363636). Mean e: 0.0009. Median e: -0.0234. Std e: 0.1150. \n",
      "4 - Kernels: 455/455 (1.0). SV: 257/262 (0.9809160305343512). Mean e: -0.0032. Median e: -0.0199. Std e: 0.0996. \n",
      "5 - Kernels: 455/455 (1.0). SV: 257/263 (0.9771863117870723). Mean e: 0.0010. Median e: -0.0233. Std e: 0.1232. \n",
      "6 - Kernels: 353/455 (0.7758241758241758). SV: 260/264 (0.9848484848484849). Mean e: -0.0097. Median e: -0.0214. Std e: 0.1095. \n",
      "7 - Kernels: 455/455 (1.0). SV: 260/264 (0.9848484848484849). Mean e: 0.0000. Median e: -0.0241. Std e: 0.1183. \n",
      "8 - Kernels: 353/455 (0.7758241758241758). SV: 250/262 (0.9541984732824428). Mean e: -0.0112. Median e: -0.0245. Std e: 0.1021. \n",
      "9 - Kernels: 455/455 (1.0). SV: 251/263 (0.9543726235741445). Mean e: -0.0074. Median e: -0.0236. Std e: 0.1284. \n",
      "10 - Kernels: 455/455 (1.0). SV: 259/264 (0.9810606060606061). Mean e: 0.0082. Median e: -0.0230. Std e: 0.1220. \n",
      "11 - Kernels: 455/455 (1.0). SV: 254/264 (0.9621212121212122). Mean e: -0.0077. Median e: -0.0145. Std e: 0.0970. \n",
      "12 - Kernels: 455/455 (1.0). SV: 254/262 (0.9694656488549618). Mean e: 0.0040. Median e: -0.0245. Std e: 0.1194. \n",
      "13 - Kernels: 455/455 (1.0). SV: 260/263 (0.9885931558935361). Mean e: -0.0041. Median e: -0.0225. Std e: 0.1110. \n",
      "14 - Kernels: 455/455 (1.0). SV: 251/264 (0.9507575757575758). Mean e: -0.0053. Median e: -0.0234. Std e: 0.1088. \n",
      "15 - Kernels: 455/455 (1.0). SV: 254/264 (0.9621212121212122). Mean e: -0.0074. Median e: -0.0208. Std e: 0.1107. \n",
      "16 - Kernels: 455/455 (1.0). SV: 254/262 (0.9694656488549618). Mean e: -0.0059. Median e: -0.0217. Std e: 0.1020. \n",
      "17 - Kernels: 455/455 (1.0). SV: 253/263 (0.9619771863117871). Mean e: -0.0062. Median e: -0.0229. Std e: 0.1238. \n",
      "18 - Kernels: 455/455 (1.0). SV: 255/264 (0.9659090909090909). Mean e: 0.0030. Median e: -0.0235. Std e: 0.1222. \n",
      "19 - Kernels: 455/455 (1.0). SV: 256/264 (0.9696969696969697). Mean e: 0.0003. Median e: -0.0146. Std e: 0.1013. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([19.0565, 13.0283, 12.8575, 12.6382, 12.5832, 12.7646, 12.8212, 13.0716, 12.791 , 12.6556,\n",
       "         13.1319, 13.3079, 12.518 , 12.529 , 12.4953, 13.7928, 12.4653, 12.5789, 12.685 , 12.5692]),\n",
       "  'score_time': array([2.0993, 1.6388, 1.6471, 1.6336, 1.6465, 1.6377, 1.6868, 1.641 , 1.6353, 1.6404, 1.6911,\n",
       "         1.6216, 1.6342, 1.6639, 1.6407, 1.6313, 1.6166, 1.629 , 1.6144, 1.6345]),\n",
       "  'test_score': array([0.8764, 0.8977, 0.8276, 0.8851, 0.9438, 0.8182, 0.8851, 0.8506, 0.9438, 0.9205, 0.8276,\n",
       "         0.8276, 0.8539, 0.875 , 0.8506, 0.9195, 0.9101, 0.9318, 0.8621, 0.7816]),\n",
       "  'train_score': array([0.9962, 0.9772, 0.9659, 0.9811, 0.9695, 0.981 , 0.9848, 0.9811, 0.9656, 0.9886, 0.9924,\n",
       "         0.9773, 0.9771, 0.9734, 0.9735, 0.9886, 0.9733, 0.9886, 0.9886, 0.9886])},\n",
       " [{'elapsed_time': 17.876033544540405,\n",
       "   'nr_kernels_used': 353,\n",
       "   'nr_sv_used': 247,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.930845022201538,\n",
       "   'nr_kernels_used': 353,\n",
       "   'nr_sv_used': 254,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.84241271018982,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 260,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.577307939529419,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 261,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.539868354797363,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 257,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.711846351623535,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 257,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.764875888824463,\n",
       "   'nr_kernels_used': 353,\n",
       "   'nr_sv_used': 260,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.011139154434204,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 260,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.73794150352478,\n",
       "   'nr_kernels_used': 353,\n",
       "   'nr_sv_used': 250,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.5968496799469,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 251,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 12.077332973480225,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 259,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.244245052337646,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 254,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.329099655151367,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 254,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.468164205551147,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 260,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.431698083877563,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 251,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 12.730753660202026,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 254,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.459062576293945,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 254,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.56963562965393,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 253,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.669740676879883,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 255,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.556985855102539,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 256,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264}])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "base_model = BEMKL(kernels=kernels, hyp_lambda_alpha=1, hyp_lambda_beta=1,\n",
    "                   hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                   hyp_omega_alpha=1, hyp_omega_beta=1,\n",
    "                   e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                   filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                   max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "base_model = make_pipeline(Normalizer(), base_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "base_cv_results = cross_validate(base_model, X, y, cv=folds, scoring=scoring)\n",
    "base_stats = deepcopy(scoring.stats)\n",
    "base_cv_results, base_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8744256542566307 +- 0.044269840764805356\n",
      "Time: 12.056291925907136 +- 1.3728212811823715\n",
      "Kernels: 434.6 +- 40.8\n",
      "SVs: 255.35 +- 3.79835490706174\n"
     ]
    }
   ],
   "source": [
    "base_times = np.array([s['elapsed_time'] for s in base_stats])\n",
    "base_kernels = np.array([s['nr_kernels_used'] for s in base_stats])\n",
    "base_sv = np.array([s['nr_sv_used'] for s in base_stats])\n",
    "print(\n",
    "    f\"Score: {base_cv_results['test_score'].mean()} +- {base_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {base_times.mean()} +- {base_times.std()}\\n\"\n",
    "    f\"Kernels: {base_kernels.mean()} +- {base_kernels.std()}\\n\"\n",
    "    f\"SVs: {base_sv.mean()} +- {base_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel-sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 3/455 (0.006593406593406593). SV: 249/262 (0.950381679389313). Mean e: 0.0090. Median e: -0.0002. Std e: 0.1108. \n",
      "1 - Kernels: 3/455 (0.006593406593406593). SV: 255/263 (0.9695817490494296). Mean e: 0.0086. Median e: -0.0001. Std e: 0.1031. \n",
      "2 - Kernels: 3/455 (0.006593406593406593). SV: 255/264 (0.9659090909090909). Mean e: 0.0098. Median e: -0.0002. Std e: 0.1064. \n",
      "3 - Kernels: 3/455 (0.006593406593406593). SV: 263/264 (0.9962121212121212). Mean e: 0.0083. Median e: -0.0002. Std e: 0.1021. \n",
      "4 - Kernels: 3/455 (0.006593406593406593). SV: 259/262 (0.9885496183206107). Mean e: 0.0091. Median e: -0.0002. Std e: 0.1124. \n",
      "5 - Kernels: 3/455 (0.006593406593406593). SV: 262/263 (0.9961977186311787). Mean e: 0.0095. Median e: -0.0002. Std e: 0.1170. \n",
      "6 - Kernels: 3/455 (0.006593406593406593). SV: 258/264 (0.9772727272727273). Mean e: 0.0085. Median e: -0.0002. Std e: 0.1061. \n",
      "7 - Kernels: 105/455 (0.23076923076923078). SV: 251/264 (0.9507575757575758). Mean e: 0.0116. Median e: -0.0002. Std e: 0.1137. \n",
      "8 - Kernels: 3/455 (0.006593406593406593). SV: 255/262 (0.9732824427480916). Mean e: 0.0096. Median e: -0.0002. Std e: 0.1195. \n",
      "9 - Kernels: 3/455 (0.006593406593406593). SV: 259/263 (0.9847908745247148). Mean e: 0.0092. Median e: -0.0002. Std e: 0.1109. \n",
      "10 - Kernels: 3/455 (0.006593406593406593). SV: 253/264 (0.9583333333333334). Mean e: 0.0080. Median e: -0.0002. Std e: 0.0987. \n",
      "11 - Kernels: 3/455 (0.006593406593406593). SV: 247/264 (0.9356060606060606). Mean e: 0.0096. Median e: -0.0002. Std e: 0.1157. \n",
      "12 - Kernels: 3/455 (0.006593406593406593). SV: 257/262 (0.9809160305343512). Mean e: 0.0082. Median e: -0.0002. Std e: 0.1013. \n",
      "13 - Kernels: 3/455 (0.006593406593406593). SV: 247/263 (0.9391634980988594). Mean e: 0.0086. Median e: -0.0002. Std e: 0.1066. \n",
      "14 - Kernels: 3/455 (0.006593406593406593). SV: 254/264 (0.9621212121212122). Mean e: 0.0093. Median e: -0.0001. Std e: 0.1101. \n",
      "15 - Kernels: 3/455 (0.006593406593406593). SV: 257/264 (0.9734848484848485). Mean e: 0.0086. Median e: -0.0001. Std e: 0.1031. \n",
      "16 - Kernels: 3/455 (0.006593406593406593). SV: 256/262 (0.9770992366412213). Mean e: 0.0095. Median e: -0.0001. Std e: 0.1155. \n",
      "17 - Kernels: 3/455 (0.006593406593406593). SV: 251/263 (0.9543726235741445). Mean e: 0.0101. Median e: -0.0001. Std e: 0.1182. \n",
      "18 - Kernels: 3/455 (0.006593406593406593). SV: 257/264 (0.9734848484848485). Mean e: 0.0087. Median e: -0.0001. Std e: 0.1061. \n",
      "19 - Kernels: 3/455 (0.006593406593406593). SV: 253/264 (0.9583333333333334). Mean e: 0.0081. Median e: -0.0002. Std e: 0.1011. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([12.8814, 12.5282, 12.7707, 12.5508, 12.1169, 12.5121, 12.346 , 12.3196, 12.7863, 12.6238,\n",
       "         12.6619, 12.6043, 12.4087, 12.996 , 12.5492, 12.5955, 12.5875, 12.6918, 12.6889, 12.7538]),\n",
       "  'score_time': array([1.6292, 1.6319, 1.6571, 1.6448, 1.6348, 1.6369, 1.6403, 1.636 , 1.6721, 1.6476, 1.6315,\n",
       "         1.7303, 1.6347, 1.6636, 1.6771, 1.6495, 1.6671, 1.6648, 1.6185, 1.7122]),\n",
       "  'test_score': array([0.8539, 0.9091, 0.908 , 0.931 , 0.9101, 0.8636, 0.8621, 0.8161, 0.8652, 0.9205, 0.8736,\n",
       "         0.8506, 0.8989, 0.8295, 0.8391, 0.8966, 0.8876, 0.8636, 0.8736, 0.8966]),\n",
       "  'train_score': array([0.9962, 0.9734, 0.9735, 0.9735, 0.9733, 0.9772, 0.9811, 0.9848, 0.9885, 0.9734, 0.9659,\n",
       "         0.9924, 0.9695, 0.981 , 0.9924, 0.9659, 0.9771, 0.9886, 0.9773, 0.9697])},\n",
       " [{'elapsed_time': 11.85596776008606,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 249,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.50810718536377,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 255,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.744829654693604,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 255,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.498770952224731,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 263,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.071604013442993,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 259,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.47491979598999,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 262,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.284440755844116,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 258,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.274663925170898,\n",
       "   'nr_kernels_used': 105,\n",
       "   'nr_sv_used': 251,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.594937324523926,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 255,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.581872463226318,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 259,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.612293004989624,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 253,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.565019845962524,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 247,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.37147569656372,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 257,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.940100908279419,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 247,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.501603841781616,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 254,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.557064294815063,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 257,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.571883201599121,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 256,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.626044273376465,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 251,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.661243200302124,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 257,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.724530220031738,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 253,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264}])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "ksparse_model = BEMKL(kernels=kernels, hyp_lambda_alpha=1, hyp_lambda_beta=1,\n",
    "                      hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                      hyp_omega_alpha=1e-11, hyp_omega_beta=1e9,\n",
    "                      e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                      filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                      max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "ksparse_pipeline = make_pipeline(Normalizer(), ksparse_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "ksparse_cv_results = cross_validate(ksparse_pipeline, X, y, cv=folds, scoring=scoring)\n",
    "ksparse_stats = deepcopy(scoring.stats)\n",
    "ksparse_cv_results, ksparse_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8774610205111948 +- 0.030515527451685762\n",
      "Time: 11.55106861591339 +- 0.19486447788724603\n",
      "Kernels: 8.1 +- 22.23038461205744\n",
      "SVs: 254.9 +- 4.31161222746202\n"
     ]
    }
   ],
   "source": [
    "ksparse_times = np.array([s['elapsed_time'] for s in ksparse_stats])\n",
    "ksparse_kernels = np.array([s['nr_kernels_used'] for s in ksparse_stats])\n",
    "ksparse_sv = np.array([s['nr_sv_used'] for s in ksparse_stats])\n",
    "print(\n",
    "    f\"Score: {ksparse_cv_results['test_score'].mean()} +- {ksparse_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {ksparse_times.mean()} +- {ksparse_times.std()}\\n\"\n",
    "    f\"Kernels: {ksparse_kernels.mean()} +- {ksparse_kernels.std()}\\n\"\n",
    "    f\"SVs: {ksparse_sv.mean()} +- {ksparse_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV-sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Kernels: 115/455 (0.25274725274725274). SV: 79/262 (0.3015267175572519). Mean e: 0.0143. Median e: -0.0088. Std e: 0.1016. \n",
      "1 - Kernels: 3/455 (0.006593406593406593). SV: 74/263 (0.2813688212927757). Mean e: 0.0050. Median e: -0.0072. Std e: 0.1075. \n",
      "2 - Kernels: 13/455 (0.02857142857142857). SV: 87/264 (0.32954545454545453). Mean e: 0.0047. Median e: -0.0041. Std e: 0.0934. \n",
      "3 - Kernels: 115/455 (0.25274725274725274). SV: 83/264 (0.3143939393939394). Mean e: -0.0012. Median e: -0.0082. Std e: 0.1016. \n",
      "4 - Kernels: 353/455 (0.7758241758241758). SV: 67/262 (0.25572519083969464). Mean e: -0.0007. Median e: -0.0113. Std e: 0.1069. \n",
      "5 - Kernels: 455/455 (1.0). SV: 90/263 (0.34220532319391633). Mean e: 0.0050. Median e: -0.0160. Std e: 0.0956. \n",
      "6 - Kernels: 13/455 (0.02857142857142857). SV: 69/264 (0.26136363636363635). Mean e: 0.0046. Median e: -0.0046. Std e: 0.1046. \n",
      "7 - Kernels: 13/455 (0.02857142857142857). SV: 91/264 (0.3446969696969697). Mean e: 0.0107. Median e: 0.0033. Std e: 0.0954. \n",
      "8 - Kernels: 105/455 (0.23076923076923078). SV: 70/262 (0.26717557251908397). Mean e: 0.0098. Median e: -0.0098. Std e: 0.1036. \n",
      "9 - Kernels: 13/455 (0.02857142857142857). SV: 76/263 (0.2889733840304182). Mean e: 0.0058. Median e: -0.0016. Std e: 0.0963. \n",
      "10 - Kernels: 445/455 (0.978021978021978). SV: 89/264 (0.3371212121212121). Mean e: 0.0050. Median e: -0.0147. Std e: 0.0973. \n",
      "11 - Kernels: 13/455 (0.02857142857142857). SV: 63/264 (0.23863636363636365). Mean e: 0.0046. Median e: -0.0044. Std e: 0.0928. \n",
      "12 - Kernels: 455/455 (1.0). SV: 66/262 (0.25190839694656486). Mean e: 0.0057. Median e: -0.0118. Std e: 0.1055. \n",
      "13 - Kernels: 455/455 (1.0). SV: 68/263 (0.2585551330798479). Mean e: 0.0013. Median e: -0.0167. Std e: 0.0844. \n",
      "14 - Kernels: 13/455 (0.02857142857142857). SV: 78/264 (0.29545454545454547). Mean e: 0.0045. Median e: -0.0049. Std e: 0.0908. \n",
      "15 - Kernels: 115/455 (0.25274725274725274). SV: 76/264 (0.2878787878787879). Mean e: 0.0081. Median e: -0.0051. Std e: 0.0970. \n",
      "16 - Kernels: 115/455 (0.25274725274725274). SV: 87/262 (0.3320610687022901). Mean e: 0.0042. Median e: -0.0084. Std e: 0.0938. \n",
      "17 - Kernels: 455/455 (1.0). SV: 78/263 (0.2965779467680608). Mean e: 0.0077. Median e: -0.0159. Std e: 0.1085. \n",
      "18 - Kernels: 455/455 (1.0). SV: 63/264 (0.23863636363636365). Mean e: 0.0012. Median e: -0.0142. Std e: 0.1046. \n",
      "19 - Kernels: 115/455 (0.25274725274725274). SV: 58/264 (0.2196969696969697). Mean e: 0.0035. Median e: -0.0025. Std e: 0.0963. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtambos/anaconda/envs/pml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([12.5261, 12.485 , 12.5159, 12.5742, 12.2896, 12.4813, 12.9318, 12.8103, 12.5811, 12.5133,\n",
       "         12.4392, 12.7345, 12.4365, 12.5706, 12.6374, 13.0286, 12.492 , 12.5688, 12.4701, 12.9897]),\n",
       "  'score_time': array([1.6526, 1.6405, 1.6177, 1.6451, 1.6385, 1.7552, 1.6339, 1.6521, 1.6433, 1.641 , 1.6362,\n",
       "         1.6445, 1.6403, 1.6368, 1.6641, 1.6808, 1.657 , 1.6344, 1.6159, 1.6467]),\n",
       "  'test_score': array([0.8315, 0.8295, 0.8851, 0.8506, 0.7753, 0.875 , 0.8276, 0.8736, 0.8315, 0.8409, 0.8621,\n",
       "         0.8046, 0.8876, 0.8409, 0.8851, 0.8506, 0.8539, 0.9091, 0.8966, 0.7816]),\n",
       "  'train_score': array([0.9924, 1.    , 0.9886, 0.9962, 0.9885, 0.9848, 0.9962, 0.9886, 0.9885, 0.9962, 0.9886,\n",
       "         0.9848, 0.9924, 0.962 , 0.9773, 0.9886, 0.9924, 0.9924, 0.9886, 0.9886])},\n",
       " [{'elapsed_time': 11.487034559249878,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 79,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.433372735977173,\n",
       "   'nr_kernels_used': 3,\n",
       "   'nr_sv_used': 74,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.450491666793823,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 87,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.51563024520874,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 83,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.246237993240356,\n",
       "   'nr_kernels_used': 353,\n",
       "   'nr_sv_used': 67,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.42712688446045,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 90,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.877650499343872,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 69,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.738378047943115,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 91,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.546751499176025,\n",
       "   'nr_kernels_used': 105,\n",
       "   'nr_sv_used': 70,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.478834390640259,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 76,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.41777753829956,\n",
       "   'nr_kernels_used': 445,\n",
       "   'nr_sv_used': 89,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.710241556167603,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 63,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.424093246459961,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 66,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.552188396453857,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 68,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.581489324569702,\n",
       "   'nr_kernels_used': 13,\n",
       "   'nr_sv_used': 78,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.968244552612305,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 76,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.448949098587036,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 87,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 262},\n",
       "  {'elapsed_time': 11.523426294326782,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 78,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 263},\n",
       "  {'elapsed_time': 11.44627070426941,\n",
       "   'nr_kernels_used': 455,\n",
       "   'nr_sv_used': 63,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264},\n",
       "  {'elapsed_time': 11.980033874511719,\n",
       "   'nr_kernels_used': 115,\n",
       "   'nr_sv_used': 58,\n",
       "   'total_kernels': 455,\n",
       "   'total_sv': 264}])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 200\n",
    "ssparse_model = BEMKL(kernels=kernels,\n",
    "                      hyp_lambda_alpha=1e-11, hyp_lambda_beta=1e9,\n",
    "                      hyp_gamma_alpha=1, hyp_gamma_beta=1,\n",
    "                      hyp_omega_alpha=1, hyp_omega_beta=1,\n",
    "                      e_null_thrsh=1e-2, a_null_thrsh=1e-2,\n",
    "                      filter_kernels=False, filter_sv=False, verbose=False,\n",
    "                      max_iter=max_iter, hyperopt_enabled=False, calculate_bounds=False)\n",
    "ssparse_pipeline = make_pipeline(Normalizer(), ssparse_model)\n",
    "\n",
    "scoring.iteration = 0\n",
    "scoring.stats = []\n",
    "folds = RepeatedStratifiedKFold(n_splits=4, n_repeats=5)\n",
    "ssparse_cv_results = cross_validate(ssparse_pipeline, X, y, cv=folds, scoring=scoring)\n",
    "ssparse_stats = deepcopy(scoring.stats)\n",
    "ssparse_cv_results, ssparse_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8496235602831884 +- 0.03533264454769601\n",
      "Time: 11.562711155414581 +- 0.1900325688305627\n",
      "Kernels: 191.7 +- 187.2103362531033\n",
      "SVs: 75.6 +- 9.723168207945392\n"
     ]
    }
   ],
   "source": [
    "ssparse_times = np.array([s['elapsed_time'] for s in ssparse_stats])\n",
    "ssparse_kernels = np.array([s['nr_kernels_used'] for s in ssparse_stats])\n",
    "ssparse_sv = np.array([s['nr_sv_used'] for s in ssparse_stats])\n",
    "print(\n",
    "    f\"Score: {ssparse_cv_results['test_score'].mean()} +- {ssparse_cv_results['test_score'].std()}\\n\"\n",
    "    f\"Time: {ssparse_times.mean()} +- {ssparse_times.std()}\\n\"\n",
    "    f\"Kernels: {ssparse_kernels.mean()} +- {ssparse_kernels.std()}\\n\"\n",
    "    f\"SVs: {ssparse_sv.mean()} +- {ssparse_sv.std()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('ionosphere_results.json', 'w') as fp:\n",
    "    json.dump(\n",
    "        {\n",
    "            'ksparse': {\n",
    "                'scores': list(ksparse_cv_results['test_score']),\n",
    "                'times': list(ksparse_times),\n",
    "                'kernels': [int(k) for k in ksparse_kernels],\n",
    "                'svs': [int(s) for s in ksparse_sv],\n",
    "            },\n",
    "            'ssparse': {\n",
    "                'scores': list(ssparse_cv_results['test_score']),\n",
    "                'times': list(ssparse_times),\n",
    "                'kernels': [int(k) for k in ksparse_kernels],\n",
    "                'svs': [int(s) for s in ssparse_sv],\n",
    "            },\n",
    "            'base': {\n",
    "                'scores': list(base_cv_results['test_score']),\n",
    "                'times': list(base_times),\n",
    "                'kernels': [int(k) for k in base_kernels],\n",
    "                'svs': [int(s) for s in base_sv],\n",
    "            },\n",
    "            'total_kernels': len(kernels),\n",
    "            'total_sv': len(X_train),\n",
    "        },\n",
    "        fp,\n",
    "        indent=4,\n",
    "        sort_keys=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml",
   "language": "python",
   "name": "pml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
