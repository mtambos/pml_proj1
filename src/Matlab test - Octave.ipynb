{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function y = psi(x)\n",
    "    %DIGAMMA   Digamma function.\n",
    "    % DIGAMMA(X) returns digamma(x) = d log(gamma(x)) / dx\n",
    "    % If X is a matrix, returns the digamma function evaluated at each element.\n",
    "\n",
    "    % Reference:\n",
    "    %\n",
    "    %    J Bernardo,\n",
    "    %    Psi ( Digamma ) Function,\n",
    "    %    Algorithm AS 103,\n",
    "    %    Applied Statistics,\n",
    "    %    Volume 25, Number 3, pages 315-317, 1976.\n",
    "    %\n",
    "    % From http://www.psc.edu/~burkardt/src/dirichlet/dirichlet.f\n",
    "\n",
    "    large = 9.5;\n",
    "    d1 = -0.5772156649015328606065121;  % digamma(1)\n",
    "    d2 = pi^2/6;\n",
    "    small = 1e-6;\n",
    "    s3 = 1/12;\n",
    "    s4 = 1/120;\n",
    "    s5 = 1/252;\n",
    "    s6 = 1/240;\n",
    "    s7 = 1/132;\n",
    "    s8 = 691/32760;\n",
    "    s9 = 1/12;\n",
    "    s10 = 3617/8160;\n",
    "\n",
    "    % Initialize\n",
    "    y = zeros(size(x));\n",
    "\n",
    "    % illegal arguments\n",
    "    i = find(x == -Inf | isnan(x));\n",
    "    if ~isempty(i)\n",
    "        x(i) = NaN;\n",
    "        y(i) = NaN;\n",
    "    end\n",
    "\n",
    "    % Negative values\n",
    "    i = find(x < 0);\n",
    "    if ~isempty(i)\n",
    "        % Use the reflection formula (Jeffrey 11.1.6):\n",
    "        % digamma(-x) = digamma(x+1) + pi*cot(pi*x)\n",
    "        y(i) = digamma(-x(i)+1) + pi*cot(-pi*x(i));\n",
    "        % This is related to the identity\n",
    "        % digamma(-x) = digamma(x+1) - digamma(z) + digamma(1-z)\n",
    "        % where z is the fractional part of x\n",
    "        % For example:\n",
    "        % digamma(-3.1) = 1/3.1 + 1/2.1 + 1/1.1 + 1/0.1 + digamma(1-0.1)\n",
    "        %               = digamma(4.1) - digamma(0.1) + digamma(1-0.1)\n",
    "        % Then we use\n",
    "        % digamma(1-z) - digamma(z) = pi*cot(pi*z)\n",
    "    end\n",
    "\n",
    "    i = find(x == 0);\n",
    "    if ~isempty(i)\n",
    "        y(i) = -Inf;\n",
    "    end\n",
    "\n",
    "    %  Use approximation if argument <= small.\n",
    "    i = find(x > 0 & x <= small);\n",
    "    if ~isempty(i)\n",
    "        y(i) = y(i) + d1 - 1 ./ x(i) + d2*x(i);\n",
    "    end\n",
    "\n",
    "    %  Reduce to digamma(X + N) where (X + N) >= large.\n",
    "    while(1)\n",
    "        i = find(x > small & x < large);\n",
    "        if isempty(i)\n",
    "            break\n",
    "          end\n",
    "        y(i) = y(i) - 1 ./ x(i);\n",
    "        x(i) = x(i) + 1;\n",
    "    end\n",
    "\n",
    "    %  Use de Moivre's expansion if argument >= large.\n",
    "    % In maple: asympt(Psi(x), x);\n",
    "    i = find(x >= large);\n",
    "    if ~isempty(i)\n",
    "        r = 1 ./ x(i);\n",
    "        y(i) = y(i) + log(x(i)) - 0.5 * r;\n",
    "        r = r .* r;\n",
    "        y(i) = y(i) - r .* ( s3 - r .* ( s4 - r .* (s5 - r .* (s6 - r .* s7))));\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function state = bemkl_supervised_classification_variational_train(Km, y, parameters)\n",
    "    rand('state', parameters.seed); %#ok<RAND>\n",
    "    randn('state', parameters.seed); %#ok<RAND>\n",
    "\n",
    "    D = size(Km, 1);\n",
    "    N = size(Km, 2);\n",
    "    P = size(Km, 3);\n",
    "    sigma_g = parameters.sigma_g;\n",
    "\n",
    "    log2pi = log(2 * pi);\n",
    "\n",
    "    lambda.alpha = (parameters.alpha_lambda + 0.5) * ones(D, 1);\n",
    "    lambda.beta = parameters.beta_lambda * ones(D, 1);\n",
    "    a.mu = randn(D, 1);\n",
    "    a.sigma = eye(D, D);\n",
    "    G.mu = (abs(randn(P, N)) + parameters.margin) .* sign(repmat(y', P, 1));\n",
    "    G.sigma = eye(P, P);\n",
    "    gamma.alpha = (parameters.alpha_gamma + 0.5);\n",
    "    gamma.beta = parameters.beta_gamma;\n",
    "    omega.alpha = (parameters.alpha_omega + 0.5) * ones(P, 1);\n",
    "    omega.beta = parameters.beta_omega * ones(P, 1);\n",
    "    be.mu = [0; ones(P, 1)];\n",
    "    be.sigma = eye(P + 1, P + 1);\n",
    "    f.mu = (abs(randn(N, 1)) + parameters.margin) .* sign(y);\n",
    "    f.sigma = ones(N, 1);\n",
    "\n",
    "    KmKm = zeros(D, D);\n",
    "    for m = 1:P\n",
    "        KmKm = KmKm + Km(:, :, m) * Km(:, :, m)';\n",
    "    end\n",
    "    Km = reshape(Km, [D, N * P]);\n",
    "\n",
    "    lower = -1e40 * ones(N, 1);\n",
    "    lower(y > 0) = +parameters.margin;\n",
    "    upper = +1e40 * ones(N, 1);\n",
    "    upper(y < 0) = -parameters.margin;\n",
    "\n",
    "    if parameters.progress == 1\n",
    "        bounds = zeros(parameters.iteration, 1);\n",
    "    end\n",
    "    \n",
    "    atimesaT.mu = a.mu * a.mu' + a.sigma;\n",
    "    GtimesGT.mu = G.mu * G.mu' + N * G.sigma;\n",
    "    btimesbT.mu = be.mu(1)^2 + be.sigma(1, 1);\n",
    "    etimeseT.mu = be.mu(2:P + 1) * be.mu(2:P + 1)' + be.sigma(2:P + 1, 2:P + 1);\n",
    "    etimesb.mu = be.mu(2:P + 1) * be.mu(1) + be.sigma(2:P + 1, 1);\n",
    "    KmtimesGT.mu = Km * reshape(G.mu', N * P, 1);\n",
    "    for iter = 1:parameters.iteration\n",
    "        %%%% update lambda\n",
    "        lambda.beta = 1 ./ (1 / parameters.beta_lambda + 0.5 * diag(atimesaT.mu));\n",
    "        %%%% update a\n",
    "        a.sigma = (diag(lambda.alpha .* lambda.beta) + KmKm / sigma_g^2) \\ eye(D, D);\n",
    "        a.mu = a.sigma * KmtimesGT.mu / sigma_g^2;\n",
    "        atimesaT.mu = a.mu * a.mu' + a.sigma;\n",
    "        %%%% update G\n",
    "        G.sigma = (eye(P, P) / sigma_g^2 + etimeseT.mu) \\ eye(P, P);\n",
    "        G.mu = G.sigma * (reshape(a.mu' * Km, [N, P])' / sigma_g^2 + be.mu(2:P + 1) * f.mu' - repmat(etimesb.mu, 1, N));\n",
    "        GtimesGT.mu = G.mu * G.mu' + N * G.sigma;\n",
    "        KmtimesGT.mu = Km * reshape(G.mu', N * P, 1);\n",
    "        %%%% update gamma\n",
    "        gamma.beta = 1 / (1 / parameters.beta_gamma + 0.5 * btimesbT.mu);\n",
    "        %%%% update omega\n",
    "        omega.beta = 1 ./ (1 / parameters.beta_omega + 0.5 * diag(etimeseT.mu));\n",
    "        %%%% update b and e\n",
    "        be.sigma = [gamma.alpha * gamma.beta + N, sum(G.mu, 2)'; sum(G.mu, 2), diag(omega.alpha .* omega.beta) + GtimesGT.mu] \\ eye(P + 1, P + 1);\n",
    "        be.mu = be.sigma * ([ones(1, N); G.mu] * f.mu);\n",
    "        btimesbT.mu = be.mu(1)^2 + be.sigma(1, 1);\n",
    "        etimeseT.mu = be.mu(2:P + 1) * be.mu(2:P + 1)' + be.sigma(2:P + 1, 2:P + 1);\n",
    "        etimesb.mu = be.mu(2:P + 1) * be.mu(1) + be.sigma(2:P + 1, 1);\n",
    "        %%%% update f\n",
    "        output = [ones(1, N); G.mu]' * be.mu;\n",
    "        alpha_norm = lower - output;\n",
    "        beta_norm = upper - output;\n",
    "        normalization = normcdf(beta_norm) - normcdf(alpha_norm);\n",
    "        normalization(normalization == 0) = 1;\n",
    "        f.mu = output + (normpdf(alpha_norm) - normpdf(beta_norm)) ./ normalization;\n",
    "        f.sigma = 1 + (alpha_norm .* normpdf(alpha_norm) - beta_norm .* normpdf(beta_norm)) ./ normalization - (normpdf(alpha_norm) - normpdf(beta_norm)).^2 ./ normalization.^2;\n",
    "\n",
    "        if parameters.progress == 1\n",
    "            lb = 0;\n",
    "\n",
    "            %%%% p(lambda)\n",
    "            lb = (lb +\n",
    "                  sum(\n",
    "                      (parameters.alpha_lambda - 1) * (psi(lambda.alpha) + log(lambda.beta)) -\n",
    "                       gammaln(parameters.alpha_lambda) -\n",
    "                       lambda.alpha .* lambda.beta / parameters.beta_lambda -\n",
    "                       parameters.alpha_lambda * log(parameters.beta_lambda)\n",
    "                  )\n",
    "                );\n",
    "\n",
    "            %%%% p(a | lambda)\n",
    "            lb = (lb -\n",
    "                  0.5 * sum(lambda.alpha .* lambda.beta .* diag(atimesaT.mu)) -\n",
    "                  0.5 * (D * log2pi - sum(psi(lambda.alpha) + log(lambda.beta))));\n",
    "            \n",
    "            %%%% p(G | a, Km)\n",
    "            lb = (lb -\n",
    "                  0.5 * sigma_g^-2 * sum(diag(GtimesGT.mu)) +\n",
    "                  sigma_g^-2 * a.mu' * KmtimesGT.mu -\n",
    "                  0.5 * sigma_g^-2 * sum(sum(KmKm .* atimesaT.mu)) -\n",
    "                  0.5 * N * P * (log2pi + 2 * log(sigma_g))\n",
    "            );\n",
    "\n",
    "            %%%% p(gamma)\n",
    "            lb = (lb +\n",
    "                  (parameters.alpha_gamma - 1) * (psi(gamma.alpha) + log(gamma.beta)) -\n",
    "                  gamma.alpha * gamma.beta / parameters.beta_gamma -\n",
    "                  gammaln(parameters.alpha_gamma) -\n",
    "                  parameters.alpha_gamma * log(parameters.beta_gamma)\n",
    "            );\n",
    "            %%%% p(b | gamma)\n",
    "            lb = (lb -\n",
    "                  0.5 * gamma.alpha * gamma.beta * btimesbT.mu -\n",
    "                  0.5 * (log2pi - (psi(gamma.alpha) + log(gamma.beta)))\n",
    "            );\n",
    "            %%%% p(omega)\n",
    "            lb = (lb +\n",
    "                  sum(\n",
    "                      (parameters.alpha_omega - 1) * (psi(omega.alpha) + log(omega.beta)) -\n",
    "                      omega.alpha .* omega.beta / parameters.beta_omega -\n",
    "                      gammaln(parameters.alpha_omega) -\n",
    "                      parameters.alpha_omega * log(parameters.beta_omega)\n",
    "                  )\n",
    "            );\n",
    "            %%%% p(e | omega)\n",
    "            lb = (lb -\n",
    "                  0.5 * sum(omega.alpha .* omega.beta .* diag(etimeseT.mu)) -\n",
    "                  0.5 * (P * log2pi - sum(psi(omega.alpha) + log(omega.beta)))\n",
    "            );\n",
    "            %%%% p(f | b, e, G)\n",
    "            lb = (lb -\n",
    "                  0.5 * (f.mu' * f.mu + sum(f.sigma)) +\n",
    "                  f.mu' * (G.mu' * be.mu(2:P + 1)) +\n",
    "                  sum(be.mu(1) * f.mu) -\n",
    "                  0.5 * sum(sum(etimeseT.mu .* GtimesGT.mu)) -\n",
    "                  sum(G.mu' * etimesb.mu) -\n",
    "                  0.5 * N * btimesbT.mu - 0.5 * N * log2pi\n",
    "            );\n",
    "\n",
    "            %%%% q(lambda)\n",
    "            lb = (lb +\n",
    "                  sum(lambda.alpha +\n",
    "                      log(lambda.beta) +\n",
    "                      gammaln(lambda.alpha) +\n",
    "                      (1 - lambda.alpha) .* psi(lambda.alpha)\n",
    "                   )\n",
    "            );\n",
    "            %%%% q(a)\n",
    "            lb = lb + 0.5 * (D * (log2pi + 1) + logdet(a.sigma));\n",
    "            %%%% q(G)\n",
    "            lb = lb + 0.5 * N * (P * (log2pi + 1) + logdet(G.sigma));\n",
    "            %%%% q(gamma)\n",
    "            lb = lb + gamma.alpha + log(gamma.beta) + gammaln(gamma.alpha) + (1 - gamma.alpha) * psi(gamma.alpha);\n",
    "            %%%% q(omega)\n",
    "            lb = lb + sum(omega.alpha + log(omega.beta) + gammaln(omega.alpha) + (1 - omega.alpha) .* psi(omega.alpha));\n",
    "            %%%% q(b, e)\n",
    "            lb = lb + 0.5 * ((P + 1) * (log2pi + 1) + logdet(be.sigma));\n",
    "            %%%% q(f)\n",
    "            lb = lb + 0.5 * sum(log2pi + f.sigma) + sum(log(normalization));\n",
    "\n",
    "            bounds(iter) = lb;\n",
    "        end\n",
    "        if mod(iter, 1) == 0\n",
    "            fprintf(1, '.');\n",
    "        end\n",
    "        if mod(iter, 10) == 0\n",
    "            fprintf(1, ' %5d', iter);\n",
    "            if parameters.progress==1\n",
    "                fprintf(1, ' %.4f', bounds(iter));\n",
    "            end\n",
    "            fprintf('\\n')\n",
    "        end\n",
    "    end\n",
    "\n",
    "    state.lambda = lambda;\n",
    "    state.a = a;\n",
    "    state.gamma = gamma;\n",
    "    state.omega = omega;\n",
    "    state.be = be;\n",
    "    if parameters.progress == 1\n",
    "        state.bounds = bounds;\n",
    "    end\n",
    "    state.parameters = parameters;\n",
    "end\n",
    "\n",
    "function ld = logdet(Sigma)\n",
    "    U = chol(Sigma);\n",
    "    ld = 2 * sum(log(diag(U)));\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function prediction = bemkl_supervised_classification_variational_test(Km, state)\n",
    "    N = size(Km, 2);\n",
    "    P = size(Km, 3);\n",
    "\n",
    "    prediction.G.mu = zeros(P, N);\n",
    "    prediction.G.sigma = zeros(P, N);\n",
    "    for m = 1:P\n",
    "        prediction.G.mu(m, :) = state.a.mu' * Km(:, :, m);\n",
    "        prediction.G.sigma(m, :) = state.parameters.sigma_g^2 + diag(Km(:, :, m)' * state.a.sigma * Km(:, :, m));\n",
    "    end\n",
    "\n",
    "    prediction.f.mu = [ones(1, N); prediction.G.mu]' * state.be.mu;\n",
    "    prediction.f.sigma = 1 + diag([ones(1, N); prediction.G.mu]' * state.be.sigma * [ones(1, N); prediction.G.mu]);\n",
    "    prediction.a.mu = state.a.mu;\n",
    "    prediction.a.sigma = state.a.sigma;\n",
    "    prediction.be.mu = state.be.mu;\n",
    "    prediction.be.sigma = state.be.sigma;\n",
    "\n",
    "    pos = 1 - normcdf((+state.parameters.margin - prediction.f.mu) ./ prediction.f.sigma);\n",
    "    neg = normcdf((-state.parameters.margin - prediction.f.mu) ./ prediction.f.sigma);\n",
    "    prediction.p = pos ./ (pos + neg);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Km = load('Km.mat');\n",
    "Km_train = Km.Km_train;\n",
    "y_train = double(Km.y_train');\n",
    "Km_test = Km.Km_test;\n",
    "y_test = double(Km.y_test');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "\n",
      "   478   478   130\n",
      "\n",
      "ans =\n",
      "\n",
      "   478     1\n",
      "\n",
      "ans =\n",
      "\n",
      "   478   205   130\n",
      "\n",
      "ans =\n",
      "\n",
      "   205     1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "size(Km_train)\n",
    "size(y_train)\n",
    "size(Km_test)\n",
    "size(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans = matrix\n",
      "ans = matrix\n",
      "ans = matrix\n",
      "ans = matrix\n"
     ]
    }
   ],
   "source": [
    "typeinfo(Km_train)\n",
    "typeinfo(y_train)\n",
    "typeinfo(Km_test)\n",
    "typeinfo(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........    10 -1441.1037\n",
      "..........    20 -1357.7385\n",
      "..........    30 -1342.0792\n",
      "..........    40 -1330.9527\n",
      "..........    50 -1312.2346\n",
      "..........    60 -1289.9190\n",
      "..........    70 -1273.8210\n",
      "..........    80 -1259.3076\n",
      "..........    90 -1232.9936\n",
      "..........   100 -1224.3736\n",
      "..........   110 -1211.8671\n",
      "..........   120 -1204.9300\n",
      "..........   130 -1198.3308\n",
      "..........   140 -1187.7496\n",
      "..........   150 -1178.5490\n",
      "..........   160 -1169.2787\n",
      "..........   170 -1165.1828\n",
      "..........   180 -1161.7347\n",
      "..........   190 -1158.1597\n",
      "..........   200 -1154.0119\n"
     ]
    }
   ],
   "source": [
    "%initalize the parameters of the algorithm\n",
    "parameters = struct();\n",
    "\n",
    "%set the hyperparameters of gamma prior used for sample weights\n",
    "parameters.alpha_lambda = 1;\n",
    "parameters.beta_lambda = 1;\n",
    "\n",
    "%set the hyperparameters of gamma prior used for bias\n",
    "parameters.alpha_gamma = 1;\n",
    "parameters.beta_gamma = 1;\n",
    "\n",
    "%set the hyperparameters of gamma prior used for kernel weights\n",
    "parameters.alpha_omega = 1;\n",
    "parameters.beta_omega = 1;\n",
    "\n",
    "%%% IMPORTANT %%%\n",
    "%For gamma priors, you can experiment with three different (alpha, beta) values\n",
    "%(1, 1) => default priors\n",
    "%(1e-10, 1e+10) => good for obtaining sparsity\n",
    "%(1e-10, 1e-10) => good for small sample size problems\n",
    "\n",
    "%set the number of iterations\n",
    "parameters.iteration = 200;\n",
    "\n",
    "%set the margin parameter\n",
    "parameters.margin = 1;\n",
    "\n",
    "%determine whether you want to calculate and store the lower bound values\n",
    "parameters.progress = 1;\n",
    "\n",
    "%set the seed for random number generator used to initalize random variables\n",
    "parameters.seed = 1606;\n",
    "\n",
    "%set the standard deviation of intermediate representations\n",
    "parameters.sigma_g = 0.1;\n",
    "\n",
    "%initialize the kernels and class labels for training\n",
    "Ktrain = Km_train; %should be an Ntra x Ntra x P matrix containing similarity values between training samples\n",
    "ytrain = y_train; %should be an Ntra x 1 matrix containing class labels (contains only -1s and +1s)\n",
    "\n",
    "%perform training\n",
    "state = bemkl_supervised_classification_variational_train(Ktrain, ytrain, parameters);\n",
    "\n",
    "%display the kernel weights\n",
    "%display(state.be.mu(2:end));\n",
    "\n",
    "%initialize the kernels for testing\n",
    "Ktest = Km_test; %should be an Ntra x Ntest x P matrix containing similarity values between training and test samples\n",
    "\n",
    "%perform prediction\n",
    "prediction = bemkl_supervised_classification_variational_test(Ktest, state);\n",
    "\n",
    "%display the predicted probabilities\n",
    "%display(prediction.p);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save('-6', 'prediction.mat', \"prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.0.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
