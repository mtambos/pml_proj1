{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function state = bemkl_supervised_classification_variational_train(Km, y, parameters)\n",
    "    rand('state', parameters.seed); %#ok<RAND>\n",
    "    randn('state', parameters.seed); %#ok<RAND>\n",
    "\n",
    "    D = size(Km, 1);\n",
    "    N = size(Km, 2);\n",
    "    P = size(Km, 3);\n",
    "    sigma_g = parameters.sigma_g;\n",
    "\n",
    "    log2pi = log(2 * pi);\n",
    "\n",
    "    lambda.alpha = (parameters.alpha_lambda + 0.5) * ones(D, 1);\n",
    "    lambda.beta = parameters.beta_lambda * ones(D, 1);\n",
    "    a.mu = randn(D, 1);\n",
    "    a.sigma = eye(D, D);\n",
    "    G.mu = (abs(randn(P, N)) + parameters.margin) .* sign(repmat(y', P, 1));\n",
    "    G.sigma = eye(P, P);\n",
    "    gamma.alpha = (parameters.alpha_gamma + 0.5);\n",
    "    gamma.beta = parameters.beta_gamma;\n",
    "    omega.alpha = (parameters.alpha_omega + 0.5) * ones(P, 1);\n",
    "    omega.beta = parameters.beta_omega * ones(P, 1);\n",
    "    be.mu = [0; ones(P, 1)];\n",
    "    be.sigma = eye(P + 1, P + 1);\n",
    "    f.mu = (abs(randn(N, 1)) + parameters.margin) .* sign(y);\n",
    "    f.sigma = ones(N, 1);\n",
    "\n",
    "    KmKm = zeros(D, D);\n",
    "    for m = 1:P\n",
    "        KmKm = KmKm + Km(:, :, m) * Km(:, :, m)';\n",
    "    end\n",
    "    Km = reshape(Km, [D, N * P]);\n",
    "\n",
    "    lower = -1e40 * ones(N, 1);\n",
    "    lower(y > 0) = +parameters.margin;\n",
    "    upper = +1e40 * ones(N, 1);\n",
    "    upper(y < 0) = -parameters.margin;\n",
    "\n",
    "    if parameters.progress == 1\n",
    "        bounds = zeros(parameters.iteration, 1);\n",
    "    end\n",
    "    \n",
    "    atimesaT.mu = a.mu * a.mu' + a.sigma;\n",
    "    GtimesGT.mu = G.mu * G.mu' + N * G.sigma;\n",
    "    btimesbT.mu = be.mu(1)^2 + be.sigma(1, 1);\n",
    "    etimeseT.mu = be.mu(2:P + 1) * be.mu(2:P + 1)' + be.sigma(2:P + 1, 2:P + 1);\n",
    "    etimesb.mu = be.mu(2:P + 1) * be.mu(1) + be.sigma(2:P + 1, 1);\n",
    "    KmtimesGT.mu = Km * reshape(G.mu', N * P, 1);\n",
    "    for iter = 1:parameters.iteration\n",
    "        if mod(iter, 1) == 0\n",
    "            fprintf(1, '.');\n",
    "        end\n",
    "        if mod(iter, 10) == 0\n",
    "            fprintf(1, ' %5d\\n', iter);\n",
    "        end\n",
    "\n",
    "        %%%% update lambda\n",
    "        lambda.beta = 1 ./ (1 / parameters.beta_lambda + 0.5 * diag(atimesaT.mu));\n",
    "        %%%% update a\n",
    "        a.sigma = (diag(lambda.alpha .* lambda.beta) + KmKm / sigma_g^2) \\ eye(D, D);\n",
    "        a.mu = a.sigma * KmtimesGT.mu / sigma_g^2;\n",
    "        atimesaT.mu = a.mu * a.mu' + a.sigma;\n",
    "        %%%% update G\n",
    "        G.sigma = (eye(P, P) / sigma_g^2 + etimeseT.mu) \\ eye(P, P);\n",
    "        G.mu = G.sigma * (reshape(a.mu' * Km, [N, P])' / sigma_g^2 + be.mu(2:P + 1) * f.mu' - repmat(etimesb.mu, 1, N));\n",
    "        GtimesGT.mu = G.mu * G.mu' + N * G.sigma;\n",
    "        KmtimesGT.mu = Km * reshape(G.mu', N * P, 1);\n",
    "        %%%% update gamma\n",
    "        gamma.beta = 1 / (1 / parameters.beta_gamma + 0.5 * btimesbT.mu);\n",
    "        %%%% update omega\n",
    "        omega.beta = 1 ./ (1 / parameters.beta_omega + 0.5 * diag(etimeseT.mu));\n",
    "        %%%% update b and e\n",
    "        be.sigma = [gamma.alpha * gamma.beta + N, sum(G.mu, 2)'; sum(G.mu, 2), diag(omega.alpha .* omega.beta) + GtimesGT.mu] \\ eye(P + 1, P + 1);\n",
    "        be.mu = be.sigma * ([ones(1, N); G.mu] * f.mu);\n",
    "        btimesbT.mu = be.mu(1)^2 + be.sigma(1, 1);\n",
    "        etimeseT.mu = be.mu(2:P + 1) * be.mu(2:P + 1)' + be.sigma(2:P + 1, 2:P + 1);\n",
    "        etimesb.mu = be.mu(2:P + 1) * be.mu(1) + be.sigma(2:P + 1, 1);\n",
    "        %%%% update f\n",
    "        output = [ones(1, N); G.mu]' * be.mu;\n",
    "        alpha_norm = lower - output;\n",
    "        beta_norm = upper - output;\n",
    "        normalization = normcdf(beta_norm) - normcdf(alpha_norm);\n",
    "        normalization(normalization == 0) = 1;\n",
    "        f.mu = output + (normpdf(alpha_norm) - normpdf(beta_norm)) ./ normalization;\n",
    "        f.sigma = 1 + (alpha_norm .* normpdf(alpha_norm) - beta_norm .* normpdf(beta_norm)) ./ normalization - (normpdf(alpha_norm) - normpdf(beta_norm)).^2 ./ normalization.^2;\n",
    "\n",
    "        if parameters.progress == 1\n",
    "            lb = 0;\n",
    "\n",
    "            %%%% p(lambda)\n",
    "            lb = lb + sum((parameters.alpha_lambda - 1) * (psi(lambda.alpha) + log(lambda.beta)) - lambda.alpha .* lambda.beta / parameters.beta_lambda - gammaln(parameters.alpha_lambda) - parameters.alpha_lambda * log(parameters.beta_lambda));\n",
    "            %%%% p(a | lambda)\n",
    "            lb = lb - 0.5 * sum(lambda.alpha .* lambda.beta .* diag(atimesaT.mu)) - 0.5 * (D * log2pi - sum(psi(lambda.alpha) + log(lambda.beta)));\n",
    "            %%%% p(G | a, Km)\n",
    "            lb = lb - 0.5 * sigma_g^-2 * sum(diag(GtimesGT.mu)) + sigma_g^-2 * a.mu' * KmtimesGT.mu - 0.5 * sigma_g^-2 * sum(sum(KmKm .* atimesaT.mu)) - 0.5 * N * P * (log2pi + 2 * log(sigma_g));\n",
    "            %%%% p(gamma)\n",
    "            lb = lb + (parameters.alpha_gamma - 1) * (psi(gamma.alpha) + log(gamma.beta)) - gamma.alpha * gamma.beta / parameters.beta_gamma - gammaln(parameters.alpha_gamma) - parameters.alpha_gamma * log(parameters.beta_gamma);\n",
    "            %%%% p(b | gamma)\n",
    "            lb = lb - 0.5 * gamma.alpha * gamma.beta * btimesbT.mu - 0.5 * (log2pi - (psi(gamma.alpha) + log(gamma.beta)));\n",
    "            %%%% p(omega)\n",
    "            lb = lb + sum((parameters.alpha_omega - 1) * (psi(omega.alpha) + log(omega.beta)) - omega.alpha .* omega.beta / parameters.beta_omega - gammaln(parameters.alpha_omega) - parameters.alpha_omega * log(parameters.beta_omega));\n",
    "            %%%% p(e | omega)\n",
    "            lb = lb - 0.5 * sum(omega.alpha .* omega.beta .* diag(etimeseT.mu)) - 0.5 * (P * log2pi - sum(psi(omega.alpha) + log(omega.beta)));\n",
    "            %%%% p(f | b, e, G)\n",
    "            lb = lb - 0.5 * (f.mu' * f.mu + sum(f.sigma)) + f.mu' * (G.mu' * be.mu(2:P + 1)) + sum(be.mu(1) * f.mu) - 0.5 * sum(sum(etimeseT.mu .* GtimesGT.mu)) - sum(G.mu' * etimesb.mu) - 0.5 * N * btimesbT.mu - 0.5 * N * log2pi;\n",
    "\n",
    "            %%%% q(lambda)\n",
    "            lb = lb + sum(lambda.alpha + log(lambda.beta) + gammaln(lambda.alpha) + (1 - lambda.alpha) .* psi(lambda.alpha));\n",
    "            %%%% q(a)\n",
    "            lb = lb + 0.5 * (D * (log2pi + 1) + logdet(a.sigma));\n",
    "            %%%% q(G)\n",
    "            lb = lb + 0.5 * N * (P * (log2pi + 1) + logdet(G.sigma));\n",
    "            %%%% q(gamma)\n",
    "            lb = lb + gamma.alpha + log(gamma.beta) + gammaln(gamma.alpha) + (1 - gamma.alpha) * psi(gamma.alpha);\n",
    "            %%%% q(omega)\n",
    "            lb = lb + sum(omega.alpha + log(omega.beta) + gammaln(omega.alpha) + (1 - omega.alpha) .* psi(omega.alpha));\n",
    "            %%%% q(b, e)\n",
    "            lb = lb + 0.5 * ((P + 1) * (log2pi + 1) + logdet(be.sigma)); \n",
    "            %%%% q(f)\n",
    "            lb = lb + 0.5 * sum(log2pi + f.sigma) + sum(log(normalization));\n",
    "\n",
    "            bounds(iter) = lb;\n",
    "        end\n",
    "    end\n",
    "\n",
    "    state.lambda = lambda;\n",
    "    state.a = a;\n",
    "    state.gamma = gamma;\n",
    "    state.omega = omega;\n",
    "    state.be = be;\n",
    "    if parameters.progress == 1\n",
    "        state.bounds = bounds;\n",
    "    end\n",
    "    state.parameters = parameters;\n",
    "end\n",
    "\n",
    "function ld = logdet(Sigma)\n",
    "    U = chol(Sigma);\n",
    "    ld = 2 * sum(log(diag(U)));\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function prediction = bemkl_supervised_classification_variational_test(Km, state)\n",
    "    N = size(Km, 2);\n",
    "    P = size(Km, 3);\n",
    "\n",
    "    prediction.G.mu = zeros(P, N);\n",
    "    prediction.G.sigma = zeros(P, N);\n",
    "    for m = 1:P\n",
    "        prediction.G.mu(m, :) = state.a.mu' * Km(:, :, m);\n",
    "        prediction.G.sigma(m, :) = state.parameters.sigma_g^2 + diag(Km(:, :, m)' * state.a.sigma * Km(:, :, m));\n",
    "    end\n",
    "\n",
    "    prediction.f.mu = [ones(1, N); prediction.G.mu]' * state.be.mu;\n",
    "    prediction.f.sigma = 1 + diag([ones(1, N); prediction.G.mu]' * state.be.sigma * [ones(1, N); prediction.G.mu]);\n",
    "\n",
    "    pos = 1 - normcdf((+state.parameters.margin - prediction.f.mu) ./ prediction.f.sigma);\n",
    "    neg = normcdf((-state.parameters.margin - prediction.f.mu) ./ prediction.f.sigma);\n",
    "    prediction.p = pos ./ (pos + neg);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Km = load('Km.mat');\n",
    "Km_train = Km.Km_train;\n",
    "y_train = double(Km.y_train');\n",
    "Km_test = Km.Km_test;\n",
    "y_test = double(Km.y_test');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "\n",
      "   478   478   130\n",
      "\n",
      "ans =\n",
      "\n",
      "   478     1\n",
      "\n",
      "ans =\n",
      "\n",
      "   478   205   130\n",
      "\n",
      "ans =\n",
      "\n",
      "   205     1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "size(Km_train)\n",
    "size(y_train)\n",
    "size(Km_test)\n",
    "size(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans = matrix\n",
      "ans = matrix\n",
      "ans = matrix\n",
      "ans = matrix\n"
     ]
    }
   ],
   "source": [
    "typeinfo(Km_train)\n",
    "typeinfo(y_train)\n",
    "typeinfo(Km_test)\n",
    "typeinfo(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........    10\n",
      "..........    20\n",
      "..........    30\n",
      "..........    40\n",
      "..........    50\n",
      "..........    60\n",
      "..........    70\n",
      "..........    80\n",
      "..........    90\n",
      "..........   100\n",
      "..........   110\n",
      "..........   120\n",
      "..........   130\n",
      "..........   140\n",
      "..........   150\n",
      "..........   160\n",
      "..........   170\n",
      "..........   180\n",
      "..........   190\n",
      "..........   200\n",
      "   0.094486\n",
      "   0.094486\n",
      "   0.094486\n",
      "   0.094486\n",
      "   0.094486\n",
      "   0.094486\n",
      "   0.094486\n",
      "   0.094486\n",
      "   0.094486\n",
      "   0.094486\n",
      "   0.696578\n",
      "   0.696578\n",
      "   0.696578\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.070501\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "   0.016084\n",
      "\n",
      "   0.03432\n",
      "   0.99923\n",
      "   1.00000\n",
      "   0.03070\n",
      "   0.00000\n",
      "   0.00000\n",
      "   0.00000\n",
      "   0.00000\n",
      "   0.88480\n",
      "   0.85141\n",
      "   0.89372\n",
      "   1.00000\n",
      "   1.00000\n",
      "   0.00000\n",
      "   0.00000\n",
      "   0.06143\n",
      "   0.99009\n",
      "   0.55849\n",
      "   0.99998\n",
      "   1.00000\n",
      "   0.14183\n",
      "   0.57062\n",
      "   0.02795\n",
      "   0.00000\n",
      "   0.14183\n",
      "   0.00000\n",
      "   0.00000\n",
      "   0.26733\n",
      "   0.39853\n",
      "   0.00085\n",
      "   1.00000\n",
      "   0.66640\n",
      "   0.04002\n",
      "   0.47455\n",
      "   1.00000\n",
      "   1.00000\n",
      "   0.00000\n",
      "   0.00000\n",
      "   0.98474\n",
      "   0.20416\n",
      "   0.00475\n",
      "   0.40442\n",
      "   0.00000\n",
      "   1.00000\n",
      "   1.00000\n",
      "   0.29588\n",
      "   0.99988\n",
      "   0.84364\n",
      "   0.00000\n",
      "   0.00000\n",
      "   1.00000\n",
      "   0.03665\n",
      "   0.88433\n",
      "   1.00000\n",
      "   0.25796\n",
      "   0.04817\n",
      "   1.00000\n",
      "   0.00000\n",
      "   0.00000\n",
      "   0.09225\n",
      "   1.00000\n",
      "   0.00000\n",
      "   0.00000\n",
      "   0.99746\n",
      "   0.78215\n",
      "   1.00000\n",
      "   0.00000\n",
      "   0.00466\n",
      "   0.00003\n",
      "   0.87048\n",
      "   0.00000\n",
      "   0.78215\n",
      "   0.99981\n",
      "   0.00000\n",
      "   0.78215\n",
      "   1.00000\n",
      "   0.99324\n",
      "   0.14183\n",
      "   0.98474\n",
      "   0.00000\n",
      "   1.00000\n",
      "   0.85768\n",
      "   0.98091\n",
      "   0.00350\n",
      "   0.91232\n",
      "   0.00293\n",
      "   0.62487\n",
      "   0.99820\n",
      "   1.00000\n",
      "   1.00000\n",
      "   0.27797\n",
      "   1.00000\n",
      "   0.08445\n",
      "   0.21207\n",
      "   0.00000\n",
      "   0.80171\n",
      "   0.00000\n",
      "   0.51638\n",
      "   0.51943\n",
      "   1.00000\n",
      "   1.00000\n",
      "   0.14183\n",
      "   1.00000\n",
      "   0.78215\n",
      "   0.39853\n",
      "   1.00000\n",
      "   0.28364\n",
      "   0.39853\n",
      "   0.00000\n",
      "   0.14183\n",
      "   1.00000\n",
      "   1.00000\n",
      "   0.00076\n",
      "   1.00000\n",
      "   0.00056\n",
      "   0.00000\n",
      "   0.16740\n",
      "   0.00000\n",
      "   1.00000\n",
      "   0.54753\n",
      "   0.99997\n",
      "   0.00000\n",
      "   0.36314\n",
      "   0.00000\n",
      "   0.26086\n",
      "   1.00000\n",
      "   0.48272\n",
      "   0.16425\n",
      "   1.00000\n",
      "   0.57628\n",
      "   0.17379\n",
      "   0.26113\n",
      "   1.00000\n",
      "   0.99205\n",
      "   0.99848\n",
      "   0.78215\n",
      "   1.00000\n",
      "   1.00000\n",
      "   0.00000\n",
      "   1.00000\n",
      "   0.00000\n",
      "   0.18366\n",
      "   0.00000\n",
      "   0.00000\n",
      "   0.99588\n",
      "   1.00000\n",
      "   0.00000\n",
      "   1.00000\n",
      "   0.03424\n",
      "   0.06585\n",
      "   0.00000\n",
      "   1.00000\n",
      "   0.99988\n",
      "   0.14183\n",
      "   0.98474\n",
      "   0.00000\n",
      "   0.00015\n",
      "   0.92242\n",
      "   1.00000\n",
      "   1.00000\n",
      "   0.00000\n",
      "   0.44117\n",
      "   0.54360\n",
      "   1.00000\n",
      "   0.00089\n",
      "   0.00000\n",
      "   0.98474\n",
      "   0.00000\n",
      "   1.00000\n",
      "   0.64443\n",
      "   0.68112\n",
      "   0.39853\n",
      "   0.09166\n",
      "   0.35147\n",
      "   1.00000\n",
      "   0.00000\n",
      "   0.00000\n",
      "   1.00000\n",
      "   1.00000\n",
      "   1.00000\n",
      "   0.99944\n",
      "   0.98453\n",
      "   0.81847\n",
      "   0.00000\n",
      "   0.93976\n",
      "   0.21207\n",
      "   0.39853\n",
      "   0.21207\n",
      "   0.00293\n",
      "   0.16571\n",
      "   0.78215\n",
      "   0.00000\n",
      "   0.14183\n",
      "   0.55320\n",
      "   0.93062\n",
      "   0.00002\n",
      "   0.05155\n",
      "   0.03292\n",
      "   1.00000\n",
      "   1.00000\n",
      "   0.21672\n",
      "   0.97652\n",
      "   0.03559\n",
      "   0.99998\n",
      "   0.99853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%initalize the parameters of the algorithm\n",
    "parameters = struct();\n",
    "\n",
    "%set the hyperparameters of gamma prior used for sample weights\n",
    "parameters.alpha_lambda = 1;\n",
    "parameters.beta_lambda = 1;\n",
    "\n",
    "%set the hyperparameters of gamma prior used for bias\n",
    "parameters.alpha_gamma = 1;\n",
    "parameters.beta_gamma = 1;\n",
    "\n",
    "%set the hyperparameters of gamma prior used for kernel weights\n",
    "parameters.alpha_omega = 1;\n",
    "parameters.beta_omega = 1;\n",
    "\n",
    "%%% IMPORTANT %%%\n",
    "%For gamma priors, you can experiment with three different (alpha, beta) values\n",
    "%(1, 1) => default priors\n",
    "%(1e-10, 1e+10) => good for obtaining sparsity\n",
    "%(1e-10, 1e-10) => good for small sample size problems\n",
    "\n",
    "%set the number of iterations\n",
    "parameters.iteration = 200;\n",
    "\n",
    "%set the margin parameter\n",
    "parameters.margin = 1;\n",
    "\n",
    "%determine whether you want to calculate and store the lower bound values\n",
    "parameters.progress = 0;\n",
    "\n",
    "%set the seed for random number generator used to initalize random variables\n",
    "parameters.seed = 1606;\n",
    "\n",
    "%set the standard deviation of intermediate representations\n",
    "parameters.sigma_g = 0.1;\n",
    "\n",
    "%initialize the kernels and class labels for training\n",
    "Ktrain = Km_train; %should be an Ntra x Ntra x P matrix containing similarity values between training samples\n",
    "ytrain = y_train; %should be an Ntra x 1 matrix containing class labels (contains only -1s and +1s)\n",
    "\n",
    "%perform training\n",
    "state = bemkl_supervised_classification_variational_train(Ktrain, ytrain, parameters);\n",
    "\n",
    "%display the kernel weights\n",
    "display(state.be.mu(2:end));\n",
    "\n",
    "%initialize the kernels for testing\n",
    "Ktest = Km_test; %should be an Ntra x Ntest x P matrix containing similarity values between training and test samples\n",
    "\n",
    "%perform prediction\n",
    "prediction = bemkl_supervised_classification_variational_test(Ktest, state);\n",
    "\n",
    "%display the predicted probabilities\n",
    "display(prediction.p);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('-6', 'prediction.mat', \"prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
